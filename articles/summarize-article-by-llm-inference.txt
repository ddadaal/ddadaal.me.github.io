1:"$Sreact.fragment"
3:I[6221,[],""]
4:I[5657,[],""]
6:I[8002,[],"OutletBoundary"]
8:I[8002,[],"MetadataBoundary"]
a:I[8002,[],"ViewportBoundary"]
c:I[4404,[],""]
:HL["/_next/static/css/ba0bc4b94db048c9.css","style"]
:HL["/_next/static/css/fe1e54f11bde7158.css","style"]
:HL["/_next/static/css/0e452e629ebb050b.css","style"]
:HL["/_next/static/css/550cc6711c036586.css","style"]
:HL["/_next/static/css/84af3e6cc7365e2a.css","style"]
0:{"P":null,"b":"nBrX811eTrPAMIIYeBHuL","p":"","c":["","articles","summarize-article-by-llm-inference"],"i":false,"f":[[["",{"children":["articles",{"children":[["params","summarize-article-by-llm-inference","oc"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/ba0bc4b94db048c9.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],"$L2"]}],{"children":["articles",["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","articles","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["params","summarize-article-by-llm-inference","oc"],["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","articles","children","$0:f:0:1:2:children:2:children:0","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$L5",[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/fe1e54f11bde7158.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","link","1",{"rel":"stylesheet","href":"/_next/static/css/0e452e629ebb050b.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","link","2",{"rel":"stylesheet","href":"/_next/static/css/550cc6711c036586.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","link","3",{"rel":"stylesheet","href":"/_next/static/css/84af3e6cc7365e2a.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","$L6",null,{"children":"$L7"}]]}],{},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","Aj-Uv74qoNNUzv7gPl2JH",{"children":[["$","$L8",null,{"children":"$L9"}],["$","$La",null,{"children":"$Lb"}],null]}]]}],false]],"m":"$undefined","G":["$c","$undefined"],"s":false,"S":true}
d:I[1574,["116","static/chunks/c556396d-49361b2e780d113c.js","845","static/chunks/845-a0203995fac91684.js","57","static/chunks/57-3951d65188499c8f.js","325","static/chunks/325-924239ad7bda233c.js","177","static/chunks/app/layout-05c4faf2ec628c45.js"],"RootLayout"]
e:I[2061,["116","static/chunks/c556396d-49361b2e780d113c.js","845","static/chunks/845-a0203995fac91684.js","57","static/chunks/57-3951d65188499c8f.js","325","static/chunks/325-924239ad7bda233c.js","177","static/chunks/app/layout-05c4faf2ec628c45.js"],""]
f:I[2725,["116","static/chunks/c556396d-49361b2e780d113c.js","845","static/chunks/845-a0203995fac91684.js","57","static/chunks/57-3951d65188499c8f.js","325","static/chunks/325-924239ad7bda233c.js","177","static/chunks/app/layout-05c4faf2ec628c45.js"],"Header"]
10:I[7583,["116","static/chunks/c556396d-49361b2e780d113c.js","413","static/chunks/7a1bdfe6-8f7609c25899d936.js","994","static/chunks/c4aeae87-2a85323a0275cbf9.js","786","static/chunks/1b3e99d6-50521588821d44ca.js","845","static/chunks/845-a0203995fac91684.js","57","static/chunks/57-3951d65188499c8f.js","826","static/chunks/826-c44bffd752ec02cd.js","971","static/chunks/app/articles/%5B%5B...params%5D%5D/page-8625a0107f5ea4bf.js"],"Localized"]
11:I[1453,["845","static/chunks/845-a0203995fac91684.js","57","static/chunks/57-3951d65188499c8f.js","974","static/chunks/app/page-6cd03741a79daf91.js"],"LocalizedArticleLink"]
12:I[8077,["116","static/chunks/c556396d-49361b2e780d113c.js","845","static/chunks/845-a0203995fac91684.js","57","static/chunks/57-3951d65188499c8f.js","325","static/chunks/325-924239ad7bda233c.js","177","static/chunks/app/layout-05c4faf2ec628c45.js"],"RunningTime"]
13:I[665,["845","static/chunks/845-a0203995fac91684.js","57","static/chunks/57-3951d65188499c8f.js","974","static/chunks/app/page-6cd03741a79daf91.js"],"LastUpdateTime"]
16:I[7365,["116","static/chunks/c556396d-49361b2e780d113c.js","845","static/chunks/845-a0203995fac91684.js","57","static/chunks/57-3951d65188499c8f.js","325","static/chunks/325-924239ad7bda233c.js","177","static/chunks/app/layout-05c4faf2ec628c45.js"],"ToTop"]
14:T518,M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z15:T5b8,M170.54 148.13v217.54l23.43.01 7.71 26.37 42.01-26.37h49.53V148.13H170.54zm97.75 193.93h-27.94l-27.9 17.51-5.08-17.47-11.9-.04V171.75h72.82v170.31zm-118.46-94.39H97.5c1.74-27.1 2.2-51.59 2.2-73.46h51.16s1.97-22.56-8.58-22.31h-88.5c3.49-13.12 7.87-26.66 13.12-40.67 0 0-24.07 0-32.27 21.57-3.39 8.9-13.21 43.14-30.7 78.12 5.89-.64 25.37-1.18 36.84-22.21 2.11-5.89 2.51-6.66 5.14-14.53h28.87c0 10.5-1.2 66.88-1.68 73.44H20.83c-11.74 0-15.56 23.62-15.56 23.62h65.58C66.45 321.1 42.83 363.12 0 396.34c20.49 5.85 40.91-.93 51-9.9 0 0 22.98-20.9 35.59-69.25l53.96 64.94s7.91-26.89-1.24-39.99c-7.58-8.92-28.06-33.06-36.79-41.81L87.9 311.95c4.36-13.98 6.99-27.55 7.87-40.67h61.65s-.09-23.62-7.59-23.62v.01zm412.02-1.6c20.83-25.64 44.98-58.57 44.98-58.57s-18.65-14.8-27.38-4.06c-6 8.15-36.83 48.2-36.83 48.2l19.23 14.43zm-150.09-59.09c-9.01-8.25-25.91 2.13-25.91 2.13s39.52 55.04 41.12 57.45l19.46-13.73s-25.67-37.61-34.66-45.86h-.01zM640 258.35c-19.78 0-130.91.93-131.06.93v-101c4.81 0 12.42-.4 22.85-1.2 40.88-2.41 70.13-4 87.77-4.81 0 0 12.22-27.19-.59-33.44-3.07-1.18-23.17 4.58-23.17 4.58s-165.22 16.49-232.36 18.05c1.6 8.82 7.62 17.08 15.78 19.55 13.31 3.48 22.69 1.7 49.15.89 24.83-1.6 43.68-2.43 56.51-2.43v99.81H351.41s2.82 22.31 25.51 22.85h107.94v70.92c0 13.97-11.19 21.99-24.48 21.12-14.08.11-26.08-1.15-41.69-1.81 1.99 3.97 6.33 14.39 19.31 21.84 9.88 4.81 16.17 6.57 26.02 6.57 29.56 0 45.67-17.28 44.89-45.31v-73.32h122.36c9.68 0 8.7-23.78 8.7-23.78l.03-.01z2:["$","$Ld",null,{"children":[["$","$Le",null,{"data-host":"https://services.ddadaal.me","data-dnt":"false","src":"https://services.ddadaal.me/monitor/script.js","id":"ZwSg9rf6GA","async":true,"defer":true}],["$","$Lf",null,{"resumeLangs":["cn","en"]}],["$","div",null,{"children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[],[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]]],"forbidden":"$undefined","unauthorized":"$undefined"}]}],["$","footer",null,{"className":"bg-base-200 text-base-content","children":["$","div",null,{"className":"footer py-6 max-w-7xl mx-auto px-4","children":[["$","div",null,{"className":"space-y-1","children":[["$","p",null,{"children":["👨🏼‍💻 ",["$","$L10",null,{"id":"footer.codeBy","args":[["$","$L11","about/me",{"className":"link link-hover","basePath":"/about/me","children":"ddadaal"}]]}]]}],["$","p",null,{"children":["📝",["$","$L10",null,{"id":"footer.license","args":[["$","a","license",{"rel":"licene noreferrer","target":"_blank","className":"link","href":"https://creativecommons.org/licenses/by-sa/4.0/","children":"CC BY-SA 4.0"}]]}]]}],["$","$L12",null,{"serverStartTime":"2025-02-15T03:16:18.247+00:00"}],["$","$L13",null,{"time":"2025-02-15T03:16:18.247+00:00"}],["$","div",null,{"children":[["$","p",null,{"children":["📲"," ",["$","$L10",null,{"id":"footer.contacts"}]]}],["$","div",null,{"className":"flex py-2 gap-2","children":[["$","span","http://wpa.qq.com/msgrd?v=3&uin=540232834&site=qq&menu=yes",{"children":["$","a",null,{"href":"http://wpa.qq.com/msgrd?v=3&uin=540232834&site=qq&menu=yes","title":"QQ: 540232834","target":"_blank","className":"block transition hover:scale-125","rel":"noreferrer","children":["$","svg",null,{"stroke":"currentColor","fill":"currentColor","strokeWidth":"0","viewBox":"0 0 448 512","children":["$undefined",[["$","path","0",{"d":"M433.754 420.445c-11.526 1.393-44.86-52.741-44.86-52.741 0 31.345-16.136 72.247-51.051 101.786 16.842 5.192 54.843 19.167 45.803 34.421-7.316 12.343-125.51 7.881-159.632 4.037-34.122 3.844-152.316 8.306-159.632-4.037-9.045-15.25 28.918-29.214 45.783-34.415-34.92-29.539-51.059-70.445-51.059-101.792 0 0-33.334 54.134-44.859 52.741-5.37-.65-12.424-29.644 9.347-99.704 10.261-33.024 21.995-60.478 40.144-105.779C60.683 98.063 108.982.006 224 0c113.737.006 163.156 96.133 160.264 214.963 18.118 45.223 29.912 72.85 40.144 105.778 21.768 70.06 14.716 99.053 9.346 99.704z","children":[]}]]],"className":"$undefined","style":{"color":"$undefined"},"height":22.400000000000002,"width":22.400000000000002,"xmlns":"http://www.w3.org/2000/svg"}]}]}],["$","span","mailto://ddadaal.me@outlook.com",{"children":["$","a",null,{"href":"mailto://ddadaal.me@outlook.com","title":"E-mail: ddadaal@outlook.com","target":"_blank","className":"block transition hover:scale-125","rel":"noreferrer","children":["$","svg",null,{"stroke":"currentColor","fill":"currentColor","strokeWidth":"0","viewBox":"0 0 576 512","children":["$undefined",[["$","path","0",{"d":"M160 448c-25.6 0-51.2-22.4-64-32-64-44.8-83.2-60.8-96-70.4V480c0 17.67 14.33 32 32 32h256c17.67 0 32-14.33 32-32V345.6c-12.8 9.6-32 25.6-96 70.4-12.8 9.6-38.4 32-64 32zm128-192H32c-17.67 0-32 14.33-32 32v16c25.6 19.2 22.4 19.2 115.2 86.4 9.6 6.4 28.8 25.6 44.8 25.6s35.2-19.2 44.8-22.4c92.8-67.2 89.6-67.2 115.2-86.4V288c0-17.67-14.33-32-32-32zm256-96H224c-17.67 0-32 14.33-32 32v32h96c33.21 0 60.59 25.42 63.71 57.82l.29-.22V416h192c17.67 0 32-14.33 32-32V192c0-17.67-14.33-32-32-32zm-32 128h-64v-64h64v64zm-352-96c0-35.29 28.71-64 64-64h224V32c0-17.67-14.33-32-32-32H96C78.33 0 64 14.33 64 32v192h96v-32z","children":[]}]]],"className":"$undefined","style":{"color":"$undefined"},"height":22.400000000000002,"width":22.400000000000002,"xmlns":"http://www.w3.org/2000/svg"}]}]}],["$","span","https://www.linkedin.com/in/chenjunda/",{"children":["$","a",null,{"href":"https://www.linkedin.com/in/chenjunda/","title":"LinkedIn: 陈俊达","target":"_blank","className":"block transition hover:scale-125","rel":"noreferrer","children":["$","svg",null,{"stroke":"currentColor","fill":"currentColor","strokeWidth":"0","viewBox":"0 0 448 512","children":["$undefined",[["$","path","0",{"d":"M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z","children":[]}]]],"className":"$undefined","style":{"color":"$undefined"},"height":22.400000000000002,"width":22.400000000000002,"xmlns":"http://www.w3.org/2000/svg"}]}]}],["$","span","https://github.com/ddadaal",{"children":["$","a",null,{"href":"https://github.com/ddadaal","title":"GitHub: ddadaal","target":"_blank","className":"block transition hover:scale-125","rel":"noreferrer","children":["$","svg",null,{"stroke":"currentColor","fill":"currentColor","strokeWidth":"0","viewBox":"0 0 496 512","children":["$undefined",[["$","path","0",{"d":"$14","children":[]}]]],"className":"$undefined","style":{"color":"$undefined"},"height":22.400000000000002,"width":22.400000000000002,"xmlns":"http://www.w3.org/2000/svg"}]}]}],["$","span","https://steamcommunity.com/profiles/76561198104889782",{"children":["$","a",null,{"href":"https://steamcommunity.com/profiles/76561198104889782","title":"Steam: Victor Crubs","target":"_blank","className":"block transition hover:scale-125","rel":"noreferrer","children":["$","svg",null,{"stroke":"currentColor","fill":"currentColor","strokeWidth":"0","viewBox":"0 0 496 512","children":["$undefined",[["$","path","0",{"d":"M496 256c0 137-111.2 248-248.4 248-113.8 0-209.6-76.3-239-180.4l95.2 39.3c6.4 32.1 34.9 56.4 68.9 56.4 39.2 0 71.9-32.4 70.2-73.5l84.5-60.2c52.1 1.3 95.8-40.9 95.8-93.5 0-51.6-42-93.5-93.7-93.5s-93.7 42-93.7 93.5v1.2L176.6 279c-15.5-.9-30.7 3.4-43.5 12.1L0 236.1C10.2 108.4 117.1 8 247.6 8 384.8 8 496 119 496 256zM155.7 384.3l-30.5-12.6a52.79 52.79 0 0 0 27.2 25.8c26.9 11.2 57.8-1.6 69-28.4 5.4-13 5.5-27.3.1-40.3-5.4-13-15.5-23.2-28.5-28.6-12.9-5.4-26.7-5.2-38.9-.6l31.5 13c19.8 8.2 29.2 30.9 20.9 50.7-8.3 19.9-31 29.2-50.8 21zm173.8-129.9c-34.4 0-62.4-28-62.4-62.3s28-62.3 62.4-62.3 62.4 28 62.4 62.3-27.9 62.3-62.4 62.3zm.1-15.6c25.9 0 46.9-21 46.9-46.8 0-25.9-21-46.8-46.9-46.8s-46.9 21-46.9 46.8c.1 25.8 21.1 46.8 46.9 46.8z","children":[]}]]],"className":"$undefined","style":{"color":"$undefined"},"height":22.400000000000002,"width":22.400000000000002,"xmlns":"http://www.w3.org/2000/svg"}]}]}],["$","span","https://zhihu.com/people/VicCrubs",{"children":["$","a",null,{"href":"https://zhihu.com/people/VicCrubs","title":"知乎：陈俊达","target":"_blank","className":"block transition hover:scale-125","rel":"noreferrer","children":["$","svg",null,{"stroke":"currentColor","fill":"currentColor","strokeWidth":"0","viewBox":"0 0 640 512","children":["$undefined",[["$","path","0",{"d":"$15","children":[]}]]],"className":"$undefined","style":{"color":"$undefined"},"height":22.400000000000002,"width":22.400000000000002,"xmlns":"http://www.w3.org/2000/svg"}]}]}],["$","span","https://www.douban.com/people/183064260/",{"children":["$","a",null,{"href":"https://www.douban.com/people/183064260/","title":"豆瓣: ddadaal","target":"_blank","className":"block transition hover:scale-125","rel":"noreferrer","children":["$","svg",null,{"stroke":"currentColor","fill":"currentColor","strokeWidth":"0","role":"img","viewBox":"0 0 24 24","children":["$undefined",[["$","path","0",{"d":"M.51 3.06h22.98V.755H.51V3.06Zm20.976 2.537v9.608h-2.137l-1.669 5.76H24v2.28H0v-2.28h6.32l-1.67-5.76H2.515V5.597h18.972Zm-5.066 9.608H7.58l1.67 5.76h5.501l1.67-5.76ZM18.367 7.9H5.634v5.025h12.733V7.9Z","children":[]}]]],"className":"$undefined","style":{"color":"$undefined"},"height":22.400000000000002,"width":22.400000000000002,"xmlns":"http://www.w3.org/2000/svg"}]}]}]]}]]}],["$","p",null,{"className":"text-center","children":["©"," ",2025," ","|"," ",["$","$L10",null,{"id":"footer.madeWithLove"}]]}]]}],["$","div",null,{"children":[["$","span",null,{"className":"footer-title","children":["🚀"," ",["$","$L10",null,{"id":"footer.poweredBy"}]]}],[["$","a","React",{"className":"link link-hover","target":"_blank","href":"https://reactjs.org/","rel":"noreferrer","children":"React"}],["$","a","Next.js",{"className":"link link-hover","target":"_blank","href":"https://nextjs.org/","rel":"noreferrer","children":"Next.js"}],["$","a","GitHub Pages",{"className":"link link-hover","target":"_blank","href":"https://pages.github.com/","rel":"noreferrer","children":"GitHub Pages"}],["$","a","TypeScript",{"className":"link link-hover","target":"_blank","href":"https://www.typescriptlang.org/","rel":"noreferrer","children":"TypeScript"}]]]}],["$","div",null,{"children":[["$","span",null,{"className":"footer-title","children":["🎨"," ",["$","$L10",null,{"id":"footer.themedWith"}]]}],[["$","a","daisyui",{"className":"link link-hover","target":"_blank","href":"https://daisyui.com/","rel":"noreferrer","children":"daisyui"}],["$","a","tailwind",{"className":"link link-hover","target":"_blank","href":"https://tailwindcss.com/","rel":"noreferrer","children":"tailwind"}]]]}],["$","div",null,{"children":[["$","span",null,{"className":"footer-title","children":["🎓"," ",["$","$L10",null,{"id":"footer.contacts"}]]}],[["$","a","idealclover - 翠翠酱的个人网站",{"className":"link link-hover","target":"_blank","href":"https://idealclover.top","rel":"noreferrer","children":"idealclover - 翠翠酱的个人网站"}],["$","a","Sephidator - Sephidator的个人博客",{"className":"link link-hover","target":"_blank","href":"https://sephidator.xyz","rel":"noreferrer","children":"Sephidator - Sephidator的个人博客"}],["$","a","iznauy - 个人博客",{"className":"link link-hover","target":"_blank","href":"https://iznauy.github.io/","rel":"noreferrer","children":"iznauy - 个人博客"}],["$","a","Aironoria - 陈俊宇的个人博客",{"className":"link link-hover","target":"_blank","href":"https://aironoria.github.io","rel":"noreferrer","children":"Aironoria - 陈俊宇的个人博客"}],["$","a","forewing - 个人主页",{"className":"link link-hover","target":"_blank","href":"https://jbesu.com/","rel":"noreferrer","children":"forewing - 个人主页"}],["$","a","Weiser - 个人主页",{"className":"link link-hover","target":"_blank","href":"https://weiser.fun","rel":"noreferrer","children":"Weiser - 个人主页"}]]]}]]}]}],["$","$L16",null,{}]]}]
17:I[4378,["116","static/chunks/c556396d-49361b2e780d113c.js","413","static/chunks/7a1bdfe6-8f7609c25899d936.js","994","static/chunks/c4aeae87-2a85323a0275cbf9.js","786","static/chunks/1b3e99d6-50521588821d44ca.js","845","static/chunks/845-a0203995fac91684.js","57","static/chunks/57-3951d65188499c8f.js","826","static/chunks/826-c44bffd752ec02cd.js","971","static/chunks/app/articles/%5B%5B...params%5D%5D/page-8625a0107f5ea4bf.js"],"ArticleFrontmatter"]
1a:I[4674,["116","static/chunks/c556396d-49361b2e780d113c.js","413","static/chunks/7a1bdfe6-8f7609c25899d936.js","994","static/chunks/c4aeae87-2a85323a0275cbf9.js","786","static/chunks/1b3e99d6-50521588821d44ca.js","845","static/chunks/845-a0203995fac91684.js","57","static/chunks/57-3951d65188499c8f.js","826","static/chunks/826-c44bffd752ec02cd.js","971","static/chunks/app/articles/%5B%5B...params%5D%5D/page-8625a0107f5ea4bf.js"],"RelatedArticles"]
1b:I[3373,["116","static/chunks/c556396d-49361b2e780d113c.js","413","static/chunks/7a1bdfe6-8f7609c25899d936.js","994","static/chunks/c4aeae87-2a85323a0275cbf9.js","786","static/chunks/1b3e99d6-50521588821d44ca.js","845","static/chunks/845-a0203995fac91684.js","57","static/chunks/57-3951d65188499c8f.js","826","static/chunks/826-c44bffd752ec02cd.js","971","static/chunks/app/articles/%5B%5B...params%5D%5D/page-8625a0107f5ea4bf.js"],"CommentPanelWithCurrentLanguage"]
18:T4819,
# Azure AI Language Service的结果太差了

去年我给我的文章增加了AI文章总结功能。在[介绍此功能的文章](/articles/ai-article-summary)，我提到当时这个功能是通过[Azure AI Language Service Text Summarization](https://learn.microsoft.com/en-us/azure/ai-services/language-service/summarization/overview?tabs=text-summarization)的功能实现的。

当时我已经发现，这个功能在英文文章上效果还行，但是在中文文章上就基本不可用。

比如，上一篇文章[2024年总结](/articles/summary-for-2024)的总结结果是：

> 本文讲述了作者在毕业后的第一年,通过深入体验现有生活,旅游,搬家,工作和生活。

![这写的是啥？](./what.png)

这是人话吗？且不说用的英文逗号，前两个分句看着还行，后面就变成关键词的叠加，完全没有概括意思。

一年过去了，DeepSeek全球爆火，而我又想起了这个问题，又重新尝试了用原有的方案生成概括，结果差不多，仍然不可用。

**拜托，随便一个大模型都应该比这个好吧！**

去研究了一下此功能的文档，发现文档上完全没有这个功能的任何细节信息，没说用的什么模型、什么Prompt，也不让用户自己定义模型。一年过去了，功能效果丝毫没有改进，似乎像是被放弃了。说得通，毕竟是微软。

# 用Azure AI部署的DeepSeek R1总结文章

实话说，我很少直接和大模型聊天。我使用AI基本只有让Copilot回答编程问题以及生成代码，在编程场景之外我基本完全不用AI，所以也一直不知道怎么把AI应用到我自己的工作和生活流中。我的工作也和AI毫无关系，即使公司策略是All in AI，但是我组仍然和AI似乎扯不上边。

而此时，需求终于来了，为何不让大模型帮我总结文章？

[Azure AI](https://ai.azure.com)是一个微软做的Model as a service平台，可以直接在上面部署、使用、微调模型，不需要自己管理基础设施。DeepSeek R1模型发布后没几天，Azure AI可以直接就支持了部署（[公告](https://azure.microsoft.com/en-us/blog/deepseek-r1-is-now-available-on-azure-ai-foundry-and-github/)），甚至没有价格表，意思是：**它是免费的？**

我立刻去Azure AI上注册了Project，部署了DeepSeek R1。

用Azure AI部署模型非常方便：

1. 注册好Project
2. 进入模型市场，选择DeepSeek R1，填一个Deployment Name，部署
3. 然后拿着Azure AI Endpoint, API Key以及这个Deployment Name，根据[文档](https://learn.microsoft.com/en-us/azure/ai-foundry/model-inference/concepts/endpoints?tabs=javascript#routing)安装调用TS SDK
4. 设计一个Prompt
5. 调用SDK

![点点就能部署模型](./deploy-model.png)

Prompt我随便想了一个：

> Summarize the article in the next message in language ${languageCode} in 100 words. Return the result in plain text format, without any other information.

其中包含三个消息：

1. 语言是`${languageCode}{:ts}`，这是文章的语言参数（`cn`, `en`），这样文章的总结和文章本身的语言一致
2. 要求返回纯文本信息，不包含markdown
3. 100字左右

另外，R1模型总是会返回思考过程，思考过程用`<think>`标签包裹，所以还需要在结果中把`<think>`中去除。

然后我立刻把[2024年总结](/articles/summary-for-2024)扔给AI，很快就拿到了结果：

> 作者回顾毕业一年后生活，探讨如何在最佳年龄充分体验当下。通过密集旅行与亲友刷新地图边界，感受陪伴的意义；开启独居生活后在郊区保租房打造个人空间，享受烹饪与自由。工作方面身处技术运维\"小而美\"团队，虽遇职业发展隐忧但珍惜当前性价比高的稳定状态。面对年龄增长带来的体能下降与生活抉择困惑，既珍视现有平衡又焦虑是否该打破舒适区。最终秉持认同感驱动原则，既保持现状又在游戏启发中思考：是继续深耕现有生活，还是用黄金年龄冒险转型，答案留待明年揭晓。

哇！这效果真不错啊，句子比我自己写得工整多了！

于是，我将脚本应用到博客中的所有文章，基本上所有文章都获得了极好的效果。这里给出几个例子：

| 文章                                                                                                                           | 原总结                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | 现总结                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
| ------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [在西雅图，给生活换个环境](/articles/a-change-of-environment-in-seattle)                                                       | 本文描述了作者在参加微软的Aspire Start Strong+活动时,感受到了全新的生活环境和社交元素。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | 作者参与微软组织的Aspire Start Strong+活动，赴美体验全新生活节奏以缓解职场单调感。西雅图市区高楼林立却人流稀少，郊区以分散式城市结构为主，无车出行困难。活动中高强度社交贯穿全程，跨文化交流时语言障碍明显，英语听说能力面临实战考验。与全球同龄校招生互动后，作者反思环境对人际关系的影响：校园阶段共同目标易建立联结，职场后各自生活轨迹差异导致社交需求转变。短暂六天打破常规，接触多元文化，更深刻思考个人追求与环境的关系。                                                                                                                                                                                                                                                                                                                                                                              |
| [从调库到翻源代码：给wakapi增加SQL Server支持](/articles/support-sqlserver-in-wakapi)                                          | 本文作者在上一篇文章中提到了如何为博客增加点击量监测,并部署到Azure。 后来,同学推荐了wakapi项目,重新实现了wakatime的后端API。 作者发现wakapi并没有原生支持SQL Server,但使用了gorm作为数据库访问框架。 作者通过重用Dialector的逻辑,为关键词加上引号,把同一个go类型在不同的数据库中映射为不同的列类型,以及使用`merge into`语句来模拟upsert的行为。 他认为go非常explicit,虽然他不喜欢它,但它非常简单。 解决这些问题后,PR顺利合并进了主分支。                                                                                                                                                                                                                                                                                       | 作者在尝试将Wakapi项目迁移至SQL Server时，遇到一系列数据库适配问题。包括SQL语法差异、ORM框架配置、外键约束冲突及GORM库的Upsert功能缺陷。通过修改原生SQL语句、动态调整时间字段类型映射、重构外键关系、手动处理唯一索引冲突，最终解决兼容性问题并成功合并代码。此次实践深入了解了SQL Server特性与GORM内部机制，验证了通过实际项目攻坚学习技术的有效性。                                                                                                                                                                                                                                                                                                                                                                                                                                                         |
| [A Kotlin DI Framework in 50 Lines and Thoughts on Kotlin](/articles/a-kotlin-di-framework-in-50-lines-and-thoughts-on-kotlin) | The document discusses the challenges and benefits of using a Dependency Injection (DI) framework in a Java project. It highlights the two main options for dependency management: introducing a full-blown DI framework or using traditional object instantiation or simple factory pattern, which can be time-consuming and cumbersome. The author uses the example of a simple Java project where the interface and implementation class pattern was used to decouple the interface and implementation, but it also introduced complexity. The document suggests using delegation and classpath scan capability to achieve minimal dependencies and extra code, and provides a code example to help understand the process. | The article discusses choosing dependency injection (DI) for small projects, comparing full DI frameworks (verbose) versus factory patterns (clumsy). The author developed a lightweight DI solution using Kotlin’s delegation and classgraph for scanning. Annotations (@Service, @ServiceImpl) mark interfaces and implementations, while a `di()` function delegates dependency resolution, enabling singleton injection with minimal code. Benefits include simplicity, circular dependency support, and dynamic resolution, though limitations include no `init` block usage and lack of advanced features. The author praises Kotlin’s modern features (null checks, lambdas) and how diverse programming paradigms expand problem-solving approaches, emphasizing tools’ influence on design thinking. |

# 本地模型的效果比较玄学

本来这篇文章到这里就该结束了，可是写到第一段的时候，突然想到：

> 随便一个大模型都应该比这个好吧！

那……我本地跑一个呢？

我的台式机是3070，一搜得知这个显卡最大可以装DeepSeek R1 8B版本。于是赶紧打开许久没有打开的Ollama，拉下`deepseek-r1:8b`

```bash
ollama pull deepseek-r1:8b
```

Windows版本的Ollama会在本地`11434`端口启动Ollama的API（[定义](https://github.com/ollama/ollama/blob/main/docs/api.md#list-running-models)），而由于我们是用的JS，Ollama单独出了[ollama-js](https://github.com/ollama/ollama-js) SDK，用起来更简单。

我直接`pnpm i -D ollama{:bash}`，学习了ollama的SDK的使用，直接把给完整版R1用的Prompt发给R1 8B，拿到以下结果：

> 这篇文章通过作者的个人经历和思考，探讨了在“最好的年龄”该如何度过这一主题。作者从20多岁进入巅峰年龄开始，经历了身体素质逐渐下降、工作环境变化以及面对各种选择的内心挣扎。\n\n### 主要内容总结：\n1. **身体与年龄的关系**：作者承认随着年龄增长，身体素质逐渐不如从前，尤其是到了“下半场”，这可能对日常生活和工作产生影响。\n   \n2. **工作环境与不确定性**：虽然选择了一家外企，因为其稳定性和良好的发展机会，但半年后发现公司结构频繁调整，高层变动较大，这让他对未来充满担忧。\n\n3. **面对选择的内心挣扎**：\n   - **职业与生活的平衡**：作者更倾向于保持现状，尤其是对稳定工作的认可和对外资企业组织结构和晋升路线的信任。\n   - **物质与生活的影响**：虽然对大城市有向往，但也清楚地认识到当前平淡的生活状态的珍贵，不愿为了追求新潮而放弃现有的优秀工作。\n\n4. **游戏中的价值观**：通过《沙石镇时光》这款游戏，作者找到了认同感和热爱一件有意义的事的精神状态，这成为他生活中重要的支撑力量。\n\n### 总结：\n文章表达了作者在成熟与不稳定之间的平衡问题上缺乏明确答案，内心对现状的满意与对变化的恐惧之间的矛盾。尽管没有给出明确的选择建议，但通过个人经历和情感描写，揭示了在最佳年龄如何度过这一哲学性问题，鼓励读者反思自己的生活态度和价值观选择。\n\n文章语言流畅，情感真挚，通过对工作、生活和游戏的多角度描述，展现了作者内心的复杂性和对未来的不确定性。

嗯？这个模型怎么不听话？这个Prompt提到的三点（语言、字数、格式），字数和格式的要求根本没有满足！

> Summarize the article in the next message in language ${languageCode} in 100 words. Return the result in plain text format, without any other information.

我试了很多次prompt，仍然没找到什么方法能够让它同时满足这三个需求。同一个提示词，有时候能生成不含markdown的文本，有时候生成又包含；文字字数的限制也是不一定生效。试了多次也没获得好的结果。

除了DeepSeek R1 8B，同时还试了[llamafamily/llama3-chinese-8b-instruct](https://ollama.com/llamafamily/llama3-chinese-8b-instruct)，而这个模型的效果就好一些，但是生成多了也会出现不听话等问题。

> 本文讲述了一名25岁男青年在他的第二十年代度过的时间，他在这段时期里，选择了深入体验现有的生活，在旅游和工作方面都有所变化。他认为这个阶段是他的成长期，是他开始独立生活、选择自己喜欢的事物，并且接受不确定性的阶段。在文章中，他对未来充满了想法和担忧，但最终还是无法预测。

小模型的效果确实和大模型没法比，而不同小模型的精调不一致，效果也差别很大。

推理过程中GPU计算量不大，主要是占了很多的显存。看来接下来换个16G显存的显卡，应该就可以跑更高级的模型了。

![运行推理过程的GPU占用](r1-8b.png)

# 代码不是业务逻辑，而是大模型调用脚本

这次体验让我认识到一点，用LLM写功能的流程和传统的软件工程完全不同：

在传统软件中，**业务逻辑总是精确地通过代码表示**。不管需求多么复杂，这些需求总会在代码中出现。

而用LLM做的功能，不管写什么需求、是什么领域，写出来的代码是基本上都是一样的，代码本身只是个大模型API Caller，实际上的业务逻辑包含在大模型里，二者的接口是提示词。

如何编写提示词完全就是一个玄学，完全和精确、科学完全不沾边。不同的提示词就得出完全不一样的结果，甚至同一个Prompt得到的结果都不一定相同。

这种不确定性让我感觉有点不安。传统的软件即使再复杂，如果模块划分合理、测试充分，起码行为是可预测的，也总做或多或少的维护。而用大模型实现的功能，世界上没有人能直到它是怎么运行的，下次能不能用、有没有可能出什么问题，完全靠天决定。

不过AI确实解决了很多之前想都不敢想让机器解决的问题，很多问题也不需要那么精确。希望以后能找到更多大模型适用的使用场景。



5:["$","article",null,{"children":[["$","div",null,{"className":"bg-neutral px-4 py-8","children":["$","div",null,{"className":"max-w-7xl mx-auto min-h-[256px] flex justify-center text-center text-neutral-content","children":["$","div",null,{"className":"flex flex-col justify-center animate-slide-up","children":[["$","h1",null,{"className":"text-4xl my-2","children":"用大模型总结文章：效果很好，但是玄学"}],["$","$L17",null,{"className":"justify-center","articleId":"summarize-article-by-llm-inference","info":{"content":"$18","title":"用大模型总结文章：效果很好，但是玄学","date":"2025-02-14 23:54","id":"summarize-article-by-llm-inference","lang":"cn","tags":["blog"],"related":["ai-article-summary"],"ignored_in_list":"$undefined","hide_heading":"$undefined","no_toc":"$undefined","absolute_path":"$undefined","last_updated":"$undefined","wordCount":3388,"readingTime":16.94,"filePath":"contents/20250214-summarize-article-by-llm-inference/cn.md","summary":{"articleId":"summarize-article-by-llm-inference","lang":"cn","hash":"7c12244a86d7ff5aed37ec8fb7bdcc88d8ab56dca1300b75e109bab2944d146d","summaries":[{"summaries":["作者批评Azure AI Language Service的中文摘要效果差，转而使用Azure部署的DeepSeek R1模型获得显著提升。通过设计精准提示词实现高质量文本摘要，成功应用于个人博客所有文章。尝试本地运行DeepSeek R1 8B版本时，发现小模型存在输出格式不稳定等问题。文章对比了传统编程与AI开发的差异，指出大模型将业务逻辑隐入黑箱带来的不确定性，但认可其突破传统技术限制的价值，期待未来探索更多适用场景。"],"metadata":{"summarizer":"azure-ai","model":"DeepSeek-R1"},"endTime":"2025-02-15T02:51:03.982Z","startTime":"2025-02-15T02:49:57.481Z"},{"summaries":["### 代码不是业务逻辑，而是大模型调用脚本\n\n这次使用大模型的体验让我深刻认识到以下几点：\n\n1. **传统软件与大模型开发的区别**：\n   - 在传统软件开发中，所有的业务逻辑都会通过精确的代码实现，不论需求多么复杂，都会在代码中有所体现。\n   - 而用大模型开发功能时，代码本质上只是一个调用大模型的API，实际的业务逻辑都在模型内部。提示词起到了决定性作用，但这种依赖感让人感到不确定和不安。\n\n2. **不确定性与玄学感**：\n   - 不同的提示词会导致完全不同的输出结果，即使是同一个模型也无法保证一致性。\n   - 传统软件即使复杂，模块划分合理且测试充分，也能提供可预测的行为和维护保障。而大模型开发后的功能，未知性高，下次是否能用、有没有可能出问题完全取决于模型本身。\n\n3. **小模型与大模型的对比**：\n   - 小模型虽然容易运行，但效果差距明显，大模型的性能和质量更好。\n   - 不同的小模型之间也存在精调差异，选择合适的模型对于结果至关重要。\n\n4. **硬件需求与 GPU 占用**：\n   - 推理过程对 GPU 的计算量和显存占用较高，不得不为更大规模的模型做好准备。\n   - 为了满足接下来的模型需求，可能需要升级 GPU 到更高显存配置。\n\n5. **AI 对传统问题的解决**：\n   - 虽然大模型开发带来了不确定性，但它确实为那些人类难以预测或处理的问题提供了新的思路。\n   - 很多时候，精确和可控不是必须的，灵活性和宽容性可能更适合实际场景。\n\n6. **未来展望与希望**：\n   - 希望能找到更多大模型适用的场景，让其在实际应用中发挥更大的作用。\n   - 同时，也期待未来大模型开发能够解决当前的不确定性问题，让其更加可靠和可控。\n\n7. **总结**：\n   - 大模型的使用与传统软件开发方式有本质的不同，需要从新的角度去理解和应用。\n   - 尽管存在不确定性，但它也带来了许多难以想象的问题解决方案。"],"metadata":{"summarizer":"ollama","model":"deepseek-r1:8b"},"endTime":"2025-02-15T03:14:54.417Z","startTime":"2025-02-15T03:14:24.818Z"},{"summaries":["本文讨论了Azure AI Language Service的效果不佳，并介绍了本地部署DeepSeek R1 8B的小型模型的方式。在文章中，作者通过学习Ollama的SDK，成功实现了小型模型调用脚本和Prompt的过程。然而，小型模型的精调存在差异，使用场景也有限，因此对于某些需求，不一定适用大型模型。不过，AI确实可以解决许多之前难以想象的问题，也有其局限性。"],"metadata":{"summarizer":"ollama","model":"llamafamily/llama3-chinese-8b-instruct"},"endTime":"2025-02-15T03:15:02.264Z","startTime":"2025-02-15T03:14:24.818Z"}]}},"langVersions":["cn"]}]]}]}]}],["$","div",null,{"className":"animate-slide-up","children":[["$","div",null,{"className":"max-w-7xl mx-auto p-4","children":"$L19"}],["$","div",null,{"className":"max-w-7xl mx-auto p-4","children":["$","$L1a",null,{"relatedArticles":[{"id":"ai-article-summary","langVersions":[{"excerpt":"\n# 一条朋友圈的提示\n\n当昨天的[2023年总结](/articles/summary-for-2023)发出后，朋友圈有人对文章做出了总结，这启发了我，何不自己用AI给文章加个总结功能呢？正好也是","lang":"cn","time":"2024-01-01 10:20:00 UTC+8","title":"博客集成AI文章总结功能","last_updated":"$undefined","absolute_path":"$undefined"}]}]}]}],["$","div",null,{"className":"max-w-7xl mx-auto p-4","children":["$","$L1b",null,{"articleId":"summarize-article-by-llm-inference","articleTitle":"用大模型总结文章：效果很好，但是玄学"}]}]]}]]}]
1d:I[7868,["116","static/chunks/c556396d-49361b2e780d113c.js","413","static/chunks/7a1bdfe6-8f7609c25899d936.js","994","static/chunks/c4aeae87-2a85323a0275cbf9.js","786","static/chunks/1b3e99d6-50521588821d44ca.js","845","static/chunks/845-a0203995fac91684.js","57","static/chunks/57-3951d65188499c8f.js","826","static/chunks/826-c44bffd752ec02cd.js","971","static/chunks/app/articles/%5B%5B...params%5D%5D/page-8625a0107f5ea4bf.js"],"Gallery"]
25:I[2422,["116","static/chunks/c556396d-49361b2e780d113c.js","413","static/chunks/7a1bdfe6-8f7609c25899d936.js","994","static/chunks/c4aeae87-2a85323a0275cbf9.js","786","static/chunks/1b3e99d6-50521588821d44ca.js","845","static/chunks/845-a0203995fac91684.js","57","static/chunks/57-3951d65188499c8f.js","826","static/chunks/826-c44bffd752ec02cd.js","971","static/chunks/app/articles/%5B%5B...params%5D%5D/page-8625a0107f5ea4bf.js"],"ArticleToc"]
1e:T4df,M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z20:T4df,M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z22:T4df,M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z24:T4df,M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z19:["$","div",null,{"className":"flex flex-row space-x-4","children":[["$","div",null,{"className":"prose max-w-full lg:w-[75%]","children":["$L1c",["$","$L1d",null,{"withCaption":true,"id":"summarize-article-by-llm-inference","children":[["$","h1","h1-0",{"id":"azure-ai-language-service的结果太差了","children":[["$","a","azure-ai-language-service的结果太差了",{"href":"#azure-ai-language-service的结果太差了","className":"mr-1","children":["$","svg",null,{"stroke":"currentColor","fill":"currentColor","strokeWidth":"0","viewBox":"0 0 512 512","className":"inline-block opacity-20 hover:opacity-60","children":["$undefined",[["$","path","0",{"d":"$1e","children":[]}]]],"style":{"color":"$undefined"},"height":16,"width":16,"xmlns":"http://www.w3.org/2000/svg"}]}],"Azure AI Language Service的结果太差了"]}],"\n",["$","p","p-0",{"children":["去年我给我的文章增加了AI文章总结功能。在",["$","a","a-0",{"href":"/articles/ai-article-summary","children":"介绍此功能的文章"}],"，我提到当时这个功能是通过",["$","a","a-1",{"href":"https://learn.microsoft.com/en-us/azure/ai-services/language-service/summarization/overview?tabs=text-summarization","children":"Azure AI Language Service Text Summarization"}],"的功能实现的。"]}],"\n",["$","p","p-1",{"children":"当时我已经发现，这个功能在英文文章上效果还行，但是在中文文章上就基本不可用。"}],"\n",["$","p","p-2",{"children":["比如，上一篇文章",["$","a","a-0",{"href":"/articles/summary-for-2024","children":"2024年总结"}],"的总结结果是："]}],"\n",["$","blockquote","blockquote-0",{"children":["\n",["$","p","p-0",{"children":"本文讲述了作者在毕业后的第一年,通过深入体验现有生活,旅游,搬家,工作和生活。"}],"\n"]}],"\n",["$","p","p-3",{"children":"$L1f"}],"\n",["$","p","p-4",{"children":"这是人话吗？且不说用的英文逗号，前两个分句看着还行，后面就变成关键词的叠加，完全没有概括意思。"}],"\n",["$","p","p-5",{"children":"一年过去了，DeepSeek全球爆火，而我又想起了这个问题，又重新尝试了用原有的方案生成概括，结果差不多，仍然不可用。"}],"\n",["$","p","p-6",{"children":["$","strong","strong-0",{"children":"拜托，随便一个大模型都应该比这个好吧！"}]}],"\n",["$","p","p-7",{"children":"去研究了一下此功能的文档，发现文档上完全没有这个功能的任何细节信息，没说用的什么模型、什么Prompt，也不让用户自己定义模型。一年过去了，功能效果丝毫没有改进，似乎像是被放弃了。说得通，毕竟是微软。"}],"\n",["$","h1","h1-1",{"id":"用azure-ai部署的deepseek-r1总结文章","children":[["$","a","用azure-ai部署的deepseek-r1总结文章",{"href":"#用azure-ai部署的deepseek-r1总结文章","className":"mr-1","children":["$","svg",null,{"stroke":"currentColor","fill":"currentColor","strokeWidth":"0","viewBox":"0 0 512 512","className":"inline-block opacity-20 hover:opacity-60","children":["$undefined",[["$","path","0",{"d":"$20","children":[]}]]],"style":{"color":"$undefined"},"height":16,"width":16,"xmlns":"http://www.w3.org/2000/svg"}]}],"用Azure AI部署的DeepSeek R1总结文章"]}],"\n",["$","p","p-8",{"children":"实话说，我很少直接和大模型聊天。我使用AI基本只有让Copilot回答编程问题以及生成代码，在编程场景之外我基本完全不用AI，所以也一直不知道怎么把AI应用到我自己的工作和生活流中。我的工作也和AI毫无关系，即使公司策略是All in AI，但是我组仍然和AI似乎扯不上边。"}],"\n",["$","p","p-9",{"children":"而此时，需求终于来了，为何不让大模型帮我总结文章？"}],"\n",["$","p","p-10",{"children":[["$","a","a-0",{"href":"https://ai.azure.com","children":"Azure AI"}],"是一个微软做的Model as a service平台，可以直接在上面部署、使用、微调模型，不需要自己管理基础设施。DeepSeek R1模型发布后没几天，Azure AI可以直接就支持了部署（",["$","a","a-1",{"href":"https://azure.microsoft.com/en-us/blog/deepseek-r1-is-now-available-on-azure-ai-foundry-and-github/","children":"公告"}],"），甚至没有价格表，意思是：",["$","strong","strong-0",{"children":"它是免费的？"}]]}],"\n",["$","p","p-11",{"children":"我立刻去Azure AI上注册了Project，部署了DeepSeek R1。"}],"\n",["$","p","p-12",{"children":"用Azure AI部署模型非常方便："}],"\n",["$","ol","ol-0",{"children":["\n",["$","li","li-0",{"children":"注册好Project"}],"\n",["$","li","li-1",{"children":"进入模型市场，选择DeepSeek R1，填一个Deployment Name，部署"}],"\n",["$","li","li-2",{"children":["然后拿着Azure AI Endpoint, API Key以及这个Deployment Name，根据",["$","a","a-0",{"href":"https://learn.microsoft.com/en-us/azure/ai-foundry/model-inference/concepts/endpoints?tabs=javascript#routing","children":"文档"}],"安装调用TS SDK"]}],"\n",["$","li","li-3",{"children":"设计一个Prompt"}],"\n",["$","li","li-4",{"children":"调用SDK"}],"\n"]}],"\n",["$","p","p-13",{"children":"$L21"}],"\n",["$","p","p-14",{"children":"Prompt我随便想了一个："}],"\n",["$","blockquote","blockquote-1",{"children":["\n",["$","p","p-0",{"children":"Summarize the article in the next message in language ${languageCode} in 100 words. Return the result in plain text format, without any other information."}],"\n"]}],"\n",["$","p","p-15",{"children":"其中包含三个消息："}],"\n",["$","ol","ol-1",{"children":["\n",["$","li","li-0",{"children":["语言是",["$","span","span-0",{"data-rehype-pretty-code-figure":"","children":["$","code","code-0",{"data-language":"ts","data-theme":"one-dark-pro","style":{"backgroundColor":"#282c34","color":"#abb2bf"},"children":["$","span","span-0",{"data-line":"","children":[["$","span","span-0",{"style":{"color":"#E06C75"},"children":"$$"}],["$","span","span-1",{"style":{"color":"#ABB2BF"},"children":"{"}],["$","span","span-2",{"style":{"color":"#E06C75"},"children":"languageCode"}],["$","span","span-3",{"style":{"color":"#ABB2BF"},"children":"}"}]]}]}]}],"，这是文章的语言参数（",["$","code","code-0",{"children":"cn"}],", ",["$","code","code-1",{"children":"en"}],"），这样文章的总结和文章本身的语言一致"]}],"\n",["$","li","li-1",{"children":"要求返回纯文本信息，不包含markdown"}],"\n",["$","li","li-2",{"children":"100字左右"}],"\n"]}],"\n",["$","p","p-16",{"children":["另外，R1模型总是会返回思考过程，思考过程用",["$","code","code-0",{"children":"<think>"}],"标签包裹，所以还需要在结果中把",["$","code","code-1",{"children":"<think>"}],"中去除。"]}],"\n",["$","p","p-17",{"children":["然后我立刻把",["$","a","a-0",{"href":"/articles/summary-for-2024","children":"2024年总结"}],"扔给AI，很快就拿到了结果："]}],"\n",["$","blockquote","blockquote-2",{"children":["\n",["$","p","p-0",{"children":"作者回顾毕业一年后生活，探讨如何在最佳年龄充分体验当下。通过密集旅行与亲友刷新地图边界，感受陪伴的意义；开启独居生活后在郊区保租房打造个人空间，享受烹饪与自由。工作方面身处技术运维\"小而美\"团队，虽遇职业发展隐忧但珍惜当前性价比高的稳定状态。面对年龄增长带来的体能下降与生活抉择困惑，既珍视现有平衡又焦虑是否该打破舒适区。最终秉持认同感驱动原则，既保持现状又在游戏启发中思考：是继续深耕现有生活，还是用黄金年龄冒险转型，答案留待明年揭晓。"}],"\n"]}],"\n",["$","p","p-18",{"children":"哇！这效果真不错啊，句子比我自己写得工整多了！"}],"\n",["$","p","p-19",{"children":"于是，我将脚本应用到博客中的所有文章，基本上所有文章都获得了极好的效果。这里给出几个例子："}],"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",["$","table","table-0",{"children":[["$","thead","thead-0",{"children":["$","tr","tr-0",{"children":[["$","th","th-0",{"children":"文章"}],["$","th","th-1",{"children":"原总结"}],["$","th","th-2",{"children":"现总结"}]]}]}],["$","tbody","tbody-0",{"children":[["$","tr","tr-0",{"children":[["$","td","td-0",{"children":["$","a","a-0",{"href":"/articles/a-change-of-environment-in-seattle","children":"在西雅图，给生活换个环境"}]}],["$","td","td-1",{"children":"本文描述了作者在参加微软的Aspire Start Strong+活动时,感受到了全新的生活环境和社交元素。"}],["$","td","td-2",{"children":"作者参与微软组织的Aspire Start Strong+活动，赴美体验全新生活节奏以缓解职场单调感。西雅图市区高楼林立却人流稀少，郊区以分散式城市结构为主，无车出行困难。活动中高强度社交贯穿全程，跨文化交流时语言障碍明显，英语听说能力面临实战考验。与全球同龄校招生互动后，作者反思环境对人际关系的影响：校园阶段共同目标易建立联结，职场后各自生活轨迹差异导致社交需求转变。短暂六天打破常规，接触多元文化，更深刻思考个人追求与环境的关系。"}]]}],["$","tr","tr-1",{"children":[["$","td","td-0",{"children":["$","a","a-0",{"href":"/articles/support-sqlserver-in-wakapi","children":"从调库到翻源代码：给wakapi增加SQL Server支持"}]}],["$","td","td-1",{"children":["本文作者在上一篇文章中提到了如何为博客增加点击量监测,并部署到Azure。 后来,同学推荐了wakapi项目,重新实现了wakatime的后端API。 作者发现wakapi并没有原生支持SQL Server,但使用了gorm作为数据库访问框架。 作者通过重用Dialector的逻辑,为关键词加上引号,把同一个go类型在不同的数据库中映射为不同的列类型,以及使用",["$","code","code-0",{"children":"merge into"}],"语句来模拟upsert的行为。 他认为go非常explicit,虽然他不喜欢它,但它非常简单。 解决这些问题后,PR顺利合并进了主分支。"]}],["$","td","td-2",{"children":"作者在尝试将Wakapi项目迁移至SQL Server时，遇到一系列数据库适配问题。包括SQL语法差异、ORM框架配置、外键约束冲突及GORM库的Upsert功能缺陷。通过修改原生SQL语句、动态调整时间字段类型映射、重构外键关系、手动处理唯一索引冲突，最终解决兼容性问题并成功合并代码。此次实践深入了解了SQL Server特性与GORM内部机制，验证了通过实际项目攻坚学习技术的有效性。"}]]}],["$","tr","tr-2",{"children":[["$","td","td-0",{"children":["$","a","a-0",{"href":"/articles/a-kotlin-di-framework-in-50-lines-and-thoughts-on-kotlin","children":"A Kotlin DI Framework in 50 Lines and Thoughts on Kotlin"}]}],["$","td","td-1",{"children":"The document discusses the challenges and benefits of using a Dependency Injection (DI) framework in a Java project. It highlights the two main options for dependency management: introducing a full-blown DI framework or using traditional object instantiation or simple factory pattern, which can be time-consuming and cumbersome. The author uses the example of a simple Java project where the interface and implementation class pattern was used to decouple the interface and implementation, but it also introduced complexity. The document suggests using delegation and classpath scan capability to achieve minimal dependencies and extra code, and provides a code example to help understand the process."}],["$","td","td-2",{"children":["The article discusses choosing dependency injection (DI) for small projects, comparing full DI frameworks (verbose) versus factory patterns (clumsy). The author developed a lightweight DI solution using Kotlin’s delegation and classgraph for scanning. Annotations (@Service, @ServiceImpl) mark interfaces and implementations, while a ",["$","code","code-0",{"children":"di()"}]," function delegates dependency resolution, enabling singleton injection with minimal code. Benefits include simplicity, circular dependency support, and dynamic resolution, though limitations include no ",["$","code","code-1",{"children":"init"}]," block usage and lack of advanced features. The author praises Kotlin’s modern features (null checks, lambdas) and how diverse programming paradigms expand problem-solving approaches, emphasizing tools’ influence on design thinking."]}]]}]]}]]}],"\n",["$","h1","h1-2",{"id":"本地模型的效果比较玄学","children":[["$","a","本地模型的效果比较玄学",{"href":"#本地模型的效果比较玄学","className":"mr-1","children":["$","svg",null,{"stroke":"currentColor","fill":"currentColor","strokeWidth":"0","viewBox":"0 0 512 512","className":"inline-block opacity-20 hover:opacity-60","children":["$undefined",[["$","path","0",{"d":"$22","children":[]}]]],"style":{"color":"$undefined"},"height":16,"width":16,"xmlns":"http://www.w3.org/2000/svg"}]}],"本地模型的效果比较玄学"]}],"\n",["$","p","p-20",{"children":"本来这篇文章到这里就该结束了，可是写到第一段的时候，突然想到："}],"\n",["$","blockquote","blockquote-3",{"children":["\n",["$","p","p-0",{"children":"随便一个大模型都应该比这个好吧！"}],"\n"]}],"\n",["$","p","p-21",{"children":"那……我本地跑一个呢？"}],"\n",["$","p","p-22",{"children":["我的台式机是3070，一搜得知这个显卡最大可以装DeepSeek R1 8B版本。于是赶紧打开许久没有打开的Ollama，拉下",["$","code","code-0",{"children":"deepseek-r1:8b"}]]}],"\n",["$","figure","figure-0",{"data-rehype-pretty-code-figure":"","children":["$","pre","pre-0",{"style":{"backgroundColor":"#282c34","color":"#abb2bf"},"tabIndex":0,"data-language":"bash","data-theme":"one-dark-pro","children":["$","code","code-0",{"data-language":"bash","data-theme":"one-dark-pro","style":{"display":"grid"},"children":["$","span","span-0",{"data-line":"","children":[["$","span","span-0",{"style":{"color":"#61AFEF"},"children":"ollama"}],["$","span","span-1",{"style":{"color":"#98C379"},"children":" pull"}],["$","span","span-2",{"style":{"color":"#98C379"},"children":" deepseek-r1:8b"}]]}]}]}]}],"\n",["$","p","p-23",{"children":["Windows版本的Ollama会在本地",["$","code","code-0",{"children":"11434"}],"端口启动Ollama的API（",["$","a","a-0",{"href":"https://github.com/ollama/ollama/blob/main/docs/api.md#list-running-models","children":"定义"}],"），而由于我们是用的JS，Ollama单独出了",["$","a","a-1",{"href":"https://github.com/ollama/ollama-js","children":"ollama-js"}]," SDK，用起来更简单。"]}],"\n",["$","p","p-24",{"children":["我直接",["$","span","span-0",{"data-rehype-pretty-code-figure":"","children":["$","code","code-0",{"data-language":"bash","data-theme":"one-dark-pro","style":{"backgroundColor":"#282c34","color":"#abb2bf"},"children":["$","span","span-0",{"data-line":"","children":[["$","span","span-0",{"style":{"color":"#61AFEF"},"children":"pnpm"}],["$","span","span-1",{"style":{"color":"#98C379"},"children":" i"}],["$","span","span-2",{"style":{"color":"#D19A66"},"children":" -D"}],["$","span","span-3",{"style":{"color":"#98C379"},"children":" ollama"}]]}]}]}],"，学习了ollama的SDK的使用，直接把给完整版R1用的Prompt发给R1 8B，拿到以下结果："]}],"\n",["$","blockquote","blockquote-4",{"children":["\n",["$","p","p-0",{"children":["这篇文章通过作者的个人经历和思考，探讨了在“最好的年龄”该如何度过这一主题。作者从20多岁进入巅峰年龄开始，经历了身体素质逐渐下降、工作环境变化以及面对各种选择的内心挣扎。\\n\\n### 主要内容总结：\\n1. ",["$","strong","strong-0",{"children":"身体与年龄的关系"}],"：作者承认随着年龄增长，身体素质逐渐不如从前，尤其是到了“下半场”，这可能对日常生活和工作产生影响。\\n   \\n2. ",["$","strong","strong-1",{"children":"工作环境与不确定性"}],"：虽然选择了一家外企，因为其稳定性和良好的发展机会，但半年后发现公司结构频繁调整，高层变动较大，这让他对未来充满担忧。\\n\\n3. ",["$","strong","strong-2",{"children":"面对选择的内心挣扎"}],"：\\n   - ",["$","strong","strong-3",{"children":"职业与生活的平衡"}],"：作者更倾向于保持现状，尤其是对稳定工作的认可和对外资企业组织结构和晋升路线的信任。\\n   - ",["$","strong","strong-4",{"children":"物质与生活的影响"}],"：虽然对大城市有向往，但也清楚地认识到当前平淡的生活状态的珍贵，不愿为了追求新潮而放弃现有的优秀工作。\\n\\n4. ",["$","strong","strong-5",{"children":"游戏中的价值观"}],"：通过《沙石镇时光》这款游戏，作者找到了认同感和热爱一件有意义的事的精神状态，这成为他生活中重要的支撑力量。\\n\\n### 总结：\\n文章表达了作者在成熟与不稳定之间的平衡问题上缺乏明确答案，内心对现状的满意与对变化的恐惧之间的矛盾。尽管没有给出明确的选择建议，但通过个人经历和情感描写，揭示了在最佳年龄如何度过这一哲学性问题，鼓励读者反思自己的生活态度和价值观选择。\\n\\n文章语言流畅，情感真挚，通过对工作、生活和游戏的多角度描述，展现了作者内心的复杂性和对未来的不确定性。"]}],"\n"]}],"\n",["$","p","p-25",{"children":"嗯？这个模型怎么不听话？这个Prompt提到的三点（语言、字数、格式），字数和格式的要求根本没有满足！"}],"\n",["$","blockquote","blockquote-5",{"children":["\n",["$","p","p-0",{"children":"Summarize the article in the next message in language ${languageCode} in 100 words. Return the result in plain text format, without any other information."}],"\n"]}],"\n",["$","p","p-26",{"children":"我试了很多次prompt，仍然没找到什么方法能够让它同时满足这三个需求。同一个提示词，有时候能生成不含markdown的文本，有时候生成又包含；文字字数的限制也是不一定生效。试了多次也没获得好的结果。"}],"\n",["$","p","p-27",{"children":["除了DeepSeek R1 8B，同时还试了",["$","a","a-0",{"href":"https://ollama.com/llamafamily/llama3-chinese-8b-instruct","children":"llamafamily/llama3-chinese-8b-instruct"}],"，而这个模型的效果就好一些，但是生成多了也会出现不听话等问题。"]}],"\n",["$","blockquote","blockquote-6",{"children":["\n",["$","p","p-0",{"children":"本文讲述了一名25岁男青年在他的第二十年代度过的时间，他在这段时期里，选择了深入体验现有的生活，在旅游和工作方面都有所变化。他认为这个阶段是他的成长期，是他开始独立生活、选择自己喜欢的事物，并且接受不确定性的阶段。在文章中，他对未来充满了想法和担忧，但最终还是无法预测。"}],"\n"]}],"\n",["$","p","p-28",{"children":"小模型的效果确实和大模型没法比，而不同小模型的精调不一致，效果也差别很大。"}],"\n",["$","p","p-29",{"children":"推理过程中GPU计算量不大，主要是占了很多的显存。看来接下来换个16G显存的显卡，应该就可以跑更高级的模型了。"}],"\n",["$","p","p-30",{"children":"$L23"}],"\n",["$","h1","h1-3",{"id":"代码不是业务逻辑而是大模型调用脚本","children":[["$","a","代码不是业务逻辑而是大模型调用脚本",{"href":"#代码不是业务逻辑而是大模型调用脚本","className":"mr-1","children":["$","svg",null,{"stroke":"currentColor","fill":"currentColor","strokeWidth":"0","viewBox":"0 0 512 512","className":"inline-block opacity-20 hover:opacity-60","children":["$undefined",[["$","path","0",{"d":"$24","children":[]}]]],"style":{"color":"$undefined"},"height":16,"width":16,"xmlns":"http://www.w3.org/2000/svg"}]}],"代码不是业务逻辑，而是大模型调用脚本"]}],"\n",["$","p","p-31",{"children":"这次体验让我认识到一点，用LLM写功能的流程和传统的软件工程完全不同："}],"\n",["$","p","p-32",{"children":["在传统软件中，",["$","strong","strong-0",{"children":"业务逻辑总是精确地通过代码表示"}],"。不管需求多么复杂，这些需求总会在代码中出现。"]}],"\n",["$","p","p-33",{"children":"而用LLM做的功能，不管写什么需求、是什么领域，写出来的代码是基本上都是一样的，代码本身只是个大模型API Caller，实际上的业务逻辑包含在大模型里，二者的接口是提示词。"}],"\n",["$","p","p-34",{"children":"如何编写提示词完全就是一个玄学，完全和精确、科学完全不沾边。不同的提示词就得出完全不一样的结果，甚至同一个Prompt得到的结果都不一定相同。"}],"\n",["$","p","p-35",{"children":"这种不确定性让我感觉有点不安。传统的软件即使再复杂，如果模块划分合理、测试充分，起码行为是可预测的，也总做或多或少的维护。而用大模型实现的功能，世界上没有人能直到它是怎么运行的，下次能不能用、有没有可能出什么问题，完全靠天决定。"}],"\n",["$","p","p-36",{"children":"不过AI确实解决了很多之前想都不敢想让机器解决的问题，很多问题也不需要那么精确。希望以后能找到更多大模型适用的使用场景。"}]]}]]}],["$","div",null,{"className":"hidden lg:block lg:w-[25%]","children":["$","$L25",null,{"toc":[{"depth":1,"value":"Azure AI Language Service的结果太差了","id":"azure-ai-language-service的结果太差了"},{"depth":1,"value":"用Azure AI部署的DeepSeek R1总结文章","id":"用azure-ai部署的deepseek-r1总结文章"},{"depth":1,"value":"本地模型的效果比较玄学","id":"本地模型的效果比较玄学"},{"depth":1,"value":"代码不是业务逻辑，而是大模型调用脚本","id":"代码不是业务逻辑而是大模型调用脚本"}],"hasSummary":true}]}]]}]
27:I[1968,["116","static/chunks/c556396d-49361b2e780d113c.js","413","static/chunks/7a1bdfe6-8f7609c25899d936.js","994","static/chunks/c4aeae87-2a85323a0275cbf9.js","786","static/chunks/1b3e99d6-50521588821d44ca.js","845","static/chunks/845-a0203995fac91684.js","57","static/chunks/57-3951d65188499c8f.js","826","static/chunks/826-c44bffd752ec02cd.js","971","static/chunks/app/articles/%5B%5B...params%5D%5D/page-8625a0107f5ea4bf.js"],""]
26:T4df,M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z1c:["$","div",null,{"className":"p-4 my-4 bg-neutral rounded shadow","children":[["$","h1",null,{"id":"summary","className":"text-neutral-content","children":[["$","a","summary",{"href":"#summary","className":"mr-1 text-neutral-content","children":["$","svg",null,{"stroke":"currentColor","fill":"currentColor","strokeWidth":"0","viewBox":"0 0 512 512","className":"inline-block opacity-20 hover:opacity-60","children":["$undefined",[["$","path","0",{"d":"$26","children":[]}]]],"style":{"color":"$undefined"},"height":16,"width":16,"xmlns":"http://www.w3.org/2000/svg"}]}],["$","$L10","summaryTitle",{"id":"articlePage.summary.title"}]]}],["$","div",null,{"children":["$","div",null,{"role":"tablist","className":"tabs tabs-boxed","children":[[["$","input",null,{"type":"radio","name":"summaryTab","role":"tab","className":"tab text-base-content","id":"summaryTab-0","aria-label":"DeepSeek_R1","defaultChecked":true}],["$","div","0",{"role":"tabpanel","className":"tab-content bg-base-100 border-base-300 rounded-box p-3","children":[["$","div",null,{"className":"prose max-w-full prose-p:m-0 prose-li:m-0 prose-ul:m-0 prose-ol:m-0","children":[["$","p","p-0",{"children":"作者批评Azure AI Language Service的中文摘要效果差，转而使用Azure部署的DeepSeek R1模型获得显著提升。通过设计精准提示词实现高质量文本摘要，成功应用于个人博客所有文章。尝试本地运行DeepSeek R1 8B版本时，发现小模型存在输出格式不稳定等问题。文章对比了传统编程与AI开发的差异，指出大模型将业务逻辑隐入黑箱带来的不确定性，但认可其突破传统技术限制的价值，期待未来探索更多适用场景。"}]]}],["$","p",null,{"className":"text-sm justify-end flex p-1","children":["$","$L10",null,{"id":"articlePage.summary.poweredBy.azureAi","args":[["$","$L27","azureAiUrl",{"target":"_blank","href":"https://ai.azure.com","children":"Azure AI"}],"DeepSeek-R1"]}]}]]}]],[["$","input",null,{"type":"radio","name":"summaryTab","role":"tab","className":"tab text-base-content","id":"summaryTab-1","aria-label":"DeepSeek_R1_8B","defaultChecked":false}],["$","div","1",{"role":"tabpanel","className":"tab-content bg-base-100 border-base-300 rounded-box p-3","children":[["$","div",null,{"className":"prose max-w-full prose-p:m-0 prose-li:m-0 prose-ul:m-0 prose-ol:m-0","children":[["$","h3","h3-0",{"children":"代码不是业务逻辑，而是大模型调用脚本"}],"\n",["$","p","p-0",{"children":"这次使用大模型的体验让我深刻认识到以下几点："}],"\n",["$","ol","ol-0",{"children":["\n",["$","li","li-0",{"children":["\n",["$","p","p-0",{"children":[["$","strong","strong-0",{"children":"传统软件与大模型开发的区别"}],"："]}],"\n",["$","ul","ul-0",{"children":["\n",["$","li","li-0",{"children":"在传统软件开发中，所有的业务逻辑都会通过精确的代码实现，不论需求多么复杂，都会在代码中有所体现。"}],"\n",["$","li","li-1",{"children":"而用大模型开发功能时，代码本质上只是一个调用大模型的API，实际的业务逻辑都在模型内部。提示词起到了决定性作用，但这种依赖感让人感到不确定和不安。"}],"\n"]}],"\n"]}],"\n",["$","li","li-1",{"children":["\n",["$","p","p-0",{"children":[["$","strong","strong-0",{"children":"不确定性与玄学感"}],"："]}],"\n",["$","ul","ul-0",{"children":["\n",["$","li","li-0",{"children":"不同的提示词会导致完全不同的输出结果，即使是同一个模型也无法保证一致性。"}],"\n",["$","li","li-1",{"children":"传统软件即使复杂，模块划分合理且测试充分，也能提供可预测的行为和维护保障。而大模型开发后的功能，未知性高，下次是否能用、有没有可能出问题完全取决于模型本身。"}],"\n"]}],"\n"]}],"\n",["$","li","li-2",{"children":["\n",["$","p","p-0",{"children":[["$","strong","strong-0",{"children":"小模型与大模型的对比"}],"："]}],"\n",["$","ul","ul-0",{"children":["\n",["$","li","li-0",{"children":"小模型虽然容易运行，但效果差距明显，大模型的性能和质量更好。"}],"\n",["$","li","li-1",{"children":"不同的小模型之间也存在精调差异，选择合适的模型对于结果至关重要。"}],"\n"]}],"\n"]}],"\n",["$","li","li-3",{"children":["\n",["$","p","p-0",{"children":[["$","strong","strong-0",{"children":"硬件需求与 GPU 占用"}],"："]}],"\n",["$","ul","ul-0",{"children":["\n",["$","li","li-0",{"children":"推理过程对 GPU 的计算量和显存占用较高，不得不为更大规模的模型做好准备。"}],"\n",["$","li","li-1",{"children":"为了满足接下来的模型需求，可能需要升级 GPU 到更高显存配置。"}],"\n"]}],"\n"]}],"\n",["$","li","li-4",{"children":["\n",["$","p","p-0",{"children":[["$","strong","strong-0",{"children":"AI 对传统问题的解决"}],"："]}],"\n",["$","ul","ul-0",{"children":["\n",["$","li","li-0",{"children":"虽然大模型开发带来了不确定性，但它确实为那些人类难以预测或处理的问题提供了新的思路。"}],"\n",["$","li","li-1",{"children":"很多时候，精确和可控不是必须的，灵活性和宽容性可能更适合实际场景。"}],"\n"]}],"\n"]}],"\n",["$","li","li-5",{"children":["\n",["$","p","p-0",{"children":[["$","strong","strong-0",{"children":"未来展望与希望"}],"："]}],"\n",["$","ul","ul-0",{"children":["\n",["$","li","li-0",{"children":"希望能找到更多大模型适用的场景，让其在实际应用中发挥更大的作用。"}],"\n",["$","li","li-1",{"children":"同时，也期待未来大模型开发能够解决当前的不确定性问题，让其更加可靠和可控。"}],"\n"]}],"\n"]}],"\n",["$","li","li-6",{"children":["\n",["$","p","p-0",{"children":[["$","strong","strong-0",{"children":"总结"}],"："]}],"\n",["$","ul","ul-0",{"children":["\n",["$","li","li-0",{"children":"大模型的使用与传统软件开发方式有本质的不同，需要从新的角度去理解和应用。"}],"\n",["$","li","li-1",{"children":"尽管存在不确定性，但它也带来了许多难以想象的问题解决方案。"}],"\n"]}],"\n"]}],"\n"]}]]}],["$","p",null,{"className":"text-sm justify-end flex p-1","children":["$","$L10",null,{"id":"articlePage.summary.poweredBy.ollama","args":[["$","$L27","ollamaUrl",{"target":"_blank","href":"https://ollama.com/","children":"Ollama"}],"deepseek-r1:8b"]}]}]]}]],[["$","input",null,{"type":"radio","name":"summaryTab","role":"tab","className":"tab text-base-content","id":"summaryTab-2","aria-label":"Llama3_Chinese_8B_Instruct","defaultChecked":false}],["$","div","2",{"role":"tabpanel","className":"tab-content bg-base-100 border-base-300 rounded-box p-3","children":[["$","div",null,{"className":"prose max-w-full prose-p:m-0 prose-li:m-0 prose-ul:m-0 prose-ol:m-0","children":[["$","p","p-0",{"children":"本文讨论了Azure AI Language Service的效果不佳，并介绍了本地部署DeepSeek R1 8B的小型模型的方式。在文章中，作者通过学习Ollama的SDK，成功实现了小型模型调用脚本和Prompt的过程。然而，小型模型的精调存在差异，使用场景也有限，因此对于某些需求，不一定适用大型模型。不过，AI确实可以解决许多之前难以想象的问题，也有其局限性。"}]]}],["$","p",null,{"className":"text-sm justify-end flex p-1","children":["$","$L10",null,{"id":"articlePage.summary.poweredBy.ollama","args":[["$","$L27","ollamaUrl",{"target":"_blank","href":"https://ollama.com/","children":"Ollama"}],"llamafamily/llama3-chinese-8b-instruct"]}]}]]}]]]}]}]]}]
b:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
9:[["$","meta","0",{"charSet":"utf-8"}],["$","title","1",{"children":"用大模型总结文章：效果很好，但是玄学 - ddadaal.me"}],["$","meta","2",{"name":"description","content":"ddadaal's personal website"}],["$","link","3",{"rel":"manifest","href":"/site.webmanifest","crossOrigin":"$undefined"}],["$","link","4",{"rel":"icon","href":"/favicon.ico","type":"image/x-icon","sizes":"16x16"}],["$","link","5",{"rel":"icon","href":"/icon.svg?35be8e76be1c3618","type":"image/svg+xml","sizes":"any"}],["$","link","6",{"rel":"apple-touch-icon","href":"/apple-icon.png?5334a64f42000bb0","type":"image/png","sizes":"180x180"}]]
7:null
28:I[51,["116","static/chunks/c556396d-49361b2e780d113c.js","413","static/chunks/7a1bdfe6-8f7609c25899d936.js","994","static/chunks/c4aeae87-2a85323a0275cbf9.js","786","static/chunks/1b3e99d6-50521588821d44ca.js","845","static/chunks/845-a0203995fac91684.js","57","static/chunks/57-3951d65188499c8f.js","826","static/chunks/826-c44bffd752ec02cd.js","971","static/chunks/app/articles/%5B%5B...params%5D%5D/page-8625a0107f5ea4bf.js"],"ArticleImage"]
1f:["$","$L28","img-0",{"src":"/articles/asset/contents/20250214-summarize-article-by-llm-inference/what.png","imageSize":{"height":316,"width":443},"imageProps":{"src":"./what.png","alt":"这写的是啥？"}}]
23:["$","$L28","img-0",{"src":"/articles/asset/contents/20250214-summarize-article-by-llm-inference/r1-8b.png","imageSize":{"height":550,"width":762},"imageProps":{"src":"r1-8b.png","alt":"运行推理过程的GPU占用"}}]
21:["$","$L28","img-0",{"src":"/articles/asset/contents/20250214-summarize-article-by-llm-inference/deploy-model.png","imageSize":{"height":885,"width":1515},"imageProps":{"src":"./deploy-model.png","alt":"点点就能部署模型"}}]

1:"$Sreact.fragment"
2:I[28979,["/_next/static/chunks/8d29a04bcfe27c24.js","/_next/static/chunks/3dff3d4c63cf346e.js","/_next/static/chunks/b3af52d5d180873a.js","/_next/static/chunks/86b442c1397f7351.js","/_next/static/chunks/0a1497ca0a1721ad.js","/_next/static/chunks/4ec1bf7a32b70f87.js","/_next/static/chunks/276b22541034e0ea.js"],"ArticleFrontmatter"]
c:I[21753,["/_next/static/chunks/8d29a04bcfe27c24.js","/_next/static/chunks/3dff3d4c63cf346e.js","/_next/static/chunks/b3af52d5d180873a.js","/_next/static/chunks/86b442c1397f7351.js","/_next/static/chunks/0a1497ca0a1721ad.js","/_next/static/chunks/4ec1bf7a32b70f87.js","/_next/static/chunks/276b22541034e0ea.js"],"ArticleSummarization"]
d:I[79817,["/_next/static/chunks/8d29a04bcfe27c24.js","/_next/static/chunks/3dff3d4c63cf346e.js","/_next/static/chunks/b3af52d5d180873a.js","/_next/static/chunks/86b442c1397f7351.js","/_next/static/chunks/0a1497ca0a1721ad.js","/_next/static/chunks/4ec1bf7a32b70f87.js","/_next/static/chunks/276b22541034e0ea.js"],"Gallery"]
45:I[23491,["/_next/static/chunks/2caa33a942c5f527.js","/_next/static/chunks/59983278a34fd25c.js"],"OutletBoundary"]
46:"$Sreact.suspense"
48:I[72053,["/_next/static/chunks/8d29a04bcfe27c24.js","/_next/static/chunks/3dff3d4c63cf346e.js","/_next/static/chunks/b3af52d5d180873a.js","/_next/static/chunks/86b442c1397f7351.js","/_next/static/chunks/0a1497ca0a1721ad.js","/_next/static/chunks/4ec1bf7a32b70f87.js","/_next/static/chunks/276b22541034e0ea.js"],"ArticleImage"]
4c:I[14620,["/_next/static/chunks/8d29a04bcfe27c24.js","/_next/static/chunks/3dff3d4c63cf346e.js","/_next/static/chunks/b3af52d5d180873a.js","/_next/static/chunks/86b442c1397f7351.js","/_next/static/chunks/0a1497ca0a1721ad.js","/_next/static/chunks/4ec1bf7a32b70f87.js","/_next/static/chunks/276b22541034e0ea.js"],"ArticleToc"]
4d:I[39182,["/_next/static/chunks/8d29a04bcfe27c24.js","/_next/static/chunks/3dff3d4c63cf346e.js","/_next/static/chunks/b3af52d5d180873a.js","/_next/static/chunks/86b442c1397f7351.js","/_next/static/chunks/0a1497ca0a1721ad.js","/_next/static/chunks/4ec1bf7a32b70f87.js","/_next/static/chunks/276b22541034e0ea.js"],"RelatedArticles"]
4e:I[42449,["/_next/static/chunks/8d29a04bcfe27c24.js","/_next/static/chunks/3dff3d4c63cf346e.js","/_next/static/chunks/b3af52d5d180873a.js","/_next/static/chunks/86b442c1397f7351.js","/_next/static/chunks/0a1497ca0a1721ad.js","/_next/static/chunks/4ec1bf7a32b70f87.js","/_next/static/chunks/276b22541034e0ea.js"],"CommentPanelWithCurrentLanguage"]
:HL["/_next/static/chunks/44d2e091595b3eca.css","style"]
:HL["/_next/static/chunks/5e55d74f3211c796.css","style"]
:HL["/_next/static/chunks/b59bad6ea4f112f2.css","style"]
3:T4819,
# Azure AI Language Service的结果太差了

去年我给我的文章增加了AI文章总结功能。在[介绍此功能的文章](/articles/ai-article-summary)，我提到当时这个功能是通过[Azure AI Language Service Text Summarization](https://learn.microsoft.com/en-us/azure/ai-services/language-service/summarization/overview?tabs=text-summarization)的功能实现的。

当时我已经发现，这个功能在英文文章上效果还行，但是在中文文章上就基本不可用。

比如，上一篇文章[2024年总结](/articles/summary-for-2024)的总结结果是：

> 本文讲述了作者在毕业后的第一年,通过深入体验现有生活,旅游,搬家,工作和生活。

![这写的是啥？](./what.png)

这是人话吗？且不说用的英文逗号，前两个分句看着还行，后面就变成关键词的叠加，完全没有概括意思。

一年过去了，DeepSeek全球爆火，而我又想起了这个问题，又重新尝试了用原有的方案生成概括，结果差不多，仍然不可用。

**拜托，随便一个大模型都应该比这个好吧！**

去研究了一下此功能的文档，发现文档上完全没有这个功能的任何细节信息，没说用的什么模型、什么Prompt，也不让用户自己定义模型。一年过去了，功能效果丝毫没有改进，似乎像是被放弃了。说得通，毕竟是微软。

# 用Azure AI部署的DeepSeek R1总结文章

实话说，我很少直接和大模型聊天。我使用AI基本只有让Copilot回答编程问题以及生成代码，在编程场景之外我基本完全不用AI，所以也一直不知道怎么把AI应用到我自己的工作和生活流中。我的工作也和AI毫无关系，即使公司策略是All in AI，但是我组仍然和AI似乎扯不上边。

而此时，需求终于来了，为何不让大模型帮我总结文章？

[Azure AI](https://ai.azure.com)是一个微软做的Model as a service平台，可以直接在上面部署、使用、微调模型，不需要自己管理基础设施。DeepSeek R1模型发布后没几天，Azure AI可以直接就支持了部署（[公告](https://azure.microsoft.com/en-us/blog/deepseek-r1-is-now-available-on-azure-ai-foundry-and-github/)），甚至没有价格表，意思是：**它是免费的？**

我立刻去Azure AI上注册了Project，部署了DeepSeek R1。

用Azure AI部署模型非常方便：

1. 注册好Project
2. 进入模型市场，选择DeepSeek R1，填一个Deployment Name，部署
3. 然后拿着Azure AI Endpoint, API Key以及这个Deployment Name，根据[文档](https://learn.microsoft.com/en-us/azure/ai-foundry/model-inference/concepts/endpoints?tabs=javascript#routing)安装调用TS SDK
4. 设计一个Prompt
5. 调用SDK

![点点就能部署模型](./deploy-model.png)

Prompt我随便想了一个：

> Summarize the article in the next message in language ${languageCode} in 100 words. Return the result in plain text format, without any other information.

其中包含三个消息：

1. 语言是`${languageCode}{:ts}`，这是文章的语言参数（`cn`, `en`），这样文章的总结和文章本身的语言一致
2. 要求返回纯文本信息，不包含markdown
3. 100字左右

另外，R1模型总是会返回思考过程，思考过程用`<think>`标签包裹，所以还需要在结果中把`<think>`中去除。

然后我立刻把[2024年总结](/articles/summary-for-2024)扔给AI，很快就拿到了结果：

> 作者回顾毕业一年后生活，探讨如何在最佳年龄充分体验当下。通过密集旅行与亲友刷新地图边界，感受陪伴的意义；开启独居生活后在郊区保租房打造个人空间，享受烹饪与自由。工作方面身处技术运维\"小而美\"团队，虽遇职业发展隐忧但珍惜当前性价比高的稳定状态。面对年龄增长带来的体能下降与生活抉择困惑，既珍视现有平衡又焦虑是否该打破舒适区。最终秉持认同感驱动原则，既保持现状又在游戏启发中思考：是继续深耕现有生活，还是用黄金年龄冒险转型，答案留待明年揭晓。

哇！这效果真不错啊，句子比我自己写得工整多了！

于是，我将脚本应用到博客中的所有文章，基本上所有文章都获得了极好的效果。这里给出几个例子：

| 文章                                                                                                                           | 原总结                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | 现总结                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
| ------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [在西雅图，给生活换个环境](/articles/a-change-of-environment-in-seattle)                                                       | 本文描述了作者在参加微软的Aspire Start Strong+活动时,感受到了全新的生活环境和社交元素。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | 作者参与微软组织的Aspire Start Strong+活动，赴美体验全新生活节奏以缓解职场单调感。西雅图市区高楼林立却人流稀少，郊区以分散式城市结构为主，无车出行困难。活动中高强度社交贯穿全程，跨文化交流时语言障碍明显，英语听说能力面临实战考验。与全球同龄校招生互动后，作者反思环境对人际关系的影响：校园阶段共同目标易建立联结，职场后各自生活轨迹差异导致社交需求转变。短暂六天打破常规，接触多元文化，更深刻思考个人追求与环境的关系。                                                                                                                                                                                                                                                                                                                                                                              |
| [从调库到翻源代码：给wakapi增加SQL Server支持](/articles/support-sqlserver-in-wakapi)                                          | 本文作者在上一篇文章中提到了如何为博客增加点击量监测,并部署到Azure。 后来,同学推荐了wakapi项目,重新实现了wakatime的后端API。 作者发现wakapi并没有原生支持SQL Server,但使用了gorm作为数据库访问框架。 作者通过重用Dialector的逻辑,为关键词加上引号,把同一个go类型在不同的数据库中映射为不同的列类型,以及使用`merge into`语句来模拟upsert的行为。 他认为go非常explicit,虽然他不喜欢它,但它非常简单。 解决这些问题后,PR顺利合并进了主分支。                                                                                                                                                                                                                                                                                       | 作者在尝试将Wakapi项目迁移至SQL Server时，遇到一系列数据库适配问题。包括SQL语法差异、ORM框架配置、外键约束冲突及GORM库的Upsert功能缺陷。通过修改原生SQL语句、动态调整时间字段类型映射、重构外键关系、手动处理唯一索引冲突，最终解决兼容性问题并成功合并代码。此次实践深入了解了SQL Server特性与GORM内部机制，验证了通过实际项目攻坚学习技术的有效性。                                                                                                                                                                                                                                                                                                                                                                                                                                                         |
| [A Kotlin DI Framework in 50 Lines and Thoughts on Kotlin](/articles/a-kotlin-di-framework-in-50-lines-and-thoughts-on-kotlin) | The document discusses the challenges and benefits of using a Dependency Injection (DI) framework in a Java project. It highlights the two main options for dependency management: introducing a full-blown DI framework or using traditional object instantiation or simple factory pattern, which can be time-consuming and cumbersome. The author uses the example of a simple Java project where the interface and implementation class pattern was used to decouple the interface and implementation, but it also introduced complexity. The document suggests using delegation and classpath scan capability to achieve minimal dependencies and extra code, and provides a code example to help understand the process. | The article discusses choosing dependency injection (DI) for small projects, comparing full DI frameworks (verbose) versus factory patterns (clumsy). The author developed a lightweight DI solution using Kotlin’s delegation and classgraph for scanning. Annotations (@Service, @ServiceImpl) mark interfaces and implementations, while a `di()` function delegates dependency resolution, enabling singleton injection with minimal code. Benefits include simplicity, circular dependency support, and dynamic resolution, though limitations include no `init` block usage and lack of advanced features. The author praises Kotlin’s modern features (null checks, lambdas) and how diverse programming paradigms expand problem-solving approaches, emphasizing tools’ influence on design thinking. |

# 本地模型的效果比较玄学

本来这篇文章到这里就该结束了，可是写到第一段的时候，突然想到：

> 随便一个大模型都应该比这个好吧！

那……我本地跑一个呢？

我的台式机是3070，一搜得知这个显卡最大可以装DeepSeek R1 8B版本。于是赶紧打开许久没有打开的Ollama，拉下`deepseek-r1:8b`

```bash
ollama pull deepseek-r1:8b
```

Windows版本的Ollama会在本地`11434`端口启动Ollama的API（[定义](https://github.com/ollama/ollama/blob/main/docs/api.md#list-running-models)），而由于我们是用的JS，Ollama单独出了[ollama-js](https://github.com/ollama/ollama-js) SDK，用起来更简单。

我直接`pnpm i -D ollama{:bash}`，学习了ollama的SDK的使用，直接把给完整版R1用的Prompt发给R1 8B，拿到以下结果：

> 这篇文章通过作者的个人经历和思考，探讨了在“最好的年龄”该如何度过这一主题。作者从20多岁进入巅峰年龄开始，经历了身体素质逐渐下降、工作环境变化以及面对各种选择的内心挣扎。\n\n### 主要内容总结：\n1. **身体与年龄的关系**：作者承认随着年龄增长，身体素质逐渐不如从前，尤其是到了“下半场”，这可能对日常生活和工作产生影响。\n   \n2. **工作环境与不确定性**：虽然选择了一家外企，因为其稳定性和良好的发展机会，但半年后发现公司结构频繁调整，高层变动较大，这让他对未来充满担忧。\n\n3. **面对选择的内心挣扎**：\n   - **职业与生活的平衡**：作者更倾向于保持现状，尤其是对稳定工作的认可和对外资企业组织结构和晋升路线的信任。\n   - **物质与生活的影响**：虽然对大城市有向往，但也清楚地认识到当前平淡的生活状态的珍贵，不愿为了追求新潮而放弃现有的优秀工作。\n\n4. **游戏中的价值观**：通过《沙石镇时光》这款游戏，作者找到了认同感和热爱一件有意义的事的精神状态，这成为他生活中重要的支撑力量。\n\n### 总结：\n文章表达了作者在成熟与不稳定之间的平衡问题上缺乏明确答案，内心对现状的满意与对变化的恐惧之间的矛盾。尽管没有给出明确的选择建议，但通过个人经历和情感描写，揭示了在最佳年龄如何度过这一哲学性问题，鼓励读者反思自己的生活态度和价值观选择。\n\n文章语言流畅，情感真挚，通过对工作、生活和游戏的多角度描述，展现了作者内心的复杂性和对未来的不确定性。

嗯？这个模型怎么不听话？这个Prompt提到的三点（语言、字数、格式），字数和格式的要求根本没有满足！

> Summarize the article in the next message in language ${languageCode} in 100 words. Return the result in plain text format, without any other information.

我试了很多次prompt，仍然没找到什么方法能够让它同时满足这三个需求。同一个提示词，有时候能生成不含markdown的文本，有时候生成又包含；文字字数的限制也是不一定生效。试了多次也没获得好的结果。

除了DeepSeek R1 8B，同时还试了[llamafamily/llama3-chinese-8b-instruct](https://ollama.com/llamafamily/llama3-chinese-8b-instruct)，而这个模型的效果就好一些，但是生成多了也会出现不听话等问题。

> 本文讲述了一名25岁男青年在他的第二十年代度过的时间，他在这段时期里，选择了深入体验现有的生活，在旅游和工作方面都有所变化。他认为这个阶段是他的成长期，是他开始独立生活、选择自己喜欢的事物，并且接受不确定性的阶段。在文章中，他对未来充满了想法和担忧，但最终还是无法预测。

小模型的效果确实和大模型没法比，而不同小模型的精调不一致，效果也差别很大。

推理过程中GPU计算量不大，主要是占了很多的显存。看来接下来换个16G显存的显卡，应该就可以跑更高级的模型了。

![运行推理过程的GPU占用](r1-8b.png)

# 代码不是业务逻辑，而是大模型调用脚本

这次体验让我认识到一点，用LLM写功能的流程和传统的软件工程完全不同：

在传统软件中，**业务逻辑总是精确地通过代码表示**。不管需求多么复杂，这些需求总会在代码中出现。

而用LLM做的功能，不管写什么需求、是什么领域，写出来的代码是基本上都是一样的，代码本身只是个大模型API Caller，实际上的业务逻辑包含在大模型里，二者的接口是提示词。

如何编写提示词完全就是一个玄学，完全和精确、科学完全不沾边。不同的提示词就得出完全不一样的结果，甚至同一个Prompt得到的结果都不一定相同。

这种不确定性让我感觉有点不安。传统的软件即使再复杂，如果模块划分合理、测试充分，起码行为是可预测的，也总做或多或少的维护。而用大模型实现的功能，世界上没有人能直到它是怎么运行的，下次能不能用、有没有可能出什么问题，完全靠天决定。

不过AI确实解决了很多之前想都不敢想让机器解决的问题，很多问题也不需要那么精确。希望以后能找到更多大模型适用的使用场景。



0:{"buildId":"x-o6oom0-eYUQFwPypfzU","rsc":["$","$1","c",{"children":[["$","article",null,{"children":[["$","div",null,{"className":"bg-neutral px-4 py-8","children":["$","div",null,{"className":"max-w-7xl mx-auto min-h-[256px] flex justify-center text-center text-neutral-content","children":["$","div",null,{"className":"flex flex-col justify-center animate-slide-up","children":[["$","h1",null,{"className":"text-4xl my-2","children":"用大模型总结文章：效果很好，但是玄学"}],["$","$L2",null,{"className":"justify-center","articleId":"summarize-article-by-llm-inference","info":{"content":"$3","title":"用大模型总结文章：效果很好，但是玄学","date":"2025-02-14 23:54","id":"summarize-article-by-llm-inference","lang":"cn","tags":["blog"],"related":["ai-article-summary"],"wordCount":3388,"readingTime":16.94,"filePath":"contents/20250214-summarize-article-by-llm-inference/cn.md","summary":{"articleId":"summarize-article-by-llm-inference","lang":"cn","hash":"124691cabfe1f0e265a63a09e09670c92e20e069119d47c5038f85759636dd60","summaries":[{"summaries":["作者去年为博客添加AI摘要功能时，发现Azure AI语言服务处理中文效果欠佳，生成内容存在语句不通、格式错误等问题。近期改用Azure平台部署的DeepSeek R1模型后，通过优化提示词成功获得高质量摘要。尝试本地部署8B小模型时，效果不稳定且难以控制输出格式。对比发现大模型服务显著优于传统方案，但基于提示词的业务逻辑存在不确定性。文章揭示了AI应用中模型选择与工程实践的平衡难题，既肯定技术突破也表达对不可控性的隐忧。"],"metadata":{"summarizer":"azure-ai","model":"deepseek-r1"},"endTime":"2025-03-08T06:54:56.079Z","startTime":"2025-03-08T06:54:37.549Z"},{"summaries":["# 追寻可控的大模型调用：从LLM应用到业务逻辑建模\n\n在这次尝试中，我深刻体会到了使用大语言模型（LLM）开发功能的特殊性。传统的软件工程中，代码是对业务逻辑精确且确定性的表示，而LLM开发则呈现出一个完全不同的范式。\n\n## 1. LL M功能实现的玄学特性\n- **提示词为核心**：功能实现依赖于提示词设计。不同的提示词可能导致相同输入下不同的输出，甚至同一个提示词也可能生成多次不同的结果。\n- **不可预测性**：大模型对输入的解读和处理过程复杂且深层，输出往往具有不确定性，难以通过代码逻辑完全控制。\n\n## 2. 软件工程与LLM开发的异同\n- **传统软件逻辑**：业务逻辑明确、可控，模块划分清晰，测试可预测。\n- **LLM开发逻辑**：功能实现依赖于大模型的理解和生成能力，代码主要起到调用和结构化的作用。\n\n## 3. 处理不确定性与挑战\n- **适用场景选择**：在需要高度定制或精确控制的业务场景中，LLM可能不是最优选择。\n- **模型管理难题**：大模型的过大的计算需求和资源消耗，对硬件配置提出了较高要求。\n\n## 4. 对未来的思考\n尽管LLM在解决复杂问题方面展现出独特优势，但其不可控性仍然是一个主要挑战。未来需要在更精准的提示词设计、模型选择以及结果处理流程上寻找突破，才能真正将大语言模型应用于实际业务中。\n\n## 5. 结论\n这次体验让我认识到：在使用大语言模型时，不仅要理解其潜力和局限，更需要建立从需求到实现的全流程管理机制，以应对其不可预测性带来的挑战。"],"metadata":{"summarizer":"ollama","model":"deepseek-r1:8b"},"endTime":"2025-03-08T06:55:53.581Z","startTime":"2025-03-08T06:54:56.080Z"},{"summaries":["本文介绍了作者尝试使用Azure AI部署的DeepSeek R1模型，对自己博客上的文章进行总结，并得到了非常好的效果。本地跑一个8B版本的R1模型也取得了较好的效果，但存在不确定性，生成多时有可能出现不听话的情况。"],"metadata":{"summarizer":"ollama","model":"llamafamily/llama3-chinese-8b-instruct"},"endTime":"2025-03-08T06:56:03.053Z","startTime":"2025-03-08T06:54:56.080Z"}]}},"langVersions":["cn"]}]]}]}]}],"$L4"]}],["$L5","$L6","$L7","$L8","$L9","$La"],"$Lb"]}],"loading":null,"isPartial":false}
e:T4df,M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z4:["$","div",null,{"className":"animate-slide-up","children":[["$","div",null,{"className":"max-w-7xl mx-auto p-4","children":["$","div",null,{"className":"flex flex-row space-x-4","children":[["$","div",null,{"className":"prose max-w-full lg:w-[75%]","children":[["$","$Lc",null,{"summaries":[{"metadata":{"summarizer":"azure-ai","model":"deepseek-r1"},"children":[["$","p","p-0",{"children":"作者去年为博客添加AI摘要功能时，发现Azure AI语言服务处理中文效果欠佳，生成内容存在语句不通、格式错误等问题。近期改用Azure平台部署的DeepSeek R1模型后，通过优化提示词成功获得高质量摘要。尝试本地部署8B小模型时，效果不稳定且难以控制输出格式。对比发现大模型服务显著优于传统方案，但基于提示词的业务逻辑存在不确定性。文章揭示了AI应用中模型选择与工程实践的平衡难题，既肯定技术突破也表达对不可控性的隐忧。"}]]},{"metadata":{"summarizer":"ollama","model":"deepseek-r1:8b"},"children":[["$","h1","h1-0",{"children":"追寻可控的大模型调用：从LLM应用到业务逻辑建模"}],"\n",["$","p","p-0",{"children":"在这次尝试中，我深刻体会到了使用大语言模型（LLM）开发功能的特殊性。传统的软件工程中，代码是对业务逻辑精确且确定性的表示，而LLM开发则呈现出一个完全不同的范式。"}],"\n",["$","h2","h2-0",{"children":"1. LL M功能实现的玄学特性"}],"\n",["$","ul","ul-0",{"children":["\n",["$","li","li-0",{"children":[["$","strong","strong-0",{"children":"提示词为核心"}],"：功能实现依赖于提示词设计。不同的提示词可能导致相同输入下不同的输出，甚至同一个提示词也可能生成多次不同的结果。"]}],"\n",["$","li","li-1",{"children":[["$","strong","strong-0",{"children":"不可预测性"}],"：大模型对输入的解读和处理过程复杂且深层，输出往往具有不确定性，难以通过代码逻辑完全控制。"]}],"\n"]}],"\n",["$","h2","h2-1",{"children":"2. 软件工程与LLM开发的异同"}],"\n",["$","ul","ul-1",{"children":["\n",["$","li","li-0",{"children":[["$","strong","strong-0",{"children":"传统软件逻辑"}],"：业务逻辑明确、可控，模块划分清晰，测试可预测。"]}],"\n",["$","li","li-1",{"children":[["$","strong","strong-0",{"children":"LLM开发逻辑"}],"：功能实现依赖于大模型的理解和生成能力，代码主要起到调用和结构化的作用。"]}],"\n"]}],"\n",["$","h2","h2-2",{"children":"3. 处理不确定性与挑战"}],"\n",["$","ul","ul-2",{"children":["\n",["$","li","li-0",{"children":[["$","strong","strong-0",{"children":"适用场景选择"}],"：在需要高度定制或精确控制的业务场景中，LLM可能不是最优选择。"]}],"\n",["$","li","li-1",{"children":[["$","strong","strong-0",{"children":"模型管理难题"}],"：大模型的过大的计算需求和资源消耗，对硬件配置提出了较高要求。"]}],"\n"]}],"\n",["$","h2","h2-3",{"children":"4. 对未来的思考"}],"\n",["$","p","p-1",{"children":"尽管LLM在解决复杂问题方面展现出独特优势，但其不可控性仍然是一个主要挑战。未来需要在更精准的提示词设计、模型选择以及结果处理流程上寻找突破，才能真正将大语言模型应用于实际业务中。"}],"\n",["$","h2","h2-4",{"children":"5. 结论"}],"\n",["$","p","p-2",{"children":"这次体验让我认识到：在使用大语言模型时，不仅要理解其潜力和局限，更需要建立从需求到实现的全流程管理机制，以应对其不可预测性带来的挑战。"}]]},{"metadata":{"summarizer":"ollama","model":"llamafamily/llama3-chinese-8b-instruct"},"children":[["$","p","p-0",{"children":"本文介绍了作者尝试使用Azure AI部署的DeepSeek R1模型，对自己博客上的文章进行总结，并得到了非常好的效果。本地跑一个8B版本的R1模型也取得了较好的效果，但存在不确定性，生成多时有可能出现不听话的情况。"}]]}]}],["$","$Ld",null,{"withCaption":true,"id":"summarize-article-by-llm-inference","children":[["$","h1","h1-0",{"id":"azure-ai-language-service的结果太差了","children":[["$","a","azure-ai-language-service的结果太差了",{"href":"#azure-ai-language-service的结果太差了","className":"mr-1","children":["$","svg",null,{"stroke":"currentColor","fill":"currentColor","strokeWidth":"0","viewBox":"0 0 512 512","className":"inline-block opacity-20 hover:opacity-60","children":["$undefined",[["$","path","0",{"d":"$e","children":[]}]]],"style":{},"height":16,"width":16,"xmlns":"http://www.w3.org/2000/svg"}]}],"Azure AI Language Service的结果太差了"]}],"\n","$Lf","\n","$L10","\n","$L11","\n","$L12","\n","$L13","\n","$L14","\n","$L15","\n","$L16","\n","$L17","\n","$L18","\n","$L19","\n","$L1a","\n","$L1b","\n","$L1c","\n","$L1d","\n","$L1e","\n","$L1f","\n","$L20","\n","$L21","\n","$L22","\n","$L23","\n","$L24","\n","$L25","\n","$L26","\n","$L27","\n","$L28","\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","$L29","\n","$L2a","\n","$L2b","\n","$L2c","\n","$L2d","\n","$L2e","\n","$L2f","\n","$L30","\n","$L31","\n","$L32","\n","$L33","\n","$L34","\n","$L35","\n","$L36","\n","$L37","\n","$L38","\n","$L39","\n","$L3a","\n","$L3b","\n","$L3c","\n","$L3d","\n","$L3e","\n","$L3f","\n","$L40","\n","$L41"]}]]}],"$L42"]}]}],"$L43","$L44"]}]
5:["$","link","0",{"rel":"stylesheet","href":"/_next/static/chunks/44d2e091595b3eca.css","precedence":"next"}]
6:["$","link","1",{"rel":"stylesheet","href":"/_next/static/chunks/5e55d74f3211c796.css","precedence":"next"}]
7:["$","link","2",{"rel":"stylesheet","href":"/_next/static/chunks/b59bad6ea4f112f2.css","precedence":"next"}]
8:["$","script","script-0",{"src":"/_next/static/chunks/0a1497ca0a1721ad.js","async":true}]
9:["$","script","script-1",{"src":"/_next/static/chunks/4ec1bf7a32b70f87.js","async":true}]
a:["$","script","script-2",{"src":"/_next/static/chunks/276b22541034e0ea.js","async":true}]
b:["$","$L45",null,{"children":["$","$46",null,{"name":"Next.MetadataOutlet","children":"$@47"}]}]
f:["$","p","p-0",{"children":["去年我给我的文章增加了AI文章总结功能。在",["$","a","a-0",{"href":"/articles/ai-article-summary","children":"介绍此功能的文章"}],"，我提到当时这个功能是通过",["$","a","a-1",{"href":"https://learn.microsoft.com/en-us/azure/ai-services/language-service/summarization/overview?tabs=text-summarization","children":"Azure AI Language Service Text Summarization"}],"的功能实现的。"]}]
10:["$","p","p-1",{"children":"当时我已经发现，这个功能在英文文章上效果还行，但是在中文文章上就基本不可用。"}]
11:["$","p","p-2",{"children":["比如，上一篇文章",["$","a","a-0",{"href":"/articles/summary-for-2024","children":"2024年总结"}],"的总结结果是："]}]
12:["$","blockquote","blockquote-0",{"children":["\n",["$","p","p-0",{"children":"本文讲述了作者在毕业后的第一年,通过深入体验现有生活,旅游,搬家,工作和生活。"}],"\n"]}]
13:["$","p","p-3",{"children":["$","$L48","img-0",{"src":"/articles/asset/contents/20250214-summarize-article-by-llm-inference/what.png","imageSize":{"height":316,"width":443},"imageProps":{"src":"./what.png","alt":"这写的是啥？"}}]}]
14:["$","p","p-4",{"children":"这是人话吗？且不说用的英文逗号，前两个分句看着还行，后面就变成关键词的叠加，完全没有概括意思。"}]
15:["$","p","p-5",{"children":"一年过去了，DeepSeek全球爆火，而我又想起了这个问题，又重新尝试了用原有的方案生成概括，结果差不多，仍然不可用。"}]
16:["$","p","p-6",{"children":["$","strong","strong-0",{"children":"拜托，随便一个大模型都应该比这个好吧！"}]}]
17:["$","p","p-7",{"children":"去研究了一下此功能的文档，发现文档上完全没有这个功能的任何细节信息，没说用的什么模型、什么Prompt，也不让用户自己定义模型。一年过去了，功能效果丝毫没有改进，似乎像是被放弃了。说得通，毕竟是微软。"}]
49:T4df,M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z18:["$","h1","h1-1",{"id":"用azure-ai部署的deepseek-r1总结文章","children":[["$","a","用azure-ai部署的deepseek-r1总结文章",{"href":"#用azure-ai部署的deepseek-r1总结文章","className":"mr-1","children":["$","svg",null,{"stroke":"currentColor","fill":"currentColor","strokeWidth":"0","viewBox":"0 0 512 512","className":"inline-block opacity-20 hover:opacity-60","children":["$undefined",[["$","path","0",{"d":"$49","children":[]}]]],"style":{},"height":16,"width":16,"xmlns":"http://www.w3.org/2000/svg"}]}],"用Azure AI部署的DeepSeek R1总结文章"]}]
19:["$","p","p-8",{"children":"实话说，我很少直接和大模型聊天。我使用AI基本只有让Copilot回答编程问题以及生成代码，在编程场景之外我基本完全不用AI，所以也一直不知道怎么把AI应用到我自己的工作和生活流中。我的工作也和AI毫无关系，即使公司策略是All in AI，但是我组仍然和AI似乎扯不上边。"}]
1a:["$","p","p-9",{"children":"而此时，需求终于来了，为何不让大模型帮我总结文章？"}]
1b:["$","p","p-10",{"children":[["$","a","a-0",{"href":"https://ai.azure.com","children":"Azure AI"}],"是一个微软做的Model as a service平台，可以直接在上面部署、使用、微调模型，不需要自己管理基础设施。DeepSeek R1模型发布后没几天，Azure AI可以直接就支持了部署（",["$","a","a-1",{"href":"https://azure.microsoft.com/en-us/blog/deepseek-r1-is-now-available-on-azure-ai-foundry-and-github/","children":"公告"}],"），甚至没有价格表，意思是：",["$","strong","strong-0",{"children":"它是免费的？"}]]}]
1c:["$","p","p-11",{"children":"我立刻去Azure AI上注册了Project，部署了DeepSeek R1。"}]
1d:["$","p","p-12",{"children":"用Azure AI部署模型非常方便："}]
1e:["$","ol","ol-0",{"children":["\n",["$","li","li-0",{"children":"注册好Project"}],"\n",["$","li","li-1",{"children":"进入模型市场，选择DeepSeek R1，填一个Deployment Name，部署"}],"\n",["$","li","li-2",{"children":["然后拿着Azure AI Endpoint, API Key以及这个Deployment Name，根据",["$","a","a-0",{"href":"https://learn.microsoft.com/en-us/azure/ai-foundry/model-inference/concepts/endpoints?tabs=javascript#routing","children":"文档"}],"安装调用TS SDK"]}],"\n",["$","li","li-3",{"children":"设计一个Prompt"}],"\n",["$","li","li-4",{"children":"调用SDK"}],"\n"]}]
1f:["$","p","p-13",{"children":["$","$L48","img-0",{"src":"/articles/asset/contents/20250214-summarize-article-by-llm-inference/deploy-model.png","imageSize":{"height":885,"width":1515},"imageProps":{"src":"./deploy-model.png","alt":"点点就能部署模型"}}]}]
20:["$","p","p-14",{"children":"Prompt我随便想了一个："}]
21:["$","blockquote","blockquote-1",{"children":["\n",["$","p","p-0",{"children":"Summarize the article in the next message in language ${languageCode} in 100 words. Return the result in plain text format, without any other information."}],"\n"]}]
22:["$","p","p-15",{"children":"其中包含三个消息："}]
23:["$","ol","ol-1",{"children":["\n",["$","li","li-0",{"children":["语言是",["$","span","span-0",{"data-rehype-pretty-code-figure":"","children":["$","code","code-0",{"data-language":"ts","data-theme":"one-dark-pro","style":{"backgroundColor":"#282c34","color":"#abb2bf"},"children":["$","span","span-0",{"data-line":"","children":[["$","span","span-0",{"style":{"color":"#E06C75"},"children":"$$"}],["$","span","span-1",{"style":{"color":"#ABB2BF"},"children":"{"}],["$","span","span-2",{"style":{"color":"#E06C75"},"children":"languageCode"}],["$","span","span-3",{"style":{"color":"#ABB2BF"},"children":"}"}]]}]}]}],"，这是文章的语言参数（",["$","code","code-0",{"children":"cn"}],", ",["$","code","code-1",{"children":"en"}],"），这样文章的总结和文章本身的语言一致"]}],"\n",["$","li","li-1",{"children":"要求返回纯文本信息，不包含markdown"}],"\n",["$","li","li-2",{"children":"100字左右"}],"\n"]}]
24:["$","p","p-16",{"children":["另外，R1模型总是会返回思考过程，思考过程用",["$","code","code-0",{"children":"<think>"}],"标签包裹，所以还需要在结果中把",["$","code","code-1",{"children":"<think>"}],"中去除。"]}]
25:["$","p","p-17",{"children":["然后我立刻把",["$","a","a-0",{"href":"/articles/summary-for-2024","children":"2024年总结"}],"扔给AI，很快就拿到了结果："]}]
26:["$","blockquote","blockquote-2",{"children":["\n",["$","p","p-0",{"children":"作者回顾毕业一年后生活，探讨如何在最佳年龄充分体验当下。通过密集旅行与亲友刷新地图边界，感受陪伴的意义；开启独居生活后在郊区保租房打造个人空间，享受烹饪与自由。工作方面身处技术运维\"小而美\"团队，虽遇职业发展隐忧但珍惜当前性价比高的稳定状态。面对年龄增长带来的体能下降与生活抉择困惑，既珍视现有平衡又焦虑是否该打破舒适区。最终秉持认同感驱动原则，既保持现状又在游戏启发中思考：是继续深耕现有生活，还是用黄金年龄冒险转型，答案留待明年揭晓。"}],"\n"]}]
27:["$","p","p-18",{"children":"哇！这效果真不错啊，句子比我自己写得工整多了！"}]
28:["$","p","p-19",{"children":"于是，我将脚本应用到博客中的所有文章，基本上所有文章都获得了极好的效果。这里给出几个例子："}]
29:["$","table","table-0",{"children":[["$","thead","thead-0",{"children":["$","tr","tr-0",{"children":[["$","th","th-0",{"children":"文章"}],["$","th","th-1",{"children":"原总结"}],["$","th","th-2",{"children":"现总结"}]]}]}],["$","tbody","tbody-0",{"children":[["$","tr","tr-0",{"children":[["$","td","td-0",{"children":["$","a","a-0",{"href":"/articles/a-change-of-environment-in-seattle","children":"在西雅图，给生活换个环境"}]}],["$","td","td-1",{"children":"本文描述了作者在参加微软的Aspire Start Strong+活动时,感受到了全新的生活环境和社交元素。"}],["$","td","td-2",{"children":"作者参与微软组织的Aspire Start Strong+活动，赴美体验全新生活节奏以缓解职场单调感。西雅图市区高楼林立却人流稀少，郊区以分散式城市结构为主，无车出行困难。活动中高强度社交贯穿全程，跨文化交流时语言障碍明显，英语听说能力面临实战考验。与全球同龄校招生互动后，作者反思环境对人际关系的影响：校园阶段共同目标易建立联结，职场后各自生活轨迹差异导致社交需求转变。短暂六天打破常规，接触多元文化，更深刻思考个人追求与环境的关系。"}]]}],["$","tr","tr-1",{"children":[["$","td","td-0",{"children":["$","a","a-0",{"href":"/articles/support-sqlserver-in-wakapi","children":"从调库到翻源代码：给wakapi增加SQL Server支持"}]}],["$","td","td-1",{"children":["本文作者在上一篇文章中提到了如何为博客增加点击量监测,并部署到Azure。 后来,同学推荐了wakapi项目,重新实现了wakatime的后端API。 作者发现wakapi并没有原生支持SQL Server,但使用了gorm作为数据库访问框架。 作者通过重用Dialector的逻辑,为关键词加上引号,把同一个go类型在不同的数据库中映射为不同的列类型,以及使用",["$","code","code-0",{"children":"merge into"}],"语句来模拟upsert的行为。 他认为go非常explicit,虽然他不喜欢它,但它非常简单。 解决这些问题后,PR顺利合并进了主分支。"]}],["$","td","td-2",{"children":"作者在尝试将Wakapi项目迁移至SQL Server时，遇到一系列数据库适配问题。包括SQL语法差异、ORM框架配置、外键约束冲突及GORM库的Upsert功能缺陷。通过修改原生SQL语句、动态调整时间字段类型映射、重构外键关系、手动处理唯一索引冲突，最终解决兼容性问题并成功合并代码。此次实践深入了解了SQL Server特性与GORM内部机制，验证了通过实际项目攻坚学习技术的有效性。"}]]}],["$","tr","tr-2",{"children":[["$","td","td-0",{"children":["$","a","a-0",{"href":"/articles/a-kotlin-di-framework-in-50-lines-and-thoughts-on-kotlin","children":"A Kotlin DI Framework in 50 Lines and Thoughts on Kotlin"}]}],["$","td","td-1",{"children":"The document discusses the challenges and benefits of using a Dependency Injection (DI) framework in a Java project. It highlights the two main options for dependency management: introducing a full-blown DI framework or using traditional object instantiation or simple factory pattern, which can be time-consuming and cumbersome. The author uses the example of a simple Java project where the interface and implementation class pattern was used to decouple the interface and implementation, but it also introduced complexity. The document suggests using delegation and classpath scan capability to achieve minimal dependencies and extra code, and provides a code example to help understand the process."}],["$","td","td-2",{"children":["The article discusses choosing dependency injection (DI) for small projects, comparing full DI frameworks (verbose) versus factory patterns (clumsy). The author developed a lightweight DI solution using Kotlin’s delegation and classgraph for scanning. Annotations (@Service, @ServiceImpl) mark interfaces and implementations, while a ",["$","code","code-0",{"children":"di()"}]," function delegates dependency resolution, enabling singleton injection with minimal code. Benefits include simplicity, circular dependency support, and dynamic resolution, though limitations include no ",["$","code","code-1",{"children":"init"}]," block usage and lack of advanced features. The author praises Kotlin’s modern features (null checks, lambdas) and how diverse programming paradigms expand problem-solving approaches, emphasizing tools’ influence on design thinking."]}]]}]]}]]}]
4a:T4df,M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z2a:["$","h1","h1-2",{"id":"本地模型的效果比较玄学","children":[["$","a","本地模型的效果比较玄学",{"href":"#本地模型的效果比较玄学","className":"mr-1","children":["$","svg",null,{"stroke":"currentColor","fill":"currentColor","strokeWidth":"0","viewBox":"0 0 512 512","className":"inline-block opacity-20 hover:opacity-60","children":["$undefined",[["$","path","0",{"d":"$4a","children":[]}]]],"style":{},"height":16,"width":16,"xmlns":"http://www.w3.org/2000/svg"}]}],"本地模型的效果比较玄学"]}]
2b:["$","p","p-20",{"children":"本来这篇文章到这里就该结束了，可是写到第一段的时候，突然想到："}]
2c:["$","blockquote","blockquote-3",{"children":["\n",["$","p","p-0",{"children":"随便一个大模型都应该比这个好吧！"}],"\n"]}]
2d:["$","p","p-21",{"children":"那……我本地跑一个呢？"}]
2e:["$","p","p-22",{"children":["我的台式机是3070，一搜得知这个显卡最大可以装DeepSeek R1 8B版本。于是赶紧打开许久没有打开的Ollama，拉下",["$","code","code-0",{"children":"deepseek-r1:8b"}]]}]
2f:["$","figure","figure-0",{"data-rehype-pretty-code-figure":"","children":["$","pre","pre-0",{"style":{"backgroundColor":"#282c34","color":"#abb2bf"},"tabIndex":0,"data-language":"bash","data-theme":"one-dark-pro","children":["$","code","code-0",{"data-language":"bash","data-theme":"one-dark-pro","style":{"display":"grid"},"children":["$","span","span-0",{"data-line":"","children":[["$","span","span-0",{"style":{"color":"#61AFEF"},"children":"ollama"}],["$","span","span-1",{"style":{"color":"#98C379"},"children":" pull"}],["$","span","span-2",{"style":{"color":"#98C379"},"children":" deepseek-r1:8b"}]]}]}]}]}]
30:["$","p","p-23",{"children":["Windows版本的Ollama会在本地",["$","code","code-0",{"children":"11434"}],"端口启动Ollama的API（",["$","a","a-0",{"href":"https://github.com/ollama/ollama/blob/main/docs/api.md#list-running-models","children":"定义"}],"），而由于我们是用的JS，Ollama单独出了",["$","a","a-1",{"href":"https://github.com/ollama/ollama-js","children":"ollama-js"}]," SDK，用起来更简单。"]}]
31:["$","p","p-24",{"children":["我直接",["$","span","span-0",{"data-rehype-pretty-code-figure":"","children":["$","code","code-0",{"data-language":"bash","data-theme":"one-dark-pro","style":{"backgroundColor":"#282c34","color":"#abb2bf"},"children":["$","span","span-0",{"data-line":"","children":[["$","span","span-0",{"style":{"color":"#61AFEF"},"children":"pnpm"}],["$","span","span-1",{"style":{"color":"#98C379"},"children":" i"}],["$","span","span-2",{"style":{"color":"#D19A66"},"children":" -D"}],["$","span","span-3",{"style":{"color":"#98C379"},"children":" ollama"}]]}]}]}],"，学习了ollama的SDK的使用，直接把给完整版R1用的Prompt发给R1 8B，拿到以下结果："]}]
32:["$","blockquote","blockquote-4",{"children":["\n",["$","p","p-0",{"children":["这篇文章通过作者的个人经历和思考，探讨了在“最好的年龄”该如何度过这一主题。作者从20多岁进入巅峰年龄开始，经历了身体素质逐渐下降、工作环境变化以及面对各种选择的内心挣扎。\\n\\n### 主要内容总结：\\n1. ",["$","strong","strong-0",{"children":"身体与年龄的关系"}],"：作者承认随着年龄增长，身体素质逐渐不如从前，尤其是到了“下半场”，这可能对日常生活和工作产生影响。\\n   \\n2. ",["$","strong","strong-1",{"children":"工作环境与不确定性"}],"：虽然选择了一家外企，因为其稳定性和良好的发展机会，但半年后发现公司结构频繁调整，高层变动较大，这让他对未来充满担忧。\\n\\n3. ",["$","strong","strong-2",{"children":"面对选择的内心挣扎"}],"：\\n   - ",["$","strong","strong-3",{"children":"职业与生活的平衡"}],"：作者更倾向于保持现状，尤其是对稳定工作的认可和对外资企业组织结构和晋升路线的信任。\\n   - ",["$","strong","strong-4",{"children":"物质与生活的影响"}],"：虽然对大城市有向往，但也清楚地认识到当前平淡的生活状态的珍贵，不愿为了追求新潮而放弃现有的优秀工作。\\n\\n4. ",["$","strong","strong-5",{"children":"游戏中的价值观"}],"：通过《沙石镇时光》这款游戏，作者找到了认同感和热爱一件有意义的事的精神状态，这成为他生活中重要的支撑力量。\\n\\n### 总结：\\n文章表达了作者在成熟与不稳定之间的平衡问题上缺乏明确答案，内心对现状的满意与对变化的恐惧之间的矛盾。尽管没有给出明确的选择建议，但通过个人经历和情感描写，揭示了在最佳年龄如何度过这一哲学性问题，鼓励读者反思自己的生活态度和价值观选择。\\n\\n文章语言流畅，情感真挚，通过对工作、生活和游戏的多角度描述，展现了作者内心的复杂性和对未来的不确定性。"]}],"\n"]}]
33:["$","p","p-25",{"children":"嗯？这个模型怎么不听话？这个Prompt提到的三点（语言、字数、格式），字数和格式的要求根本没有满足！"}]
34:["$","blockquote","blockquote-5",{"children":["\n",["$","p","p-0",{"children":"Summarize the article in the next message in language ${languageCode} in 100 words. Return the result in plain text format, without any other information."}],"\n"]}]
35:["$","p","p-26",{"children":"我试了很多次prompt，仍然没找到什么方法能够让它同时满足这三个需求。同一个提示词，有时候能生成不含markdown的文本，有时候生成又包含；文字字数的限制也是不一定生效。试了多次也没获得好的结果。"}]
36:["$","p","p-27",{"children":["除了DeepSeek R1 8B，同时还试了",["$","a","a-0",{"href":"https://ollama.com/llamafamily/llama3-chinese-8b-instruct","children":"llamafamily/llama3-chinese-8b-instruct"}],"，而这个模型的效果就好一些，但是生成多了也会出现不听话等问题。"]}]
37:["$","blockquote","blockquote-6",{"children":["\n",["$","p","p-0",{"children":"本文讲述了一名25岁男青年在他的第二十年代度过的时间，他在这段时期里，选择了深入体验现有的生活，在旅游和工作方面都有所变化。他认为这个阶段是他的成长期，是他开始独立生活、选择自己喜欢的事物，并且接受不确定性的阶段。在文章中，他对未来充满了想法和担忧，但最终还是无法预测。"}],"\n"]}]
38:["$","p","p-28",{"children":"小模型的效果确实和大模型没法比，而不同小模型的精调不一致，效果也差别很大。"}]
39:["$","p","p-29",{"children":"推理过程中GPU计算量不大，主要是占了很多的显存。看来接下来换个16G显存的显卡，应该就可以跑更高级的模型了。"}]
3a:["$","p","p-30",{"children":["$","$L48","img-0",{"src":"/articles/asset/contents/20250214-summarize-article-by-llm-inference/r1-8b.png","imageSize":{"height":550,"width":762},"imageProps":{"src":"r1-8b.png","alt":"运行推理过程的GPU占用"}}]}]
4b:T4df,M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z3b:["$","h1","h1-3",{"id":"代码不是业务逻辑而是大模型调用脚本","children":[["$","a","代码不是业务逻辑而是大模型调用脚本",{"href":"#代码不是业务逻辑而是大模型调用脚本","className":"mr-1","children":["$","svg",null,{"stroke":"currentColor","fill":"currentColor","strokeWidth":"0","viewBox":"0 0 512 512","className":"inline-block opacity-20 hover:opacity-60","children":["$undefined",[["$","path","0",{"d":"$4b","children":[]}]]],"style":{},"height":16,"width":16,"xmlns":"http://www.w3.org/2000/svg"}]}],"代码不是业务逻辑，而是大模型调用脚本"]}]
3c:["$","p","p-31",{"children":"这次体验让我认识到一点，用LLM写功能的流程和传统的软件工程完全不同："}]
3d:["$","p","p-32",{"children":["在传统软件中，",["$","strong","strong-0",{"children":"业务逻辑总是精确地通过代码表示"}],"。不管需求多么复杂，这些需求总会在代码中出现。"]}]
3e:["$","p","p-33",{"children":"而用LLM做的功能，不管写什么需求、是什么领域，写出来的代码是基本上都是一样的，代码本身只是个大模型API Caller，实际上的业务逻辑包含在大模型里，二者的接口是提示词。"}]
3f:["$","p","p-34",{"children":"如何编写提示词完全就是一个玄学，完全和精确、科学完全不沾边。不同的提示词就得出完全不一样的结果，甚至同一个Prompt得到的结果都不一定相同。"}]
40:["$","p","p-35",{"children":"这种不确定性让我感觉有点不安。传统的软件即使再复杂，如果模块划分合理、测试充分，起码行为是可预测的，也总做或多或少的维护。而用大模型实现的功能，世界上没有人能直到它是怎么运行的，下次能不能用、有没有可能出什么问题，完全靠天决定。"}]
41:["$","p","p-36",{"children":"不过AI确实解决了很多之前想都不敢想让机器解决的问题，很多问题也不需要那么精确。希望以后能找到更多大模型适用的使用场景。"}]
42:["$","div",null,{"className":"hidden lg:block lg:w-[25%]","children":["$","$L4c",null,{"toc":[{"depth":1,"value":"Azure AI Language Service的结果太差了","id":"azure-ai-language-service的结果太差了"},{"depth":1,"value":"用Azure AI部署的DeepSeek R1总结文章","id":"用azure-ai部署的deepseek-r1总结文章"},{"depth":1,"value":"本地模型的效果比较玄学","id":"本地模型的效果比较玄学"},{"depth":1,"value":"代码不是业务逻辑，而是大模型调用脚本","id":"代码不是业务逻辑而是大模型调用脚本"}],"hasSummary":true}]}]
43:["$","div",null,{"className":"max-w-7xl mx-auto p-4","children":["$","$L4d",null,{"relatedArticles":[{"id":"ai-article-summary","langVersions":[{"excerpt":"\n# 一条朋友圈的提示\n\n当昨天的[2023年总结](/articles/summary-for-2023)发出后，朋友圈有人对文章做出了总结，这启发了我，何不自己用AI给文章加个总结功能呢？正好也是","lang":"cn","time":"2024-01-01 10:20:00 UTC+8","title":"博客集成AI文章总结功能"}]}]}]}]
44:["$","div",null,{"className":"max-w-7xl mx-auto p-4","children":["$","$L4e",null,{"articleId":"summarize-article-by-llm-inference","articleTitle":"用大模型总结文章：效果很好，但是玄学"}]}]
47:null

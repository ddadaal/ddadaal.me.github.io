<!DOCTYPE html><!--aOy5JX6Q5NHJv_y8DZ933--><html lang="zh-CN" class="scroll-smooth"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/chunks/a705e43fee9b0e0d.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/chunks/44d2e091595b3eca.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/chunks/5e55d74f3211c796.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/chunks/b59bad6ea4f112f2.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/56e7209dcf17c86b.js"/><script src="/_next/static/chunks/ef7d1ff3e850aaf7.js" async=""></script><script src="/_next/static/chunks/e5b2def022ec07d6.js" async=""></script><script src="/_next/static/chunks/45a12d6e0f51d3c5.js" async=""></script><script src="/_next/static/chunks/turbopack-4426406ad0fbf8ee.js" async=""></script><script src="/_next/static/chunks/2caa33a942c5f527.js" async=""></script><script src="/_next/static/chunks/59983278a34fd25c.js" async=""></script><script src="/_next/static/chunks/8d29a04bcfe27c24.js" async=""></script><script src="/_next/static/chunks/3dff3d4c63cf346e.js" async=""></script><script src="/_next/static/chunks/b3af52d5d180873a.js" async=""></script><script src="/_next/static/chunks/86b442c1397f7351.js" async=""></script><script src="/_next/static/chunks/0a1497ca0a1721ad.js" async=""></script><script src="/_next/static/chunks/4ec1bf7a32b70f87.js" async=""></script><script src="/_next/static/chunks/276b22541034e0ea.js" async=""></script><link rel="preload" href="https://services.ddadaal.me/monitor/script.js" as="script"/><title>可划分显存 != 统一内存：AI Max+ 395 64G AI推理性能 - ddadaal.me</title><meta name="description" content="ddadaal&#x27;s personal website"/><link rel="manifest" href="/site.webmanifest"/><link rel="icon" href="/favicon.ico?favicon.3d1adb1d.ico" sizes="48x48" type="image/x-icon"/><link rel="icon" href="/icon.svg?icon.443451fa.svg" sizes="any" type="image/svg+xml"/><link rel="apple-touch-icon" href="/apple-icon.png?apple-icon.01036b81.png" sizes="180x180" type="image/png"/><script src="/_next/static/chunks/a6dad97d9634a72d.js" noModule=""></script></head><body class="w-full"><div hidden=""><!--$--><!--/$--></div><div class="flex items-center sticky z-50 w-full h-13 transition -top-[1px] bg-base-200 text-base-content"><div class="flex w-full justify-between items-center max-w-7xl mx-auto px-4"><a class="flex items-center justify-center space-x-1" href="/"><img alt="logo" loading="lazy" width="42" height="42" decoding="async" data-nimg="1" style="color:transparent" src="/_next/static/media/logo.5e47eabf.svg"/><h1 class="text-sm font-bold">ddadaal.me</h1></a><div class="flex items-center gap-1"><div class="hidden lg:flex"><ul class="menu menu-horizontal"><li><a class="" href="/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M280.37 148.26L96 300.11V464a16 16 0 0 0 16 16l112.06-.29a16 16 0 0 0 15.92-16V368a16 16 0 0 1 16-16h64a16 16 0 0 1 16 16v95.64a16 16 0 0 0 16 16.05L464 480a16 16 0 0 0 16-16V300L295.67 148.26a12.19 12.19 0 0 0-15.3 0zM571.6 251.47L488 182.56V44.05a12 12 0 0 0-12-12h-56a12 12 0 0 0-12 12v72.61L318.47 43a48 48 0 0 0-61 0L4.34 251.47a12 12 0 0 0-1.6 16.9l25.5 31A12 12 0 0 0 45.15 301l235.22-193.74a12.19 12.19 0 0 1 15.3 0L530.9 301a12 12 0 0 0 16.9-1.6l25.5-31a12 12 0 0 0-1.7-16.93z"></path></svg>主页</a></li><li><a class="active" href="/articles"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M542.22 32.05c-54.8 3.11-163.72 14.43-230.96 55.59-4.64 2.84-7.27 7.89-7.27 13.17v363.87c0 11.55 12.63 18.85 23.28 13.49 69.18-34.82 169.23-44.32 218.7-46.92 16.89-.89 30.02-14.43 30.02-30.66V62.75c.01-17.71-15.35-31.74-33.77-30.7zM264.73 87.64C197.5 46.48 88.58 35.17 33.78 32.05 15.36 31.01 0 45.04 0 62.75V400.6c0 16.24 13.13 29.78 30.02 30.66 49.49 2.6 149.59 12.11 218.77 46.95 10.62 5.35 23.21-1.94 23.21-13.46V100.63c0-5.29-2.62-10.14-7.27-12.99z"></path></svg>文章</a></li><li><a class="" href="/sparks"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M478.21 334.093L336 256l142.21-78.093c11.795-6.477 15.961-21.384 9.232-33.037l-19.48-33.741c-6.728-11.653-21.72-15.499-33.227-8.523L296 186.718l3.475-162.204C299.763 11.061 288.937 0 275.48 0h-38.96c-13.456 0-24.283 11.061-23.994 24.514L216 186.718 77.265 102.607c-11.506-6.976-26.499-3.13-33.227 8.523l-19.48 33.741c-6.728 11.653-2.562 26.56 9.233 33.037L176 256 33.79 334.093c-11.795 6.477-15.961 21.384-9.232 33.037l19.48 33.741c6.728 11.653 21.721 15.499 33.227 8.523L216 325.282l-3.475 162.204C212.237 500.939 223.064 512 236.52 512h38.961c13.456 0 24.283-11.061 23.995-24.514L296 325.282l138.735 84.111c11.506 6.976 26.499 3.13 33.227-8.523l19.48-33.741c6.728-11.653 2.563-26.559-9.232-33.036z"></path></svg>想法</a></li><li><details><summary class=""><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 384 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M224 136V0H24C10.7 0 0 10.7 0 24v464c0 13.3 10.7 24 24 24h336c13.3 0 24-10.7 24-24V160H248c-13.2 0-24-10.8-24-24zm160-14.1v6.1H256V0h6.1c6.4 0 12.5 2.5 17 7l97.9 98c4.5 4.5 7 10.6 7 16.9z"></path></svg>简历</summary><ul class="shadow bg-base-200 text-base-content min-w-max"><li><a class="" href="/resume/cn">🇨🇳 <!-- -->简体中文</a></li><li><a class="" href="/resume/en">🇺🇸 <!-- -->English</a></li></ul></details></li><li><details><summary class=""><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 192 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M20 424.229h20V279.771H20c-11.046 0-20-8.954-20-20V212c0-11.046 8.954-20 20-20h112c11.046 0 20 8.954 20 20v212.229h20c11.046 0 20 8.954 20 20V492c0 11.046-8.954 20-20 20H20c-11.046 0-20-8.954-20-20v-47.771c0-11.046 8.954-20 20-20zM96 0C56.235 0 24 32.235 24 72s32.235 72 72 72 72-32.235 72-72S135.764 0 96 0z"></path></svg>关于</summary><ul class="shadow bg-base-200 text-base-content min-w-max"><li><a class="" href="/about/odyssey"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M542.22 32.05c-54.8 3.11-163.72 14.43-230.96 55.59-4.64 2.84-7.27 7.89-7.27 13.17v363.87c0 11.55 12.63 18.85 23.28 13.49 69.18-34.82 169.23-44.32 218.7-46.92 16.89-.89 30.02-14.43 30.02-30.66V62.75c.01-17.71-15.35-31.74-33.77-30.7zM264.73 87.64C197.5 46.48 88.58 35.17 33.78 32.05 15.36 31.01 0 45.04 0 62.75V400.6c0 16.24 13.13 29.78 30.02 30.66 49.49 2.6 149.59 12.11 218.77 46.95 10.62 5.35 23.21-1.94 23.21-13.46V100.63c0-5.29-2.62-10.14-7.27-12.99z"></path></svg>一个个人博客的史诗</a></li><li><a class="" href="/about/project"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M336.5 160C322 70.7 287.8 8 248 8s-74 62.7-88.5 152h177zM152 256c0 22.2 1.2 43.5 3.3 64h185.3c2.1-20.5 3.3-41.8 3.3-64s-1.2-43.5-3.3-64H155.3c-2.1 20.5-3.3 41.8-3.3 64zm324.7-96c-28.6-67.9-86.5-120.4-158-141.6 24.4 33.8 41.2 84.7 50 141.6h108zM177.2 18.4C105.8 39.6 47.8 92.1 19.3 160h108c8.7-56.9 25.5-107.8 49.9-141.6zM487.4 192H372.7c2.1 21 3.3 42.5 3.3 64s-1.2 43-3.3 64h114.6c5.5-20.5 8.6-41.8 8.6-64s-3.1-43.5-8.5-64zM120 256c0-21.5 1.2-43 3.3-64H8.6C3.2 212.5 0 233.8 0 256s3.2 43.5 8.6 64h114.6c-2-21-3.2-42.5-3.2-64zm39.5 96c14.5 89.3 48.7 152 88.5 152s74-62.7 88.5-152h-177zm159.3 141.6c71.4-21.2 129.4-73.7 158-141.6h-108c-8.8 56.9-25.6 107.8-50 141.6zM19.3 352c28.6 67.9 86.5 120.4 158 141.6-24.4-33.8-41.2-84.7-50-141.6h-108z"></path></svg>关于网站</a></li><li><a class="" href="/about/me"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 192 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M96 0c35.346 0 64 28.654 64 64s-28.654 64-64 64-64-28.654-64-64S60.654 0 96 0m48 144h-11.36c-22.711 10.443-49.59 10.894-73.28 0H48c-26.51 0-48 21.49-48 48v136c0 13.255 10.745 24 24 24h16v136c0 13.255 10.745 24 24 24h64c13.255 0 24-10.745 24-24V352h16c13.255 0 24-10.745 24-24V192c0-26.51-21.49-48-48-48z"></path></svg>关于我</a></li></ul></details></li></ul></div><div class="dropdown dropdown-end"><label tabindex="0" class="btn"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8 256c0 136.966 111.033 248 248 248s248-111.034 248-248S392.966 8 256 8 8 119.033 8 256zm248 184V72c101.705 0 184 82.311 184 184 0 101.705-82.311 184-184 184z"></path></svg><span class="hidden sm:block">自动</span></label><ul tabindex="0" class="dropdown-content menu p-2 bg-base-200 text-base-content shadow rounded-box min-w-max"><li><a class="justify-between">自动</a></li><li><a class="justify-between">明亮</a></li><li><a class="justify-between">暗色</a></li><li><a class="justify-between">杯子蛋糕</a></li><li><a class="justify-between">大黄蜂</a></li><li><a class="justify-between">白色商务</a></li><li><a class="justify-between">黑色商务</a></li><li><a class="justify-between">金色奢华</a></li><li><a class="justify-between">夏日柠檬</a></li><li><a class="justify-between">绿野仙踪</a></li><li><a class="justify-between">复古</a></li><li><a class="justify-between">粉色浪漫</a></li><li><a class="justify-between">赛博朋克</a></li></ul></div><div class="dropdown dropdown-end"><label tabindex="0" class="btn">🇨🇳 <span class="hidden sm:block">简体中文</span></label><ul tabindex="0" class="dropdown-content menu p-2 shadow bg-base-200 rounded-box min-w-max text-base-content"><li><a class="justify-between">🇨🇳 <!-- -->简体中文</a></li><li><a class="justify-between">🇺🇸 <!-- -->English</a></li></ul></div><div class="dropdown dropdown-end lg:hidden"><label tabindex="0" class="btn btn-ghost"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M328 256c0 39.8-32.2 72-72 72s-72-32.2-72-72 32.2-72 72-72 72 32.2 72 72zm104-72c-39.8 0-72 32.2-72 72s32.2 72 72 72 72-32.2 72-72-32.2-72-72-72zm-352 0c-39.8 0-72 32.2-72 72s32.2 72 72 72 72-32.2 72-72-32.2-72-72-72z"></path></svg></label><ul tabindex="0" class="menu menu-compact dropdown-content min-w-max mt-3 p-2 shadow rounded-box bg-base-200 text-base-content"><li><a class="" href="/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M280.37 148.26L96 300.11V464a16 16 0 0 0 16 16l112.06-.29a16 16 0 0 0 15.92-16V368a16 16 0 0 1 16-16h64a16 16 0 0 1 16 16v95.64a16 16 0 0 0 16 16.05L464 480a16 16 0 0 0 16-16V300L295.67 148.26a12.19 12.19 0 0 0-15.3 0zM571.6 251.47L488 182.56V44.05a12 12 0 0 0-12-12h-56a12 12 0 0 0-12 12v72.61L318.47 43a48 48 0 0 0-61 0L4.34 251.47a12 12 0 0 0-1.6 16.9l25.5 31A12 12 0 0 0 45.15 301l235.22-193.74a12.19 12.19 0 0 1 15.3 0L530.9 301a12 12 0 0 0 16.9-1.6l25.5-31a12 12 0 0 0-1.7-16.93z"></path></svg>主页</a></li><li><a class="active" href="/articles"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M542.22 32.05c-54.8 3.11-163.72 14.43-230.96 55.59-4.64 2.84-7.27 7.89-7.27 13.17v363.87c0 11.55 12.63 18.85 23.28 13.49 69.18-34.82 169.23-44.32 218.7-46.92 16.89-.89 30.02-14.43 30.02-30.66V62.75c.01-17.71-15.35-31.74-33.77-30.7zM264.73 87.64C197.5 46.48 88.58 35.17 33.78 32.05 15.36 31.01 0 45.04 0 62.75V400.6c0 16.24 13.13 29.78 30.02 30.66 49.49 2.6 149.59 12.11 218.77 46.95 10.62 5.35 23.21-1.94 23.21-13.46V100.63c0-5.29-2.62-10.14-7.27-12.99z"></path></svg>文章</a></li><li><a class="" href="/sparks"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M478.21 334.093L336 256l142.21-78.093c11.795-6.477 15.961-21.384 9.232-33.037l-19.48-33.741c-6.728-11.653-21.72-15.499-33.227-8.523L296 186.718l3.475-162.204C299.763 11.061 288.937 0 275.48 0h-38.96c-13.456 0-24.283 11.061-23.994 24.514L216 186.718 77.265 102.607c-11.506-6.976-26.499-3.13-33.227 8.523l-19.48 33.741c-6.728 11.653-2.562 26.56 9.233 33.037L176 256 33.79 334.093c-11.795 6.477-15.961 21.384-9.232 33.037l19.48 33.741c6.728 11.653 21.721 15.499 33.227 8.523L216 325.282l-3.475 162.204C212.237 500.939 223.064 512 236.52 512h38.961c13.456 0 24.283-11.061 23.995-24.514L296 325.282l138.735 84.111c11.506 6.976 26.499 3.13 33.227-8.523l19.48-33.741c6.728-11.653 2.563-26.559-9.232-33.036z"></path></svg>想法</a></li><li><a><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 384 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M224 136V0H24C10.7 0 0 10.7 0 24v464c0 13.3 10.7 24 24 24h336c13.3 0 24-10.7 24-24V160H248c-13.2 0-24-10.8-24-24zm160-14.1v6.1H256V0h6.1c6.4 0 12.5 2.5 17 7l97.9 98c4.5 4.5 7 10.6 7 16.9z"></path></svg>简历</a><ul><li><a class="" href="/resume/cn">🇨🇳 <!-- -->简体中文</a></li><li><a class="" href="/resume/en">🇺🇸 <!-- -->English</a></li></ul></li><li><a><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 192 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M20 424.229h20V279.771H20c-11.046 0-20-8.954-20-20V212c0-11.046 8.954-20 20-20h112c11.046 0 20 8.954 20 20v212.229h20c11.046 0 20 8.954 20 20V492c0 11.046-8.954 20-20 20H20c-11.046 0-20-8.954-20-20v-47.771c0-11.046 8.954-20 20-20zM96 0C56.235 0 24 32.235 24 72s32.235 72 72 72 72-32.235 72-72S135.764 0 96 0z"></path></svg>关于</a><ul><li><a class="" href="/about/odyssey"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M542.22 32.05c-54.8 3.11-163.72 14.43-230.96 55.59-4.64 2.84-7.27 7.89-7.27 13.17v363.87c0 11.55 12.63 18.85 23.28 13.49 69.18-34.82 169.23-44.32 218.7-46.92 16.89-.89 30.02-14.43 30.02-30.66V62.75c.01-17.71-15.35-31.74-33.77-30.7zM264.73 87.64C197.5 46.48 88.58 35.17 33.78 32.05 15.36 31.01 0 45.04 0 62.75V400.6c0 16.24 13.13 29.78 30.02 30.66 49.49 2.6 149.59 12.11 218.77 46.95 10.62 5.35 23.21-1.94 23.21-13.46V100.63c0-5.29-2.62-10.14-7.27-12.99z"></path></svg>一个个人博客的史诗</a></li><li><a class="" href="/about/project"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M336.5 160C322 70.7 287.8 8 248 8s-74 62.7-88.5 152h177zM152 256c0 22.2 1.2 43.5 3.3 64h185.3c2.1-20.5 3.3-41.8 3.3-64s-1.2-43.5-3.3-64H155.3c-2.1 20.5-3.3 41.8-3.3 64zm324.7-96c-28.6-67.9-86.5-120.4-158-141.6 24.4 33.8 41.2 84.7 50 141.6h108zM177.2 18.4C105.8 39.6 47.8 92.1 19.3 160h108c8.7-56.9 25.5-107.8 49.9-141.6zM487.4 192H372.7c2.1 21 3.3 42.5 3.3 64s-1.2 43-3.3 64h114.6c5.5-20.5 8.6-41.8 8.6-64s-3.1-43.5-8.5-64zM120 256c0-21.5 1.2-43 3.3-64H8.6C3.2 212.5 0 233.8 0 256s3.2 43.5 8.6 64h114.6c-2-21-3.2-42.5-3.2-64zm39.5 96c14.5 89.3 48.7 152 88.5 152s74-62.7 88.5-152h-177zm159.3 141.6c71.4-21.2 129.4-73.7 158-141.6h-108c-8.8 56.9-25.6 107.8-50 141.6zM19.3 352c28.6 67.9 86.5 120.4 158 141.6-24.4-33.8-41.2-84.7-50-141.6h-108z"></path></svg>关于网站</a></li><li><a class="" href="/about/me"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 192 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M96 0c35.346 0 64 28.654 64 64s-28.654 64-64 64-64-28.654-64-64S60.654 0 96 0m48 144h-11.36c-22.711 10.443-49.59 10.894-73.28 0H48c-26.51 0-48 21.49-48 48v136c0 13.255 10.745 24 24 24h16v136c0 13.255 10.745 24 24 24h64c13.255 0 24-10.745 24-24V352h16c13.255 0 24-10.745 24-24V192c0-26.51-21.49-48-48-48z"></path></svg>关于我</a></li></ul></li></ul></div></div></div></div><div><article><div class="bg-neutral px-4 py-8"><div class="max-w-7xl mx-auto min-h-[256px] flex justify-center text-center text-neutral-content"><div class="flex flex-col justify-center animate-slide-up"><h1 class="text-4xl my-2">可划分显存 != 统一内存：AI Max+ 395 64G AI推理性能</h1><div class="flex flex-wrap gap-3 my-2 text-sm justify-center"><div class="flex flex-wrap gap-1 items-center"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 252.118V48C0 21.49 21.49 0 48 0h204.118a48 48 0 0 1 33.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137 0 67.882L293.823 497.941c-18.745 18.745-49.137 18.745-67.882 0L14.059 286.059A48 48 0 0 1 0 252.118zM112 64c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48z"></path></svg><a class="badge badge-accent mx-0.5 text-accent-content" href="/articles/search?query=ai">ai</a><a class="badge badge-accent mx-0.5 text-accent-content" href="/articles/search?query=hands-on">上手</a><a class="badge badge-accent mx-0.5 text-accent-content" href="/articles/search?query=thoughts">看法</a></div><div class="flex items-center" title="发表时间"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M12 192h424c6.6 0 12 5.4 12 12v260c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V204c0-6.6 5.4-12 12-12zm436-44v-36c0-26.5-21.5-48-48-48h-48V12c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v52H160V12c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v52H48C21.5 64 0 85.5 0 112v36c0 6.6 5.4 12 12 12h424c6.6 0 12-5.4 12-12z"></path></svg><span class="mx-0.5">2026-02-02 20:34:00 UTC+8</span></div><div class="flex items-center"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 384 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M224 136V0H24C10.7 0 0 10.7 0 24v464c0 13.3 10.7 24 24 24h336c13.3 0 24-10.7 24-24V160H248c-13.2 0-24-10.8-24-24zm57.1 120H305c7.7 0 13.4 7.1 11.7 14.7l-38 168c-1.2 5.5-6.1 9.3-11.7 9.3h-38c-5.5 0-10.3-3.8-11.6-9.1-25.8-103.5-20.8-81.2-25.6-110.5h-.5c-1.1 14.3-2.4 17.4-25.6 110.5-1.3 5.3-6.1 9.1-11.6 9.1H117c-5.6 0-10.5-3.9-11.7-9.4l-37.8-168c-1.7-7.5 4-14.6 11.7-14.6h24.5c5.7 0 10.7 4 11.8 9.7 15.6 78 20.1 109.5 21 122.2 1.6-10.2 7.3-32.7 29.4-122.7 1.3-5.4 6.1-9.1 11.7-9.1h29.1c5.6 0 10.4 3.8 11.7 9.2 24 100.4 28.8 124 29.6 129.4-.2-11.2-2.6-17.8 21.6-129.2 1-5.6 5.9-9.5 11.5-9.5zM384 121.9v6.1H256V0h6.1c6.4 0 12.5 2.5 17 7l97.9 98c4.5 4.5 7 10.6 7 16.9z"></path></svg><span class="mx-0.5">2457<!-- --> 字</span></div><div class="flex items-center"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M256,8C119,8,8,119,8,256S119,504,256,504,504,393,504,256,393,8,256,8Zm92.49,313h0l-20,25a16,16,0,0,1-22.49,2.5h0l-67-49.72a40,40,0,0,1-15-31.23V112a16,16,0,0,1,16-16h32a16,16,0,0,1,16,16V256l58,42.5A16,16,0,0,1,348.49,321Z"></path></svg><span class="mx-0.5">13<!-- --> 分钟阅读</span></div><div class="flex items-center"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M336.5 160C322 70.7 287.8 8 248 8s-74 62.7-88.5 152h177zM152 256c0 22.2 1.2 43.5 3.3 64h185.3c2.1-20.5 3.3-41.8 3.3-64s-1.2-43.5-3.3-64H155.3c-2.1 20.5-3.3 41.8-3.3 64zm324.7-96c-28.6-67.9-86.5-120.4-158-141.6 24.4 33.8 41.2 84.7 50 141.6h108zM177.2 18.4C105.8 39.6 47.8 92.1 19.3 160h108c8.7-56.9 25.5-107.8 49.9-141.6zM487.4 192H372.7c2.1 21 3.3 42.5 3.3 64s-1.2 43-3.3 64h114.6c5.5-20.5 8.6-41.8 8.6-64s-3.1-43.5-8.5-64zM120 256c0-21.5 1.2-43 3.3-64H8.6C3.2 212.5 0 233.8 0 256s3.2 43.5 8.6 64h114.6c-2-21-3.2-42.5-3.2-64zm39.5 96c14.5 89.3 48.7 152 88.5 152s74-62.7 88.5-152h-177zm159.3 141.6c71.4-21.2 129.4-73.7 158-141.6h-108c-8.8 56.9-25.6 107.8-50 141.6zM19.3 352c28.6 67.9 86.5 120.4 158 141.6-24.4-33.8-41.2-84.7-50-141.6h-108z"></path></svg><span class="mx-0.5 space-x-1"><a class="link link-hover" href="/articles/aimaxplus395-ai-inference/cn">简体中文</a></span></div></div></div></div></div><div class="animate-slide-up"><div class="max-w-7xl mx-auto p-4"><div class="flex flex-row space-x-4"><div class="prose max-w-full lg:w-[75%]"><h1 id="前言"><a href="#前言" class="mr-1"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="inline-block opacity-20 hover:opacity-60" height="16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>前言</h1>
<p>之前写过一篇<a href="/articles/aimaxplus395-experience">关于HP战99 Ultra（搭载AMD AI Max+ 395）的使用体验</a>，今天聊聊这台笔记本在AI推理场景下的表现。作为这台机器宣传的主要场景，AI推理的实际使用情况却优点一言难尽。</p>
<h1 id="硬件配置回顾"><a href="#硬件配置回顾" class="mr-1"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="inline-block opacity-20 hover:opacity-60" height="16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>硬件配置回顾</h1>

























<table><thead><tr><th>配置</th><th>详情</th></tr></thead><tbody><tr><td>CPU</td><td>AMD Ryzen AI Max+ 395 16C32T Zen5</td></tr><tr><td>内存</td><td>64G LPDDR5 8000MT 4通道可划分显存</td></tr><tr><td>显卡</td><td>Radeon 8060S 40CU RDNA3.5</td></tr><tr><td>显存</td><td>可在BIOS里将几个固定挡位的内存分配给显存</td></tr></tbody></table>
<h1 id="关键概念可划分显存-vs-统一内存"><a href="#关键概念可划分显存-vs-统一内存" class="mr-1"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="inline-block opacity-20 hover:opacity-60" height="16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>关键概念：可划分显存 vs 统一内存</h1>
<p>在深入分析数据之前，需要理解几个重要概念：</p>
<ul>
<li><strong>传统显存</strong>：传统独立显卡的固定显存，容量固定，如RTX 4090的24G</li>
<li><strong>可划分显存</strong>：静态分配机制，将内存的一部分固定划给GPU作为显存使用，如AI Max+ 395</li>
<li><strong>统一内存</strong>：内存和显存统一寻址，整个内存空间CPU和GPU都可以访问，无需显式分配（主要见于Apple M系列芯片）</li>
</ul>
<p><strong>重要区别</strong>：AI Max+ 395使用可划分显存架构，需要静态分配部分内存给GPU使用；而统一内存无需显式分配，灵活性更高。</p>
<h1 id="ai推理测试数据"><a href="#ai推理测试数据" class="mr-1"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="inline-block opacity-20 hover:opacity-60" height="16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>AI推理测试数据</h1>
<p>为了方便，以及因为我至今没能在WSL下成功运行<code>rocminfo</code>也就没办法跑vllm等主流推理引擎方案（就离谱），本次测试均在Windows下使用LM Studio运行。</p>
<h2 id="glm-47-flash"><a href="#glm-47-flash" class="mr-1"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="inline-block opacity-20 hover:opacity-60" height="16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>GLM 4.7 Flash</h2>
<p>这是个MoE模型，总参数量30B激活3B的规模，主要测试<code>Q4_K_M</code>量化的情况。在这个量化等级下，在模型大小为<code>18.13GB</code>。</p>
<p>以下的给出Prompt为：</p>
<blockquote>
<p>编写一个科技公司的官网的HTML</p>
</blockquote>
<p>另外值得一提的是，LM Studio中对AMD显卡有两种Runtime：Vulkan和ROCm。我本以为两种Runtime不会有什么很大的区别，但是实际测试下来却axm并非如此。</p>
<p>在16K上下文下：</p>



































<table><thead><tr><th>专用显存</th><th>512M</th><th>32G</th></tr></thead><tbody><tr><td>显存占用</td><td>20.8G</td><td>21.3G</td></tr><tr><td>Vulkan速度、总数(token/s)</td><td>17.26 (6970)</td><td><strong>42.89</strong> (6107)</td></tr><tr><td>Vulkan 首token (s)</td><td>0.8</td><td>0.8</td></tr><tr><td>ROCm速度、总数（token/s）</td><td>15.28 (5262)</td><td>14.42 (6351)</td></tr><tr><td>ROCm 首token (s)</td><td>0.04</td><td>0.34</td></tr></tbody></table>
<p>Vulkan在32G专用显存下的速度实在是过于逆天，于是我重新跑了数次，结果均非常接近。后面我们还能拿到如此让人匪夷所思的成绩。</p>
<p>16K的上下文只能说勉强够用。既然还有这么多显存可用，不妨试试更多的长度上下文。根据LM Studio估计，不同长度上下文的显存使用估计值：</p>
<ul>
<li>16K上下文：<strong>18.59G</strong></li>
<li>64K上下文：<strong>19.57G</strong></li>
<li>最大支持（198K）：<strong>22.3G</strong></li>
</ul>
<p>看起来MoE模型的一大好处就是可以把上下文拉大！于是我选择GLM 4.7 Flash最大支持的长上下文 198K下，虽然LM Studio的估计显存占用也仅有<strong>22.3G</strong>，但是512M专用显存的无法正常加载：</p>
<p><figure><img alt="无法正常加载模型" loading="lazy" width="454" height="175" decoding="async" data-nimg="1" class="cursor-zoom-in mx-auto" style="color:transparent" srcSet="/articles/asset/contents/20260202-aimaxplus395-ai-inference/198K-glm4.7-vulkan-no-memory.png?width=640 1x, /articles/asset/contents/20260202-aimaxplus395-ai-inference/198K-glm4.7-vulkan-no-memory.png?width=1080 2x" src="/articles/asset/contents/20260202-aimaxplus395-ai-inference/198K-glm4.7-vulkan-no-memory.png?width=1080"/><figcaption class="text-center">无法正常加载模型</figcaption></figure></p>
<p>只有在32G下可以正常使用，在Vulkan下获得了**37.28 token/s（7857 token，首token 0.15s）**的成绩。</p>
<p>同时我还测试了<strong>Q6_K</strong>的量化模型，在16K上下文、32G专用显存下：</p>
<ul>
<li><strong>模型大小</strong>：24.61GB</li>
<li><strong>预计显存占用</strong>：25.12GB</li>
<li><strong>推理性能</strong>：
<ul>
<li>ROCm：13.79 token/s（6419 token，首token 0.33s）</li>
<li>Vulkan：<strong>25.51</strong> token/s（5717 token，首token 0.20s）</li>
</ul>
</li>
</ul>
<p>再次看到了不知道该说是Vulkan逆天还是ROCm的成绩！ROCm作为AMD官方的方案，居然被Vulkan拉开了如此大的差距。</p>
<p>在不开启思考的情况下，10 token/s的速度还是可以应付日常使用的。</p>
<h2 id="qwen3-vl-32b"><a href="#qwen3-vl-32b" class="mr-1"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="inline-block opacity-20 hover:opacity-60" height="16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>Qwen3 VL 32B</h2>
<p>稠密模型的情况就不一样了。这一部分我选择了Qwen 3 VL 32B来测试。</p>
<p>这是个支持图像输入的模型，于是我去stackoverflow上截了如下这一张图，</p>
<p><figure><img alt="Stack Overflow截图" loading="lazy" width="1486" height="831" decoding="async" data-nimg="1" class="cursor-zoom-in mx-auto" style="color:transparent" srcSet="/articles/asset/contents/20260202-aimaxplus395-ai-inference/reproduce.png?width=1920 1x, /articles/asset/contents/20260202-aimaxplus395-ai-inference/reproduce.png?width=3840 2x" src="/articles/asset/contents/20260202-aimaxplus395-ai-inference/reproduce.png?width=3840"/><figcaption class="text-center">Stack Overflow截图</figcaption></figure></p>
<p>并给出prompt：</p>
<blockquote>
<p>使用html和css重现这个HTML页面</p>
</blockquote>
<p>以下为结果：</p>









































<table><thead><tr><th>专用显存</th><th>512M 16K</th><th>512M 24K</th><th>32G 16K</th></tr></thead><tbody><tr><td>显存占用</td><td>25.8G</td><td>28.3G</td><td>27.5G</td></tr><tr><td>Vulkan速度、总数(token/s)</td><td>3.74 (4059)</td><td>3.51 (3676)</td><td>9.41 (6801)</td></tr><tr><td>Vulkan 首token (s)</td><td>36.67</td><td>39.29</td><td>18.32</td></tr><tr><td>ROCm速度、总数（token/s）</td><td>4.15 (3723)</td><td>3.10 (3713)</td><td>9.42 (4198)</td></tr><tr><td>ROCm 首token (s)</td><td>24.59</td><td>26.56</td><td>9.46s</td></tr></tbody></table>
<p>可以看到，在24K上下文已经到32G显存的极限了（28G）。但不管有没有独立显存，这个推理速度用起来已经是比较难受的级别了。</p>
<h1 id="分配48g给显存"><a href="#分配48g给显存" class="mr-1"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="inline-block opacity-20 hover:opacity-60" height="16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>分配48G给显存？</h1>
<p>395的另一个宣传点是可以将75%的内存划给显存，在64G的型号上，BIOS中最高可以将48G的内存划给显存。</p>
<p>听起来很美？48G显存甚至可以高量化跑32B模型了！</p>
<p>Qwen 3 VL 32B的Q6_K量化模型大小为<strong>28.08G</strong>，在32G显存下可以加载，但是推理的时候因为显存不够了，速度比可以完全在显存中的Q4版本慢很多。经过测试，Q5_K_M是最大的32G显存可以充分的量化规格。</p>
<p>而这时候你想到，48G显存岂不是就可以接近这个问题了？</p>
<p>可是事实却是：<strong>16G的系统内存</strong>不仅使得正常的系统操作会开始缓慢甚至卡顿，甚至模型都无法正常加载！而我已经LM Studio中有三个选项和显存和内存全部调整为不给内存太多压力了：</p>
<ul>
<li>KV缓存卸载到GPU内存中：打开，显存够大！</li>
<li>保持模型在内存中：关闭</li>
<li>尝试mmap()：将磁盘上映射到内存中空间中，关闭</li>
</ul>
<p><figure><img alt="Qwen 3 VL 32B的Q6_K模型无法加载" loading="lazy" width="1046" height="821" decoding="async" data-nimg="1" class="cursor-zoom-in mx-auto" style="color:transparent" srcSet="/articles/asset/contents/20260202-aimaxplus395-ai-inference/q6_16G-memory-not-loadable-vulkan.png?width=1080 1x, /articles/asset/contents/20260202-aimaxplus395-ai-inference/q6_16G-memory-not-loadable-vulkan.png?width=3840 2x" src="/articles/asset/contents/20260202-aimaxplus395-ai-inference/q6_16G-memory-not-loadable-vulkan.png?width=3840"/><figcaption class="text-center">Qwen 3 VL 32B的Q6_K模型无法加载</figcaption></figure></p>
<h1 id="内存可划分为显存--共享内存"><a href="#内存可划分为显存--共享内存" class="mr-1"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="inline-block opacity-20 hover:opacity-60" height="16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>内存可划分为显存 != 共享内存</h1>
<p>395的主要的宣传口号，就是内存可以当作显存用。这话当然不假，BIOS里确实可以将内存划分给显存，但是，它和我们预期的<strong>共享内存</strong>完全是两码事：</p>
<ul>
<li>被划分给显存部分不可以再作为内存使用</li>
<li>每次切换显存需要重启，不可无缝切换</li>
</ul>
<p>那，如果我们不划分显存，<strong>直接把内存当显存用呢</strong>？其实现在的推理框架都支持把内存当显存用，但是以下两个问题让用内存当显存的方案下的推理速度惨不忍睹：</p>
<ol>
<li>内存与显存的速度之间有巨大差距</li>
<li>内存中的数据仅能由CPU计算，而CPU在AI计算场景下速度非常缓慢，且CPU和显卡的计算数据需频繁相互拷贝</li>
</ol>
<p>理论上来说，395的内存和显存均为同一款芯片，问题1不存在，但实际上问题2的问题仍然无法避免：即使是在同一块芯片上，显存仍然不能直接用内存部分的部分，内存和显存之间拷贝仍然非常频繁。</p>
<p>以下为使用512M专用显存（上）和32G专用显存（下）使用Vulkan运行GLM 4.7 Flash Q4_K_M时的任务管理器的图片，可以看出，512M的专用显存下GPU利用率只有70%左右，而32G下可以到达90%以上。而右上角的Copy也可以看出512M专用显存下显存一直在进行复制的操作。</p>
<p><figure><img alt="512M显存跑GLM 4.7 Flash Q4 16K" loading="lazy" width="1844" height="1553" decoding="async" data-nimg="1" class="cursor-zoom-in mx-auto" style="color:transparent" srcSet="/articles/asset/contents/20260202-aimaxplus395-ai-inference/glm4.7-no-dedicated-vulkan.png?width=1920 1x, /articles/asset/contents/20260202-aimaxplus395-ai-inference/glm4.7-no-dedicated-vulkan.png?width=3840 2x" src="/articles/asset/contents/20260202-aimaxplus395-ai-inference/glm4.7-no-dedicated-vulkan.png?width=3840"/><figcaption class="text-center">512M显存跑GLM 4.7 Flash Q4 16K</figcaption></figure></p>
<p><figure><img alt="32G显存跑GLM 4.7 Flash Q4 16K" loading="lazy" width="1866" height="1470" decoding="async" data-nimg="1" class="cursor-zoom-in mx-auto" style="color:transparent" srcSet="/articles/asset/contents/20260202-aimaxplus395-ai-inference/dedicated-memory-vulkan-glm4.7.png?width=1920 1x, /articles/asset/contents/20260202-aimaxplus395-ai-inference/dedicated-memory-vulkan-glm4.7.png?width=3840 2x" src="/articles/asset/contents/20260202-aimaxplus395-ai-inference/dedicated-memory-vulkan-glm4.7.png?width=3840"/><figcaption class="text-center">32G显存跑GLM 4.7 Flash Q4 16K</figcaption></figure></p>
<p>同一现象也出现在512M专用显存下运行Qwen 3 VL 32B Q4_K_M的情况，GPU利用率更是只有50%，而Copy图中也能一直看到复制的过程，而整个过程中CPU也在（艰难地）参与运算。而CPU参与计算在笔记本场景下有抢功耗的问题，更影响了GPU的性能发挥。</p>
<p><figure><img alt="512M显存跑Qwen 3 32B Q4KM，16K" loading="lazy" width="1127" height="735" decoding="async" data-nimg="1" class="cursor-zoom-in mx-auto" style="color:transparent" srcSet="/articles/asset/contents/20260202-aimaxplus395-ai-inference/qwen3-32b-q4-km-no-dedicated-memory.png?width=1200 1x, /articles/asset/contents/20260202-aimaxplus395-ai-inference/qwen3-32b-q4-km-no-dedicated-memory.png?width=3840 2x" src="/articles/asset/contents/20260202-aimaxplus395-ai-inference/qwen3-32b-q4-km-no-dedicated-memory.png?width=3840"/><figcaption class="text-center">512M显存跑Qwen 3 32B Q4KM，16K</figcaption></figure></p>
<p>更进一步地，如果把上下文拉到24K，进一步加大显存的需求量，在512M专用显存下情况更加恶化了：GPU有接近一半的时间都闲着。要知道，这个时候显存需求甚至才26G！</p>
<p><figure><img alt="512M显存跑Qwen 3 32B Q4KM，24K" loading="lazy" width="1661" height="1072" decoding="async" data-nimg="1" class="cursor-zoom-in mx-auto" style="color:transparent" srcSet="/articles/asset/contents/20260202-aimaxplus395-ai-inference/24k-qwen3-32b-q4km-no-dedicated.png?width=1920 1x, /articles/asset/contents/20260202-aimaxplus395-ai-inference/24k-qwen3-32b-q4km-no-dedicated.png?width=3840 2x" src="/articles/asset/contents/20260202-aimaxplus395-ai-inference/24k-qwen3-32b-q4km-no-dedicated.png?width=3840"/><figcaption class="text-center">512M显存跑Qwen 3 32B Q4KM，24K</figcaption></figure></p>
<h1 id="总结"><a href="#总结" class="mr-1"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="inline-block opacity-20 hover:opacity-60" height="16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>总结</h1>
<p>我用两个字总结395的优点：<strong>能用</strong></p>
<ul>
<li>大显存确实可以跑一些正常显卡无法跑的模型，虽然慢，但是能跑比不能跑好！</li>
<li>成本相对较低（相比高端显卡）（也只是相对了）</li>
<li>4060移动端的绝对算力，不算高，但是愿意等等的话，它能跑的模型还是能给出结果的</li>
</ul>
<p>可是这台笔记本形态、64G的总内存的设备却有点尴尬：</p>
<ul>
<li>为了兼顾日常使用，实际上最多只能32G给显存</li>
<li>80W的最高功耗，无法充分发挥CPU的性能</li>
<li>手动划分显存操作失去了灵活性</li>
</ul>
<p>所以395确实非常适合小主机场景：</p>
<ul>
<li>这类主机在分配96G显存的情况下还有32G可以用于日常场景，比64G=48G+16G实用太多</li>
<li>这类主机的性能释放普遍超过100W，也有更完善的散热方案，可以更完美地发挥CPU和GPU的性能</li>
<li>和395刚出来的时候AMD更羸弱的AI生态相比，至少现在主流的推理场景（LM Studio，Ollama、ComfyUI）都已经可以用了（至少我在搜索了包括AMD官网的无数地方后，终于还是找到了AMD官方支持的<code>pytorch</code>）</li>
</ul>
<p>甚至小主机的价格也比笔记本形态的设备（64G 19999）便宜太多（128G普遍15000，希望还没开始涨）。在这个内存价格疯涨的年代，能以这个价格有一台可以跑大模型的机器已经很不容易了。</p></div><div class="hidden lg:block lg:w-[25%]"><div class="px-1 sticky top-24 max-h-[60vh] overflow-auto"><div class="flex space-x-1 items-center py-2"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill="none" d="M0 0h24v24H0z"></path><path d="M3 9h14V7H3v2zm0 4h14v-2H3v2zm0 4h14v-2H3v2zm16 0h2v-2h-2v2zm0-10v2h2V7h-2zm0 6h2v-2h-2v2z"></path></svg><span>目录</span></div><ul class="pl-2 border-l border-neutral"><li class="w-full text-sm"><a class="transition hover:bg-base-300 rounded w-full flex p-1" data-tocid="前言" href="#前言">前言</a></li><li class="w-full text-sm"><a class="transition hover:bg-base-300 rounded w-full flex p-1" data-tocid="硬件配置回顾" href="#硬件配置回顾">硬件配置回顾</a></li><li class="w-full text-sm"><a class="transition hover:bg-base-300 rounded w-full flex p-1" data-tocid="关键概念可划分显存-vs-统一内存" href="#关键概念可划分显存-vs-统一内存">关键概念：可划分显存 vs 统一内存</a></li><li class="w-full text-sm"><a class="transition hover:bg-base-300 rounded w-full flex p-1" data-tocid="ai推理测试数据" href="#ai推理测试数据">AI推理测试数据</a><ul class="pl-2 border-l border-neutral"><li class="w-full text-sm"><a class="transition hover:bg-base-300 rounded w-full flex p-1" data-tocid="glm-47-flash" href="#glm-47-flash">GLM 4.7 Flash</a></li><li class="w-full text-sm"><a class="transition hover:bg-base-300 rounded w-full flex p-1" data-tocid="qwen3-vl-32b" href="#qwen3-vl-32b">Qwen3 VL 32B</a></li></ul></li><li class="w-full text-sm"><a class="transition hover:bg-base-300 rounded w-full flex p-1" data-tocid="分配48g给显存" href="#分配48g给显存">分配48G给显存？</a></li><li class="w-full text-sm"><a class="transition hover:bg-base-300 rounded w-full flex p-1" data-tocid="内存可划分为显存--共享内存" href="#内存可划分为显存--共享内存">内存可划分为显存 != 共享内存</a></li><li class="w-full text-sm"><a class="transition hover:bg-base-300 rounded w-full flex p-1" data-tocid="总结" href="#总结">总结</a></li></ul></div></div></div></div><div class="max-w-7xl mx-auto p-4"></div><div class="max-w-7xl mx-auto p-4"><div><h2 class="text-2xl font-bold mb-2 flex items-center"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 192c0-88.4-93.1-160-208-160S0 103.6 0 192c0 34.3 14.1 65.9 38 92-13.4 30.2-35.5 54.2-35.8 54.5-2.2 2.3-2.8 5.7-1.5 8.7S4.8 352 8 352c36.6 0 66.9-12.3 88.7-25 32.2 15.7 70.3 25 111.3 25 114.9 0 208-71.6 208-160zm122 220c23.9-26 38-57.7 38-92 0-66.9-53.5-124.2-129.3-148.1.9 6.6 1.3 13.3 1.3 20.1 0 105.9-107.7 192-240 192-10.8 0-21.3-.8-31.7-1.9C207.8 439.6 281.8 480 368 480c41 0 79.1-9.2 111.3-25 21.8 12.7 52.1 25 88.7 25 3.2 0 6.1-1.9 7.3-4.8 1.3-2.9.7-6.3-1.5-8.7-.3-.3-22.4-24.2-35.8-54.5z"></path></svg><span class="mx-2"> 评论</span></h2></div></div></div></article><!--$--><!--/$--></div><footer class="bg-base-200 text-base-content"><div class="footer sm:footer-horizontal py-6 max-w-7xl mx-auto px-4"><div class="space-y-1"><p>👨🏼‍💻 <!-- -->本网站由<a class="link link-hover" href="/about/me/cn">ddadaal</a>自豪地编写</p><p>📝<!-- -->本站文章在<a rel="licene noreferrer" target="_blank" class="link" href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a>协议下授权</p><div class="tooltip" data-tip="2018-11-17 06:51:00 UTC+0"><p>📅<!-- --> <!-- -->博客已经运行 <span class="countdown"><span style="--value:7"></span></span> 年 <span class="countdown"><span style="--value:3"></span></span> 月 <span class="countdown"><span style="--value:24"></span></span> 天 <span class="countdown"><span style="--value:6"></span></span> 时 <span class="countdown"><span style="--value:16"></span></span> 分 <span class="countdown"><span style="--value:4"></span></span> 秒</p></div><p>⏲️<!-- --> <!-- -->最后更新<!-- -->:  <!-- -->2026-02-02 13:07:04 UTC+0</p><div><p>📲<!-- --> <!-- -->联系我</p><div class="flex py-2 gap-2"><span><a href="http://wpa.qq.com/msgrd?v=3&amp;uin=540232834&amp;site=qq&amp;menu=yes" title="QQ: 540232834" target="_blank" class="block transition hover:scale-125" rel="noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="22.400000000000002" width="22.400000000000002" xmlns="http://www.w3.org/2000/svg"><path d="M433.754 420.445c-11.526 1.393-44.86-52.741-44.86-52.741 0 31.345-16.136 72.247-51.051 101.786 16.842 5.192 54.843 19.167 45.803 34.421-7.316 12.343-125.51 7.881-159.632 4.037-34.122 3.844-152.316 8.306-159.632-4.037-9.045-15.25 28.918-29.214 45.783-34.415-34.92-29.539-51.059-70.445-51.059-101.792 0 0-33.334 54.134-44.859 52.741-5.37-.65-12.424-29.644 9.347-99.704 10.261-33.024 21.995-60.478 40.144-105.779C60.683 98.063 108.982.006 224 0c113.737.006 163.156 96.133 160.264 214.963 18.118 45.223 29.912 72.85 40.144 105.778 21.768 70.06 14.716 99.053 9.346 99.704z"></path></svg></a></span><span><a href="mailto://ddadaal.me@outlook.com" title="E-mail: ddadaal@outlook.com" target="_blank" class="block transition hover:scale-125" rel="noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="22.400000000000002" width="22.400000000000002" xmlns="http://www.w3.org/2000/svg"><path d="M160 448c-25.6 0-51.2-22.4-64-32-64-44.8-83.2-60.8-96-70.4V480c0 17.67 14.33 32 32 32h256c17.67 0 32-14.33 32-32V345.6c-12.8 9.6-32 25.6-96 70.4-12.8 9.6-38.4 32-64 32zm128-192H32c-17.67 0-32 14.33-32 32v16c25.6 19.2 22.4 19.2 115.2 86.4 9.6 6.4 28.8 25.6 44.8 25.6s35.2-19.2 44.8-22.4c92.8-67.2 89.6-67.2 115.2-86.4V288c0-17.67-14.33-32-32-32zm256-96H224c-17.67 0-32 14.33-32 32v32h96c33.21 0 60.59 25.42 63.71 57.82l.29-.22V416h192c17.67 0 32-14.33 32-32V192c0-17.67-14.33-32-32-32zm-32 128h-64v-64h64v64zm-352-96c0-35.29 28.71-64 64-64h224V32c0-17.67-14.33-32-32-32H96C78.33 0 64 14.33 64 32v192h96v-32z"></path></svg></a></span><span><a href="https://www.linkedin.com/in/chenjunda/" title="LinkedIn: 陈俊达" target="_blank" class="block transition hover:scale-125" rel="noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="22.400000000000002" width="22.400000000000002" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></span><span><a href="https://github.com/ddadaal" title="GitHub: ddadaal" target="_blank" class="block transition hover:scale-125" rel="noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="22.400000000000002" width="22.400000000000002" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></span><span><a href="https://steamcommunity.com/profiles/76561198104889782" title="Steam: Victor Crubs" target="_blank" class="block transition hover:scale-125" rel="noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="22.400000000000002" width="22.400000000000002" xmlns="http://www.w3.org/2000/svg"><path d="M496 256c0 137-111.2 248-248.4 248-113.8 0-209.6-76.3-239-180.4l95.2 39.3c6.4 32.1 34.9 56.4 68.9 56.4 39.2 0 71.9-32.4 70.2-73.5l84.5-60.2c52.1 1.3 95.8-40.9 95.8-93.5 0-51.6-42-93.5-93.7-93.5s-93.7 42-93.7 93.5v1.2L176.6 279c-15.5-.9-30.7 3.4-43.5 12.1L0 236.1C10.2 108.4 117.1 8 247.6 8 384.8 8 496 119 496 256zM155.7 384.3l-30.5-12.6a52.79 52.79 0 0 0 27.2 25.8c26.9 11.2 57.8-1.6 69-28.4 5.4-13 5.5-27.3.1-40.3-5.4-13-15.5-23.2-28.5-28.6-12.9-5.4-26.7-5.2-38.9-.6l31.5 13c19.8 8.2 29.2 30.9 20.9 50.7-8.3 19.9-31 29.2-50.8 21zm173.8-129.9c-34.4 0-62.4-28-62.4-62.3s28-62.3 62.4-62.3 62.4 28 62.4 62.3-27.9 62.3-62.4 62.3zm.1-15.6c25.9 0 46.9-21 46.9-46.8 0-25.9-21-46.8-46.9-46.8s-46.9 21-46.9 46.8c.1 25.8 21.1 46.8 46.9 46.8z"></path></svg></a></span><span><a href="https://zhihu.com/people/VicCrubs" title="知乎：陈俊达" target="_blank" class="block transition hover:scale-125" rel="noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="22.400000000000002" width="22.400000000000002" xmlns="http://www.w3.org/2000/svg"><path d="M170.54 148.13v217.54l23.43.01 7.71 26.37 42.01-26.37h49.53V148.13H170.54zm97.75 193.93h-27.94l-27.9 17.51-5.08-17.47-11.9-.04V171.75h72.82v170.31zm-118.46-94.39H97.5c1.74-27.1 2.2-51.59 2.2-73.46h51.16s1.97-22.56-8.58-22.31h-88.5c3.49-13.12 7.87-26.66 13.12-40.67 0 0-24.07 0-32.27 21.57-3.39 8.9-13.21 43.14-30.7 78.12 5.89-.64 25.37-1.18 36.84-22.21 2.11-5.89 2.51-6.66 5.14-14.53h28.87c0 10.5-1.2 66.88-1.68 73.44H20.83c-11.74 0-15.56 23.62-15.56 23.62h65.58C66.45 321.1 42.83 363.12 0 396.34c20.49 5.85 40.91-.93 51-9.9 0 0 22.98-20.9 35.59-69.25l53.96 64.94s7.91-26.89-1.24-39.99c-7.58-8.92-28.06-33.06-36.79-41.81L87.9 311.95c4.36-13.98 6.99-27.55 7.87-40.67h61.65s-.09-23.62-7.59-23.62v.01zm412.02-1.6c20.83-25.64 44.98-58.57 44.98-58.57s-18.65-14.8-27.38-4.06c-6 8.15-36.83 48.2-36.83 48.2l19.23 14.43zm-150.09-59.09c-9.01-8.25-25.91 2.13-25.91 2.13s39.52 55.04 41.12 57.45l19.46-13.73s-25.67-37.61-34.66-45.86h-.01zM640 258.35c-19.78 0-130.91.93-131.06.93v-101c4.81 0 12.42-.4 22.85-1.2 40.88-2.41 70.13-4 87.77-4.81 0 0 12.22-27.19-.59-33.44-3.07-1.18-23.17 4.58-23.17 4.58s-165.22 16.49-232.36 18.05c1.6 8.82 7.62 17.08 15.78 19.55 13.31 3.48 22.69 1.7 49.15.89 24.83-1.6 43.68-2.43 56.51-2.43v99.81H351.41s2.82 22.31 25.51 22.85h107.94v70.92c0 13.97-11.19 21.99-24.48 21.12-14.08.11-26.08-1.15-41.69-1.81 1.99 3.97 6.33 14.39 19.31 21.84 9.88 4.81 16.17 6.57 26.02 6.57 29.56 0 45.67-17.28 44.89-45.31v-73.32h122.36c9.68 0 8.7-23.78 8.7-23.78l.03-.01z"></path></svg></a></span><span><a href="https://www.douban.com/people/183064260/" title="豆瓣: ddadaal" target="_blank" class="block transition hover:scale-125" rel="noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" role="img" viewBox="0 0 24 24" height="22.400000000000002" width="22.400000000000002" xmlns="http://www.w3.org/2000/svg"><path d="M.51 3.06h22.98V.755H.51V3.06Zm20.976 2.537v9.608h-2.137l-1.669 5.76H24v2.28H0v-2.28h6.32l-1.67-5.76H2.515V5.597h18.972Zm-5.066 9.608H7.58l1.67 5.76h5.501l1.67-5.76ZM18.367 7.9H5.634v5.025h12.733V7.9Z"></path></svg></a></span></div></div><p class="text-center">©<!-- --> <!-- -->2026<!-- --> <!-- -->|<!-- --> <!-- -->用 ❤ 制作</p></div><div><span class="footer-title">🚀<!-- --> <!-- -->强力驱动</span><a class="link link-hover" target="_blank" href="https://reactjs.org/" rel="noreferrer">React</a><a class="link link-hover" target="_blank" href="https://nextjs.org/" rel="noreferrer">Next.js</a><a class="link link-hover" target="_blank" href="https://pages.github.com/" rel="noreferrer">GitHub Pages</a><a class="link link-hover" target="_blank" href="https://www.typescriptlang.org/" rel="noreferrer">TypeScript</a></div><div><span class="footer-title">🎨<!-- --> <!-- -->描绘主题</span><a class="link link-hover" target="_blank" href="https://daisyui.com/" rel="noreferrer">daisyui</a><a class="link link-hover" target="_blank" href="https://tailwindcss.com/" rel="noreferrer">tailwind</a></div><div><span class="footer-title">🎓<!-- --> <!-- -->联系我</span><a class="link link-hover" target="_blank" href="https://idealclover.top" rel="noreferrer">idealclover - 翠翠酱的个人网站</a><a class="link link-hover" target="_blank" href="https://sephidator.xyz" rel="noreferrer">Sephidator - Sephidator的个人博客</a><a class="link link-hover" target="_blank" href="https://iznauy.github.io/" rel="noreferrer">iznauy - 个人博客</a><a class="link link-hover" target="_blank" href="https://aironoria.github.io" rel="noreferrer">Aironoria - 陈俊宇的个人博客</a><a class="link link-hover" target="_blank" href="https://jbesu.com/" rel="noreferrer">forewing - 个人主页</a><a class="link link-hover" target="_blank" href="https://weiser.fun" rel="noreferrer">Weiser - 个人主页</a></div></div></footer><button class="fixed animate-slide-up bottom-8 right-8 z-50 p-3 rounded-full bg-base-300 text-base-content shadow" title="To top"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" class="w-6 h-6" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M34.9 289.5l-22.2-22.2c-9.4-9.4-9.4-24.6 0-33.9L207 39c9.4-9.4 24.6-9.4 33.9 0l194.3 194.3c9.4 9.4 9.4 24.6 0 33.9L413 289.4c-9.5 9.5-25 9.3-34.3-.4L264 168.6V456c0 13.3-10.7 24-24 24h-32c-13.3 0-24-10.7-24-24V168.6L69.2 289.1c-9.3 9.8-24.8 10-34.3.4z"></path></svg></button><script src="/_next/static/chunks/56e7209dcf17c86b.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n3:I[61870,[\"/_next/static/chunks/2caa33a942c5f527.js\",\"/_next/static/chunks/59983278a34fd25c.js\"],\"default\"]\n4:I[20278,[\"/_next/static/chunks/2caa33a942c5f527.js\",\"/_next/static/chunks/59983278a34fd25c.js\"],\"default\"]\n6:I[23491,[\"/_next/static/chunks/2caa33a942c5f527.js\",\"/_next/static/chunks/59983278a34fd25c.js\"],\"OutletBoundary\"]\n7:\"$Sreact.suspense\"\n9:I[23491,[\"/_next/static/chunks/2caa33a942c5f527.js\",\"/_next/static/chunks/59983278a34fd25c.js\"],\"ViewportBoundary\"]\nb:I[23491,[\"/_next/static/chunks/2caa33a942c5f527.js\",\"/_next/static/chunks/59983278a34fd25c.js\"],\"MetadataBoundary\"]\nd:I[20632,[],\"default\"]\n:HL[\"/_next/static/chunks/a705e43fee9b0e0d.css\",\"style\"]\n:HL[\"/_next/static/chunks/44d2e091595b3eca.css\",\"style\"]\n:HL[\"/_next/static/chunks/5e55d74f3211c796.css\",\"style\"]\n:HL[\"/_next/static/chunks/b59bad6ea4f112f2.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"aOy5JX6Q5NHJv_y8DZ933\",\"c\":[\"\",\"articles\",\"aimaxplus395-ai-inference\"],\"q\":\"\",\"i\":false,\"f\":[[[\"\",{\"children\":[\"articles\",{\"children\":[[\"params\",\"aimaxplus395-ai-inference\",\"oc\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/a705e43fee9b0e0d.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-0\",{\"src\":\"/_next/static/chunks/8d29a04bcfe27c24.js\",\"async\":true,\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-1\",{\"src\":\"/_next/static/chunks/3dff3d4c63cf346e.js\",\"async\":true,\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-2\",{\"src\":\"/_next/static/chunks/b3af52d5d180873a.js\",\"async\":true,\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-3\",{\"src\":\"/_next/static/chunks/86b442c1397f7351.js\",\"async\":true,\"nonce\":\"$undefined\"}]],\"$L2\"]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[\"$L5\",[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/44d2e091595b3eca.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/5e55d74f3211c796.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"2\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/b59bad6ea4f112f2.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-0\",{\"src\":\"/_next/static/chunks/0a1497ca0a1721ad.js\",\"async\":true,\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-1\",{\"src\":\"/_next/static/chunks/4ec1bf7a32b70f87.js\",\"async\":true,\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-2\",{\"src\":\"/_next/static/chunks/276b22541034e0ea.js\",\"async\":true,\"nonce\":\"$undefined\"}]],[\"$\",\"$L6\",null,{\"children\":[\"$\",\"$7\",null,{\"name\":\"Next.MetadataOutlet\",\"children\":\"$@8\"}]}]]}],{},null,false,false]},null,false,false]},null,false,false]},null,false,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$L9\",null,{\"children\":\"$La\"}],[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$Lb\",null,{\"children\":[\"$\",\"$7\",null,{\"name\":\"Next.Metadata\",\"children\":\"$Lc\"}]}]}],null]}],false]],\"m\":\"$undefined\",\"G\":[\"$d\",[]],\"S\":true}\n"])</script><script>self.__next_f.push([1,"e:I[45509,[\"/_next/static/chunks/8d29a04bcfe27c24.js\",\"/_next/static/chunks/3dff3d4c63cf346e.js\",\"/_next/static/chunks/b3af52d5d180873a.js\",\"/_next/static/chunks/86b442c1397f7351.js\"],\"RootLayout\"]\nf:I[10024,[\"/_next/static/chunks/8d29a04bcfe27c24.js\",\"/_next/static/chunks/3dff3d4c63cf346e.js\",\"/_next/static/chunks/b3af52d5d180873a.js\",\"/_next/static/chunks/86b442c1397f7351.js\"],\"\"]\n10:I[30159,[\"/_next/static/chunks/8d29a04bcfe27c24.js\",\"/_next/static/chunks/3dff3d4c63cf346e.js\",\"/_next/static/chunks/b3af52d5d180873a.js\",\"/_next/static/chunks/86b442c1397f7351.js\"],\"Header\"]\n11:I[88459,[\"/_next/static/chunks/8d29a04bcfe27c24.js\",\"/_next/static/chunks/3dff3d4c63cf346e.js\",\"/_next/static/chunks/b3af52d5d180873a.js\",\"/_next/static/chunks/86b442c1397f7351.js\"],\"Localized\"]\n12:I[12025,[\"/_next/static/chunks/8d29a04bcfe27c24.js\",\"/_next/static/chunks/3dff3d4c63cf346e.js\",\"/_next/static/chunks/b3af52d5d180873a.js\",\"/_next/static/chunks/86b442c1397f7351.js\"],\"LocalizedArticleLink\"]\n13:I[33770,[\"/_next/static/chunks/8d29a04bcfe27c24.js\",\"/_next/static/chunks/3dff3d4c63cf346e.js\",\"/_next/static/chunks/b3af52d5d180873a.js\",\"/_next/static/chunks/86b442c1397f7351.js\"],\"RunningTime\"]\n14:I[39239,[\"/_next/static/chunks/8d29a04bcfe27c24.js\",\"/_next/static/chunks/3dff3d4c63cf346e.js\",\"/_next/static/chunks/b3af52d5d180873a.js\",\"/_next/static/chunks/86b442c1397f7351.js\"],\"LastUpdateTime\"]\n"])</script><script>self.__next_f.push([1,"2:[\"$\",\"$Le\",null,{\"children\":[[\"$\",\"$Lf\",null,{\"data-host\":\"https://services.ddadaal.me\",\"data-dnt\":\"false\",\"src\":\"https://services.ddadaal.me/monitor/script.js\",\"id\":\"ZwSg9rf6GA\",\"async\":true,\"defer\":true}],[\"$\",\"$L10\",null,{\"resumeLangs\":[\"cn\",\"en\"]}],[\"$\",\"div\",null,{\"children\":[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}],[\"$\",\"footer\",null,{\"className\":\"bg-base-200 text-base-content\",\"children\":[\"$\",\"div\",null,{\"className\":\"footer sm:footer-horizontal py-6 max-w-7xl mx-auto px-4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"space-y-1\",\"children\":[[\"$\",\"p\",null,{\"children\":[\"👨🏼‍💻 \",[\"$\",\"$L11\",null,{\"id\":\"footer.codeBy\",\"args\":[[\"$\",\"$L12\",\"about/me\",{\"className\":\"link link-hover\",\"basePath\":\"/about/me\",\"children\":\"ddadaal\"}]]}]]}],[\"$\",\"p\",null,{\"children\":[\"📝\",[\"$\",\"$L11\",null,{\"id\":\"footer.license\",\"args\":[[\"$\",\"a\",\"license\",{\"rel\":\"licene noreferrer\",\"target\":\"_blank\",\"className\":\"link\",\"href\":\"https://creativecommons.org/licenses/by-sa/4.0/\",\"children\":\"CC BY-SA 4.0\"}]]}]]}],[\"$\",\"$L13\",null,{\"serverStartTime\":\"2026-02-02T13:07:04.589+00:00\"}],[\"$\",\"$L14\",null,{\"time\":\"2026-02-02T13:07:04.589+00:00\"}],[\"$\",\"div\",null,{\"children\":[[\"$\",\"p\",null,{\"children\":[\"📲\",\" \",[\"$\",\"$L11\",null,{\"id\":\"footer.contacts\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex py-2 gap-2\",\"children\":[[\"$\",\"span\",\"http://wpa.qq.com/msgrd?v=3\u0026uin=540232834\u0026site=qq\u0026menu=yes\",{\"children\":[\"$\",\"a\",null,{\"href\":\"http://wpa.qq.com/msgrd?v=3\u0026uin=540232834\u0026site=qq\u0026menu=yes\",\"title\":\"QQ: 540232834\",\"target\":\"_blank\",\"className\":\"block transition hover:scale-125\",\"rel\":\"noreferrer\",\"children\":[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 448 512\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"M433.754 420.445c-11.526 1.393-44.86-52.741-44.86-52.741 0 31.345-16.136 72.247-51.051 101.786 16.842 5.192 54.843 19.167 45.803 34.421-7.316 12.343-125.51 7.881-159.632 4.037-34.122 3.844-152.316 8.306-159.632-4.037-9.045-15.25 28.918-29.214 45.783-34.415-34.92-29.539-51.059-70.445-51.059-101.792 0 0-33.334 54.134-44.859 52.741-5.37-.65-12.424-29.644 9.347-99.704 10.261-33.024 21.995-60.478 40.144-105.779C60.683 98.063 108.982.006 224 0c113.737.006 163.156 96.133 160.264 214.963 18.118 45.223 29.912 72.85 40.144 105.778 21.768 70.06 14.716 99.053 9.346 99.704z\",\"children\":[]}]]],\"className\":\"$undefined\",\"style\":{\"color\":\"$undefined\"},\"height\":22.400000000000002,\"width\":22.400000000000002,\"xmlns\":\"http://www.w3.org/2000/svg\"}]}]}],[\"$\",\"span\",\"mailto://ddadaal.me@outlook.com\",{\"children\":[\"$\",\"a\",null,{\"href\":\"mailto://ddadaal.me@outlook.com\",\"title\":\"E-mail: ddadaal@outlook.com\",\"target\":\"_blank\",\"className\":\"block transition hover:scale-125\",\"rel\":\"noreferrer\",\"children\":[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 576 512\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"M160 448c-25.6 0-51.2-22.4-64-32-64-44.8-83.2-60.8-96-70.4V480c0 17.67 14.33 32 32 32h256c17.67 0 32-14.33 32-32V345.6c-12.8 9.6-32 25.6-96 70.4-12.8 9.6-38.4 32-64 32zm128-192H32c-17.67 0-32 14.33-32 32v16c25.6 19.2 22.4 19.2 115.2 86.4 9.6 6.4 28.8 25.6 44.8 25.6s35.2-19.2 44.8-22.4c92.8-67.2 89.6-67.2 115.2-86.4V288c0-17.67-14.33-32-32-32zm256-96H224c-17.67 0-32 14.33-32 32v32h96c33.21 0 60.59 25.42 63.71 57.82l.29-.22V416h192c17.67 0 32-14.33 32-32V192c0-17.67-14.33-32-32-32zm-32 128h-64v-64h64v64zm-352-96c0-35.29 28.71-64 64-64h224V32c0-17.67-14.33-32-32-32H96C78.33 0 64 14.33 64 32v192h96v-32z\",\"children\":[]}]]],\"className\":\"$undefined\",\"style\":{\"color\":\"$undefined\"},\"height\":22.400000000000002,\"width\":22.400000000000002,\"xmlns\":\"http://www.w3.org/2000/svg\"}]}]}],\"$L15\",\"$L16\",\"$L17\",\"$L18\",\"$L19\"]}]]}],\"$L1a\"]}],\"$L1b\",\"$L1c\",\"$L1d\"]}]}],\"$L1e\"]}]\n"])</script><script>self.__next_f.push([1,"21:I[35631,[\"/_next/static/chunks/8d29a04bcfe27c24.js\",\"/_next/static/chunks/3dff3d4c63cf346e.js\",\"/_next/static/chunks/b3af52d5d180873a.js\",\"/_next/static/chunks/86b442c1397f7351.js\"],\"ToTop\"]\n15:[\"$\",\"span\",\"https://www.linkedin.com/in/chenjunda/\",{\"children\":[\"$\",\"a\",null,{\"href\":\"https://www.linkedin.com/in/chenjunda/\",\"title\":\"LinkedIn: 陈俊达\",\"target\":\"_blank\",\"className\":\"block transition hover:scale-125\",\"rel\":\"noreferrer\",\"children\":[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 448 512\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z\",\"children\":[]}]]],\"className\":\"$undefined\",\"style\":{\"color\":\"$undefined\"},\"height\":22.400000000000002,\"width\":22.400000000000002,\"xmlns\":\"http://www.w3.org/2000/svg\"}]}]}]\n1f:T518,M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z16:[\"$\",\"span\",\"https://github.com/ddadaal\",{\"children\":[\"$\",\"a\",null,{\"href\":\"https://github.com/ddadaal\",\"title\":\"GitHub: ddadaal\",\"target\":\"_blank\",\"className\":\"block transition hover:scale-125\",\"rel\":\"noreferrer\",\"children\":[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 496 512\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"$1f\",\"children\":[]}]]],\"className\":\"$undefined\",\"style\":{\"color\":\"$undefined\"},\"height\":22.400000000000002,\"width\":22.400000000000002,\"xmlns\":\"http://www.w3.org/2000/svg\"}]}]}]\n17:[\"$\",\"span\",\"https://steamcommunity.com/profiles/76561198104889782\",{\"children\":[\"$\",\"a\",null,{\"href\":\"https://steamcommunity.com/profiles/76561198104889782\",\"title\":\"Steam: Victor Crubs\",\"target\":\"_blank\",\"className\":\"block transition hover:scale-125\",\"rel\":\"noreferrer\",\"children\":[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 496 512\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"M496 256c0 137-111.2 248-248.4 248-113.8 0-209.6-76.3-239-180.4l95.2 39.3c6.4 32.1 34.9 56.4 68.9 56.4 39.2 0 71.9-32.4 70.2-73.5l84.5-60.2c52.1 1.3 95.8-40.9 95.8-93.5 0-51.6-42-93.5-93.7-93.5s-93.7 42-93.7 93.5v1.2L176.6 279c-15.5-.9-30.7 3.4-43.5 12.1L0 236.1C10.2 108.4 117.1 8 247.6 8 384.8 8 496 119 496 256zM155.7 384.3l-30.5-12.6a52.79 52.79 0 0 0 27.2 25.8c26.9 11.2 57.8-1.6 69-28.4 5.4-13 5.5-27.3.1-40.3-5.4-13-15.5-23.2-28.5-28.6-12.9-5.4-26.7-5.2-38.9-.6l31.5 13c19.8 8.2 29.2 30.9 20.9 50.7-8.3 19.9-31 29.2-50.8 21zm173.8-129.9c-34.4 0-62.4-28-62.4-62.3s28-62.3 62.4-62."])</script><script>self.__next_f.push([1,"3 62.4 28 62.4 62.3-27.9 62.3-62.4 62.3zm.1-15.6c25.9 0 46.9-21 46.9-46.8 0-25.9-21-46.8-46.9-46.8s-46.9 21-46.9 46.8c.1 25.8 21.1 46.8 46.9 46.8z\",\"children\":[]}]]],\"className\":\"$undefined\",\"style\":{\"color\":\"$undefined\"},\"height\":22.400000000000002,\"width\":22.400000000000002,\"xmlns\":\"http://www.w3.org/2000/svg\"}]}]}]\n20:T5b8,"])</script><script>self.__next_f.push([1,"M170.54 148.13v217.54l23.43.01 7.71 26.37 42.01-26.37h49.53V148.13H170.54zm97.75 193.93h-27.94l-27.9 17.51-5.08-17.47-11.9-.04V171.75h72.82v170.31zm-118.46-94.39H97.5c1.74-27.1 2.2-51.59 2.2-73.46h51.16s1.97-22.56-8.58-22.31h-88.5c3.49-13.12 7.87-26.66 13.12-40.67 0 0-24.07 0-32.27 21.57-3.39 8.9-13.21 43.14-30.7 78.12 5.89-.64 25.37-1.18 36.84-22.21 2.11-5.89 2.51-6.66 5.14-14.53h28.87c0 10.5-1.2 66.88-1.68 73.44H20.83c-11.74 0-15.56 23.62-15.56 23.62h65.58C66.45 321.1 42.83 363.12 0 396.34c20.49 5.85 40.91-.93 51-9.9 0 0 22.98-20.9 35.59-69.25l53.96 64.94s7.91-26.89-1.24-39.99c-7.58-8.92-28.06-33.06-36.79-41.81L87.9 311.95c4.36-13.98 6.99-27.55 7.87-40.67h61.65s-.09-23.62-7.59-23.62v.01zm412.02-1.6c20.83-25.64 44.98-58.57 44.98-58.57s-18.65-14.8-27.38-4.06c-6 8.15-36.83 48.2-36.83 48.2l19.23 14.43zm-150.09-59.09c-9.01-8.25-25.91 2.13-25.91 2.13s39.52 55.04 41.12 57.45l19.46-13.73s-25.67-37.61-34.66-45.86h-.01zM640 258.35c-19.78 0-130.91.93-131.06.93v-101c4.81 0 12.42-.4 22.85-1.2 40.88-2.41 70.13-4 87.77-4.81 0 0 12.22-27.19-.59-33.44-3.07-1.18-23.17 4.58-23.17 4.58s-165.22 16.49-232.36 18.05c1.6 8.82 7.62 17.08 15.78 19.55 13.31 3.48 22.69 1.7 49.15.89 24.83-1.6 43.68-2.43 56.51-2.43v99.81H351.41s2.82 22.31 25.51 22.85h107.94v70.92c0 13.97-11.19 21.99-24.48 21.12-14.08.11-26.08-1.15-41.69-1.81 1.99 3.97 6.33 14.39 19.31 21.84 9.88 4.81 16.17 6.57 26.02 6.57 29.56 0 45.67-17.28 44.89-45.31v-73.32h122.36c9.68 0 8.7-23.78 8.7-23.78l.03-.01z"])</script><script>self.__next_f.push([1,"18:[\"$\",\"span\",\"https://zhihu.com/people/VicCrubs\",{\"children\":[\"$\",\"a\",null,{\"href\":\"https://zhihu.com/people/VicCrubs\",\"title\":\"知乎：陈俊达\",\"target\":\"_blank\",\"className\":\"block transition hover:scale-125\",\"rel\":\"noreferrer\",\"children\":[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 640 512\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"$20\",\"children\":[]}]]],\"className\":\"$undefined\",\"style\":{\"color\":\"$undefined\"},\"height\":22.400000000000002,\"width\":22.400000000000002,\"xmlns\":\"http://www.w3.org/2000/svg\"}]}]}]\n19:[\"$\",\"span\",\"https://www.douban.com/people/183064260/\",{\"children\":[\"$\",\"a\",null,{\"href\":\"https://www.douban.com/people/183064260/\",\"title\":\"豆瓣: ddadaal\",\"target\":\"_blank\",\"className\":\"block transition hover:scale-125\",\"rel\":\"noreferrer\",\"children\":[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"role\":\"img\",\"viewBox\":\"0 0 24 24\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"M.51 3.06h22.98V.755H.51V3.06Zm20.976 2.537v9.608h-2.137l-1.669 5.76H24v2.28H0v-2.28h6.32l-1.67-5.76H2.515V5.597h18.972Zm-5.066 9.608H7.58l1.67 5.76h5.501l1.67-5.76ZM18.367 7.9H5.634v5.025h12.733V7.9Z\",\"children\":[]}]]],\"className\":\"$undefined\",\"style\":{\"color\":\"$undefined\"},\"height\":22.400000000000002,\"width\":22.400000000000002,\"xmlns\":\"http://www.w3.org/2000/svg\"}]}]}]\n1a:[\"$\",\"p\",null,{\"className\":\"text-center\",\"children\":[\"©\",\" \",2026,\" \",\"|\",\" \",[\"$\",\"$L11\",null,{\"id\":\"footer.madeWithLove\"}]]}]\n1b:[\"$\",\"div\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"footer-title\",\"children\":[\"🚀\",\" \",[\"$\",\"$L11\",null,{\"id\":\"footer.poweredBy\"}]]}],[[\"$\",\"a\",\"React\",{\"className\":\"link link-hover\",\"target\":\"_blank\",\"href\":\"https://reactjs.org/\",\"rel\":\"noreferrer\",\"children\":\"React\"}],[\"$\",\"a\",\"Next.js\",{\"className\":\"link link-hover\",\"target\":\"_blank\",\"href\":\"https://nextjs.org/\",\"rel\":\"noreferrer\",\"children\":\"Next.js\"}],[\"$\",\"a\",\"GitHub Pages\",{\"className\":\"link link-hover\",\"target\":\"_blank\",\"href\":\"https://pages.github.com/\",\"rel\":\"noreferrer\",\"children\":\"GitHub Pages\"}],[\"$\",\"a\",\"TypeScript\",{\"className\":\"link link-hover\",\"target\":\"_blank\",\"href\":\"https://www.typescriptlang.org/\",\"rel\":\"noreferrer\",\"children\":\"TypeScript\"}]]]}]\n1c:[\"$\",\"div\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"footer-title\",\"children\":[\"🎨\",\" \",[\"$\",\"$L11\",null,{\"id\":\"footer.themedWith\"}]]}],[[\"$\",\"a\",\"daisyui\",{\"className\":\"link link-hover\",\"target\":\"_blank\",\"href\":\"https://daisyui.com/\",\"rel\":\"noreferrer\",\"children\":\"daisyui\"}],[\"$\",\"a\",\"tailwind\",{\"className\":\"link link-hover\",\"target\":\"_blank\",\"href\":\"https://tailwindcss.com/\",\"rel\":\"noreferrer\",\"children\":\"tailwind\"}]]]}]\n1d:[\"$\",\"div\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"footer-title\",\"children\":[\"🎓\",\" \",[\"$\",\"$L11\",null,{\"id\":\"footer.contacts\"}]]}],[[\"$\",\"a\",\"idealclover - 翠翠酱的个人网站\",{\"className\":\"link link-hover\",\"target\":\"_blank\",\"href\":\"https://idealclover.top\",\"rel\":\"noreferrer\",\"children\":\"idealclover - 翠翠酱的个人网站\"}],[\"$\",\"a\",\"Sephidator - Sephidator的个人博客\",{\"className\":\"link link-hover\",\"target\":\"_blank\",\"href\":\"https://sephidator.xyz\",\"rel\":\"noreferrer\",\"children\":\"Sephidator - Sephidator的个人博客\"}],[\"$\",\"a\",\"iznauy - 个人博客\",{\"className\":\"link link-hover\",\"target\":\"_blank\",\"href\":\"https://iznauy.github.io/\",\"rel\":\"noreferrer\",\"children\":\"iznauy - 个人博客\"}],[\"$\",\"a\",\"Aironoria - 陈俊宇的个人博客\",{\"className\":\"link link-hover\",\"target\":\"_blank\",\"href\":\"https://aironoria.github.io\",\"rel\":\"noreferrer\",\"children\":\"Aironoria - 陈俊宇的个人博客\"}],[\"$\",\"a\",\"forewing - 个人主页\",{\"className\":\"link link-hover\",\"target\":\"_blank\",\"href\":\"https://jbesu.com/\",\"rel\":\"noreferrer\",\"children\":\"forewing - 个人主页\"}],[\"$\",\"a\",\"Weiser - 个人主页\",{\"className\":\"link link-hover\",\"target\":\"_blank\",\"href\":\"https://weiser.fun\",\"rel\":\"noreferrer\",\"children\":\"Weiser - 个人主页\"}]]]}]\n1e:[\"$\",\"$L21\",null,{}]\n"])</script><script>self.__next_f.push([1,"22:I[28979,[\"/_next/static/chunks/8d29a04bcfe27c24.js\",\"/_next/static/chunks/3dff3d4c63cf346e.js\",\"/_next/static/chunks/b3af52d5d180873a.js\",\"/_next/static/chunks/86b442c1397f7351.js\",\"/_next/static/chunks/0a1497ca0a1721ad.js\",\"/_next/static/chunks/4ec1bf7a32b70f87.js\",\"/_next/static/chunks/276b22541034e0ea.js\"],\"ArticleFrontmatter\"]\n23:T253d,"])</script><script>self.__next_f.push([1,"\n# 前言\n\n之前写过一篇[关于HP战99 Ultra（搭载AMD AI Max+ 395）的使用体验](/articles/aimaxplus395-experience)，今天聊聊这台笔记本在AI推理场景下的表现。作为这台机器宣传的主要场景，AI推理的实际使用情况却优点一言难尽。\n\n# 硬件配置回顾\n\n| 配置 | 详情                                     |\n| ---- | ---------------------------------------- |\n| CPU  | AMD Ryzen AI Max+ 395 16C32T Zen5        |\n| 内存 | 64G LPDDR5 8000MT 4通道可划分显存        |\n| 显卡 | Radeon 8060S 40CU RDNA3.5                |\n| 显存 | 可在BIOS里将几个固定挡位的内存分配给显存 |\n\n# 关键概念：可划分显存 vs 统一内存\n\n在深入分析数据之前，需要理解几个重要概念：\n\n- **传统显存**：传统独立显卡的固定显存，容量固定，如RTX 4090的24G\n- **可划分显存**：静态分配机制，将内存的一部分固定划给GPU作为显存使用，如AI Max+ 395\n- **统一内存**：内存和显存统一寻址，整个内存空间CPU和GPU都可以访问，无需显式分配（主要见于Apple M系列芯片）\n\n**重要区别**：AI Max+ 395使用可划分显存架构，需要静态分配部分内存给GPU使用；而统一内存无需显式分配，灵活性更高。\n\n# AI推理测试数据\n\n为了方便，以及因为我至今没能在WSL下成功运行`rocminfo`也就没办法跑vllm等主流推理引擎方案（就离谱），本次测试均在Windows下使用LM Studio运行。\n\n## GLM 4.7 Flash \n\n这是个MoE模型，总参数量30B激活3B的规模，主要测试`Q4_K_M`量化的情况。在这个量化等级下，在模型大小为`18.13GB`。\n\n以下的给出Prompt为：\n\n\u003e 编写一个科技公司的官网的HTML\n\n另外值得一提的是，LM Studio中对AMD显卡有两种Runtime：Vulkan和ROCm。我本以为两种Runtime不会有什么很大的区别，但是实际测试下来却axm并非如此。\n\n在16K上下文下：\n\n| 专用显存                  | 512M         | 32G              |\n| ------------------------- | ------------ | ---------------- |\n| 显存占用                  | 20.8G        | 21.3G            |\n| Vulkan速度、总数(token/s) | 17.26 (6970) | **42.89** (6107) |\n| Vulkan 首token (s)        | 0.8          | 0.8              |\n| ROCm速度、总数（token/s） | 15.28 (5262) | 14.42 (6351)     |\n| ROCm 首token (s)          | 0.04         | 0.34             |\n\nVulkan在32G专用显存下的速度实在是过于逆天，于是我重新跑了数次，结果均非常接近。后面我们还能拿到如此让人匪夷所思的成绩。\n\n16K的上下文只能说勉强够用。既然还有这么多显存可用，不妨试试更多的长度上下文。根据LM Studio估计，不同长度上下文的显存使用估计值：\n\n- 16K上下文：**18.59G**\n- 64K上下文：**19.57G**\n- 最大支持（198K）：**22.3G**\n\n看起来MoE模型的一大好处就是可以把上下文拉大！于是我选择GLM 4.7 Flash最大支持的长上下文 198K下，虽然LM Studio的估计显存占用也仅有**22.3G**，但是512M专用显存的无法正常加载：\n\n![无法正常加载模型](./198K-glm4.7-vulkan-no-memory.png)\n\n只有在32G下可以正常使用，在Vulkan下获得了**37.28 token/s（7857 token，首token 0.15s）**的成绩。\n\n同时我还测试了**Q6_K**的量化模型，在16K上下文、32G专用显存下：\n\n- **模型大小**：24.61GB\n- **预计显存占用**：25.12GB\n- **推理性能**：\n  - ROCm：13.79 token/s（6419 token，首token 0.33s）\n  - Vulkan：**25.51** token/s（5717 token，首token 0.20s）\n\n再次看到了不知道该说是Vulkan逆天还是ROCm的成绩！ROCm作为AMD官方的方案，居然被Vulkan拉开了如此大的差距。\n\n在不开启思考的情况下，10 token/s的速度还是可以应付日常使用的。\n\n## Qwen3 VL 32B\n\n稠密模型的情况就不一样了。这一部分我选择了Qwen 3 VL 32B来测试。\n\n这是个支持图像输入的模型，于是我去stackoverflow上截了如下这一张图，\n\n![Stack Overflow截图](reproduce.png)\n\n并给出prompt：\n\n\u003e 使用html和css重现这个HTML页面\n\n以下为结果：\n\n| 专用显存                  | 512M 16K    | 512M 24K    | 32G 16K     |\n| ------------------------- | ----------- | ----------- | ----------- |\n| 显存占用                  | 25.8G       | 28.3G       |    27.5G       |\n| Vulkan速度、总数(token/s) | 3.74 (4059) | 3.51 (3676) | 9.41 (6801) |\n| Vulkan 首token (s)        | 36.67       | 39.29       | 18.32       |\n| ROCm速度、总数（token/s） | 4.15 (3723) | 3.10 (3713) |  9.42 (4198)           |\n| ROCm 首token (s)          | 24.59       | 26.56       |    9.46s         |\n\n可以看到，在24K上下文已经到32G显存的极限了（28G）。但不管有没有独立显存，这个推理速度用起来已经是比较难受的级别了。\n\n# 分配48G给显存？\n\n395的另一个宣传点是可以将75%的内存划给显存，在64G的型号上，BIOS中最高可以将48G的内存划给显存。\n\n听起来很美？48G显存甚至可以高量化跑32B模型了！\n\nQwen 3 VL 32B的Q6_K量化模型大小为**28.08G**，在32G显存下可以加载，但是推理的时候因为显存不够了，速度比可以完全在显存中的Q4版本慢很多。经过测试，Q5_K_M是最大的32G显存可以充分的量化规格。\n\n而这时候你想到，48G显存岂不是就可以接近这个问题了？\n\n可是事实却是：**16G的系统内存**不仅使得正常的系统操作会开始缓慢甚至卡顿，甚至模型都无法正常加载！而我已经LM Studio中有三个选项和显存和内存全部调整为不给内存太多压力了：\n\n- KV缓存卸载到GPU内存中：打开，显存够大！\n- 保持模型在内存中：关闭\n- 尝试mmap()：将磁盘上映射到内存中空间中，关闭\n\n![Qwen 3 VL 32B的Q6_K模型无法加载](./q6_16G-memory-not-loadable-vulkan.png)\n\n# 内存可划分为显存 != 共享内存\n\n395的主要的宣传口号，就是内存可以当作显存用。这话当然不假，BIOS里确实可以将内存划分给显存，但是，它和我们预期的**共享内存**完全是两码事：\n\n- 被划分给显存部分不可以再作为内存使用\n- 每次切换显存需要重启，不可无缝切换\n\n那，如果我们不划分显存，**直接把内存当显存用呢**？其实现在的推理框架都支持把内存当显存用，但是以下两个问题让用内存当显存的方案下的推理速度惨不忍睹：\n\n1. 内存与显存的速度之间有巨大差距\n2. 内存中的数据仅能由CPU计算，而CPU在AI计算场景下速度非常缓慢，且CPU和显卡的计算数据需频繁相互拷贝\n\n理论上来说，395的内存和显存均为同一款芯片，问题1不存在，但实际上问题2的问题仍然无法避免：即使是在同一块芯片上，显存仍然不能直接用内存部分的部分，内存和显存之间拷贝仍然非常频繁。\n\n以下为使用512M专用显存（上）和32G专用显存（下）使用Vulkan运行GLM 4.7 Flash Q4_K_M时的任务管理器的图片，可以看出，512M的专用显存下GPU利用率只有70%左右，而32G下可以到达90%以上。而右上角的Copy也可以看出512M专用显存下显存一直在进行复制的操作。\n\n![512M显存跑GLM 4.7 Flash Q4 16K](./glm4.7-no-dedicated-vulkan.png)\n\n![32G显存跑GLM 4.7 Flash Q4 16K](./dedicated-memory-vulkan-glm4.7.png)\n\n同一现象也出现在512M专用显存下运行Qwen 3 VL 32B Q4_K_M的情况，GPU利用率更是只有50%，而Copy图中也能一直看到复制的过程，而整个过程中CPU也在（艰难地）参与运算。而CPU参与计算在笔记本场景下有抢功耗的问题，更影响了GPU的性能发挥。\n\n![512M显存跑Qwen 3 32B Q4KM，16K](./qwen3-32b-q4-km-no-dedicated-memory.png)\n\n更进一步地，如果把上下文拉到24K，进一步加大显存的需求量，在512M专用显存下情况更加恶化了：GPU有接近一半的时间都闲着。要知道，这个时候显存需求甚至才26G！\n\n![512M显存跑Qwen 3 32B Q4KM，24K](./24k-qwen3-32b-q4km-no-dedicated.png)\n\n# 总结\n\n我用两个字总结395的优点：**能用**\n\n- 大显存确实可以跑一些正常显卡无法跑的模型，虽然慢，但是能跑比不能跑好！\n- 成本相对较低（相比高端显卡）（也只是相对了）\n- 4060移动端的绝对算力，不算高，但是愿意等等的话，它能跑的模型还是能给出结果的\n\n可是这台笔记本形态、64G的总内存的设备却有点尴尬：\n\n- 为了兼顾日常使用，实际上最多只能32G给显存\n- 80W的最高功耗，无法充分发挥CPU的性能\n- 手动划分显存操作失去了灵活性\n\n所以395确实非常适合小主机场景：\n\n- 这类主机在分配96G显存的情况下还有32G可以用于日常场景，比64G=48G+16G实用太多\n- 这类主机的性能释放普遍超过100W，也有更完善的散热方案，可以更完美地发挥CPU和GPU的性能\n- 和395刚出来的时候AMD更羸弱的AI生态相比，至少现在主流的推理场景（LM Studio，Ollama、ComfyUI）都已经可以用了（至少我在搜索了包括AMD官网的无数地方后，终于还是找到了AMD官方支持的`pytorch`）\n\n甚至小主机的价格也比笔记本形态的设备（64G 19999）便宜太多（128G普遍15000，希望还没开始涨）。在这个内存价格疯涨的年代，能以这个价格有一台可以跑大模型的机器已经很不容易了。"])</script><script>self.__next_f.push([1,"5:[\"$\",\"article\",null,{\"children\":[[\"$\",\"div\",null,{\"className\":\"bg-neutral px-4 py-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-7xl mx-auto min-h-[256px] flex justify-center text-center text-neutral-content\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex flex-col justify-center animate-slide-up\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-4xl my-2\",\"children\":\"可划分显存 != 统一内存：AI Max+ 395 64G AI推理性能\"}],[\"$\",\"$L22\",null,{\"className\":\"justify-center\",\"articleId\":\"aimaxplus395-ai-inference\",\"info\":{\"content\":\"$23\",\"title\":\"可划分显存 != 统一内存：AI Max+ 395 64G AI推理性能\",\"date\":\"2026-02-02 20:34\",\"id\":\"aimaxplus395-ai-inference\",\"lang\":\"cn\",\"tags\":[\"ai\",\"hands-on\",\"thoughts\"],\"related\":\"$undefined\",\"ignored_in_list\":\"$undefined\",\"hide_heading\":\"$undefined\",\"no_toc\":\"$undefined\",\"absolute_path\":\"$undefined\",\"last_updated\":\"$undefined\",\"wordCount\":2457,\"readingTime\":12.285,\"filePath\":\"contents/20260202-aimaxplus395-ai-inference/cn.md\",\"summary\":\"$undefined\"},\"langVersions\":[\"cn\"]}]]}]}]}],\"$L24\"]}]\n"])</script><script>self.__next_f.push([1,"26:I[39182,[\"/_next/static/chunks/8d29a04bcfe27c24.js\",\"/_next/static/chunks/3dff3d4c63cf346e.js\",\"/_next/static/chunks/b3af52d5d180873a.js\",\"/_next/static/chunks/86b442c1397f7351.js\",\"/_next/static/chunks/0a1497ca0a1721ad.js\",\"/_next/static/chunks/4ec1bf7a32b70f87.js\",\"/_next/static/chunks/276b22541034e0ea.js\"],\"RelatedArticles\"]\n27:I[42449,[\"/_next/static/chunks/8d29a04bcfe27c24.js\",\"/_next/static/chunks/3dff3d4c63cf346e.js\",\"/_next/static/chunks/b3af52d5d180873a.js\",\"/_next/static/chunks/86b442c1397f7351.js\",\"/_next/static/chunks/0a1497ca0a1721ad.js\",\"/_next/static/chunks/4ec1bf7a32b70f87.js\",\"/_next/static/chunks/276b22541034e0ea.js\"],\"CommentPanelWithCurrentLanguage\"]\n24:[\"$\",\"div\",null,{\"className\":\"animate-slide-up\",\"children\":[[\"$\",\"div\",null,{\"className\":\"max-w-7xl mx-auto p-4\",\"children\":\"$L25\"}],[\"$\",\"div\",null,{\"className\":\"max-w-7xl mx-auto p-4\",\"children\":[\"$\",\"$L26\",null,{\"relatedArticles\":[]}]}],[\"$\",\"div\",null,{\"className\":\"max-w-7xl mx-auto p-4\",\"children\":[\"$\",\"$L27\",null,{\"articleId\":\"aimaxplus395-ai-inference\",\"articleTitle\":\"可划分显存 != 统一内存：AI Max+ 395 64G AI推理性能\"}]}]]}]\n"])</script><script>self.__next_f.push([1,"28:I[79817,[\"/_next/static/chunks/8d29a04bcfe27c24.js\",\"/_next/static/chunks/3dff3d4c63cf346e.js\",\"/_next/static/chunks/b3af52d5d180873a.js\",\"/_next/static/chunks/86b442c1397f7351.js\",\"/_next/static/chunks/0a1497ca0a1721ad.js\",\"/_next/static/chunks/4ec1bf7a32b70f87.js\",\"/_next/static/chunks/276b22541034e0ea.js\"],\"Gallery\"]\n29:T4df,M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z2a:T4df,M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"])</script><script>self.__next_f.push([1,"25:[\"$\",\"div\",null,{\"className\":\"flex flex-row space-x-4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"prose max-w-full lg:w-[75%]\",\"children\":[\"$undefined\",[\"$\",\"$L28\",null,{\"withCaption\":true,\"id\":\"aimaxplus395-ai-inference\",\"children\":[[\"$\",\"h1\",\"h1-0\",{\"id\":\"前言\",\"children\":[[\"$\",\"a\",\"前言\",{\"href\":\"#前言\",\"className\":\"mr-1\",\"children\":[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 512 512\",\"className\":\"inline-block opacity-20 hover:opacity-60\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"$29\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":16,\"width\":16,\"xmlns\":\"http://www.w3.org/2000/svg\"}]}],\"前言\"]}],\"\\n\",[\"$\",\"p\",\"p-0\",{\"children\":[\"之前写过一篇\",[\"$\",\"a\",\"a-0\",{\"href\":\"/articles/aimaxplus395-experience\",\"children\":\"关于HP战99 Ultra（搭载AMD AI Max+ 395）的使用体验\"}],\"，今天聊聊这台笔记本在AI推理场景下的表现。作为这台机器宣传的主要场景，AI推理的实际使用情况却优点一言难尽。\"]}],\"\\n\",[\"$\",\"h1\",\"h1-1\",{\"id\":\"硬件配置回顾\",\"children\":[[\"$\",\"a\",\"硬件配置回顾\",{\"href\":\"#硬件配置回顾\",\"className\":\"mr-1\",\"children\":[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 512 512\",\"className\":\"inline-block opacity-20 hover:opacity-60\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"$2a\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":16,\"width\":16,\"xmlns\":\"http://www.w3.org/2000/svg\"}]}],\"硬件配置回顾\"]}],\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\",\"$L2b\",\"\\n\",\"$L2c\",\"\\n\",\"$L2d\",\"\\n\",\"$L2e\",\"\\n\",\"$L2f\",\"\\n\",\"$L30\",\"\\n\",\"$L31\",\"\\n\",\"$L32\",\"\\n\",\"$L33\",\"\\n\",\"$L34\",\"\\n\",\"$L35\",\"\\n\",\"$L36\",\"\\n\",\"$L37\",\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\",\"$L38\",\"\\n\",\"$L39\",\"\\n\",\"$L3a\",\"\\n\",\"$L3b\",\"\\n\",\"$L3c\",\"\\n\",\"$L3d\",\"\\n\",\"$L3e\",\"\\n\",\"$L3f\",\"\\n\",\"$L40\",\"\\n\",\"$L41\",\"\\n\",\"$L42\",\"\\n\",\"$L43\",\"\\n\",\"$L44\",\"\\n\",\"$L45\",\"\\n\",\"$L46\",\"\\n\",\"$L47\",\"\\n\",\"$L48\",\"\\n\",\"$L49\",\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\",\"$L4a\",\"\\n\",\"$L4b\",\"\\n\",\"$L4c\",\"\\n\",\"$L4d\",\"\\n\",\"$L4e\",\"\\n\",\"$L4f\",\"\\n\",\"$L50\",\"\\n\",\"$L51\",\"\\n\",\"$L52\",\"\\n\",\"$L53\",\"\\n\",\"$L54\",\"\\n\",\"$L55\",\"\\n\",\"$L56\",\"\\n\",\"$L57\",\"\\n\",\"$L58\",\"\\n\",\"$L59\",\"\\n\",\"$L5a\",\"\\n\",\"$L5b\",\"\\n\",\"$L5c\",\"\\n\",\"$L5d\",\"\\n\",\"$L5e\",\"\\n\",\"$L5f\",\"\\n\",\"$L60\",\"\\n\",\"$L61\",\"\\n\",\"$L62\",\"\\n\",\"$L63\",\"\\n\",\"$L64\",\"\\n\",\"$L65\",\"\\n\",\"$L66\",\"\\n\",\"$L67\",\"\\n\",\"$L68\"]}]]}],\"$L69\"]}]\n"])</script><script>self.__next_f.push([1,"78:I[14620,[\"/_next/static/chunks/8d29a04bcfe27c24.js\",\"/_next/static/chunks/3dff3d4c63cf346e.js\",\"/_next/static/chunks/b3af52d5d180873a.js\",\"/_next/static/chunks/86b442c1397f7351.js\",\"/_next/static/chunks/0a1497ca0a1721ad.js\",\"/_next/static/chunks/4ec1bf7a32b70f87.js\",\"/_next/static/chunks/276b22541034e0ea.js\"],\"ArticleToc\"]\n2b:[\"$\",\"table\",\"table-0\",{\"children\":[[\"$\",\"thead\",\"thead-0\",{\"children\":[\"$\",\"tr\",\"tr-0\",{\"children\":[[\"$\",\"th\",\"th-0\",{\"children\":\"配置\"}],[\"$\",\"th\",\"th-1\",{\"children\":\"详情\"}]]}]}],[\"$\",\"tbody\",\"tbody-0\",{\"children\":[[\"$\",\"tr\",\"tr-0\",{\"children\":[[\"$\",\"td\",\"td-0\",{\"children\":\"CPU\"}],[\"$\",\"td\",\"td-1\",{\"children\":\"AMD Ryzen AI Max+ 395 16C32T Zen5\"}]]}],[\"$\",\"tr\",\"tr-1\",{\"children\":[[\"$\",\"td\",\"td-0\",{\"children\":\"内存\"}],[\"$\",\"td\",\"td-1\",{\"children\":\"64G LPDDR5 8000MT 4通道可划分显存\"}]]}],[\"$\",\"tr\",\"tr-2\",{\"children\":[[\"$\",\"td\",\"td-0\",{\"children\":\"显卡\"}],[\"$\",\"td\",\"td-1\",{\"children\":\"Radeon 8060S 40CU RDNA3.5\"}]]}],[\"$\",\"tr\",\"tr-3\",{\"children\":[[\"$\",\"td\",\"td-0\",{\"children\":\"显存\"}],[\"$\",\"td\",\"td-1\",{\"children\":\"可在BIOS里将几个固定挡位的内存分配给显存\"}]]}]]}]]}]\n6a:T4df,M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z2c:[\"$\",\"h1\",\"h1-2\",{\"id\":\"关键概念可划分显存-vs-统一内存\",\"children\":[[\"$\",\"a\",\"关键概念可划分显存-vs-统一内存\",{\"href\":\"#关键概念可划分显存-vs-统一内存\",\"className\":\"mr-1\",\"children\":[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 512 512\",\"className\":\"inline-block opacity-20 hover:opacity-60\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"$6a\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":16,\"width\":16,\"xmlns\":\"http://www.w3.org/2000/svg\"}]}],\"关键概念：可划分显存 vs 统一内存\"]}]\n2d:[\"$\",\"p\",\"p-1\",{\"children\":\"在深入分析数据之前，需要理解几个重要概念：\"}]\n2e:[\"$\",\"ul\",\"ul-0\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"传统显存\"}],\"：传统独立显卡的固定显存，容量固定，如RTX 4090的24G\"]}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"可划分显存\"}],\"：静态分配机制，将内存的一部分固定划给GPU作为显存使用，如AI Max+ 395\"]}],\"\\n\",[\"$\",\"li\",\"li-2\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"统一内存\"}],\"：内存和显存统一寻址，整个内存空间CPU和GPU都可以访问，无需显式分配（主要见于Apple M系列芯片）\"]}],\"\\n\"]}]\n2f:[\"$\",\"p\",\"p-2\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"重要区别\"}],\"：AI Max+ 395使用可划分显存架构，需要静态分配部分内存给GPU使用；而统一内存无需显式分配，灵活性更高。\"]}]\n6b:T4df,M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-"])</script><script>self.__next_f.push([1,"59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z30:[\"$\",\"h1\",\"h1-3\",{\"id\":\"ai推理测试数据\",\"children\":[[\"$\",\"a\",\"ai推理测试数据\",{\"href\":\"#ai推理测试数据\",\"className\":\"mr-1\",\"children\":[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 512 512\",\"className\":\"inline-block opacity-20 hover:opacity-60\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"$6b\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":16,\"width\":16,\"xmlns\":\"http://www.w3.org/2000/svg\"}]}],\"AI推理测试数据\"]}]\n31:[\"$\",\"p\",\"p-3\",{\"children\":[\"为了方便，以及因为我至今没能在WSL下成功运行\",[\"$\",\"code\",\"code-0\",{\"children\":\"rocminfo\"}],\"也就没办法跑vllm等主流推理引擎方案（就离谱），本次测试均在Windows下使用LM Studio运行。\"]}]\n6c:T4df,M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z32:[\"$\",\"h2\",\"h2-0\",{\"id\":\"glm-47-flash\",\"children\":[[\"$\",\"a\",\"glm-47-flash\",{\"href\":\"#glm-47-flash\",\"className\":\"mr-1\",\"children\":[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 512 512\",\"className\":\"inline-block opacity-20 hover:opacity-60\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"$6c\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":16,\"width\":16,\"xmlns\":\"http://www.w3.org/2000/svg\"}]}],\"GLM 4.7 Flash\"]}]\n33:[\"$\",\"p\",\"p-4\",{\"children\":[\"这是个MoE模型，总参数量30B激活3B的规模，主要测试\",[\"$\",\"code\",\"code-0\",{\"children\":\"Q4_K_M\"}],\"量化的情况。在这个量化等级下，在模型大小为\",[\"$\",\"code\",\"code-1\",{\"children\":\"18.13GB\"}],\"。\"]}]\n34:[\"$\",\"p\",\"p-5\",{\"children\":\"以下的给出Prompt为：\"}]\n35:[\"$\",\"blockquote\",\"blockquote-0\",{\"children\":[\"\\n\",[\"$\",\"p\",\"p-0\",{\"children\":\"编写一个科技公司的官网的HTML\"}],\"\\n\"]}]\n36:[\"$\",\"p\","])</script><script>self.__next_f.push([1,"\"p-6\",{\"children\":\"另外值得一提的是，LM Studio中对AMD显卡有两种Runtime：Vulkan和ROCm。我本以为两种Runtime不会有什么很大的区别，但是实际测试下来却axm并非如此。\"}]\n37:[\"$\",\"p\",\"p-7\",{\"children\":\"在16K上下文下：\"}]\n38:[\"$\",\"table\",\"table-1\",{\"children\":[[\"$\",\"thead\",\"thead-0\",{\"children\":[\"$\",\"tr\",\"tr-0\",{\"children\":[[\"$\",\"th\",\"th-0\",{\"children\":\"专用显存\"}],[\"$\",\"th\",\"th-1\",{\"children\":\"512M\"}],[\"$\",\"th\",\"th-2\",{\"children\":\"32G\"}]]}]}],[\"$\",\"tbody\",\"tbody-0\",{\"children\":[[\"$\",\"tr\",\"tr-0\",{\"children\":[[\"$\",\"td\",\"td-0\",{\"children\":\"显存占用\"}],[\"$\",\"td\",\"td-1\",{\"children\":\"20.8G\"}],[\"$\",\"td\",\"td-2\",{\"children\":\"21.3G\"}]]}],[\"$\",\"tr\",\"tr-1\",{\"children\":[[\"$\",\"td\",\"td-0\",{\"children\":\"Vulkan速度、总数(token/s)\"}],[\"$\",\"td\",\"td-1\",{\"children\":\"17.26 (6970)\"}],[\"$\",\"td\",\"td-2\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"42.89\"}],\" (6107)\"]}]]}],[\"$\",\"tr\",\"tr-2\",{\"children\":[[\"$\",\"td\",\"td-0\",{\"children\":\"Vulkan 首token (s)\"}],[\"$\",\"td\",\"td-1\",{\"children\":\"0.8\"}],[\"$\",\"td\",\"td-2\",{\"children\":\"0.8\"}]]}],[\"$\",\"tr\",\"tr-3\",{\"children\":[[\"$\",\"td\",\"td-0\",{\"children\":\"ROCm速度、总数（token/s）\"}],[\"$\",\"td\",\"td-1\",{\"children\":\"15.28 (5262)\"}],[\"$\",\"td\",\"td-2\",{\"children\":\"14.42 (6351)\"}]]}],[\"$\",\"tr\",\"tr-4\",{\"children\":[[\"$\",\"td\",\"td-0\",{\"children\":\"ROCm 首token (s)\"}],[\"$\",\"td\",\"td-1\",{\"children\":\"0.04\"}],[\"$\",\"td\",\"td-2\",{\"children\":\"0.34\"}]]}]]}]]}]\n39:[\"$\",\"p\",\"p-8\",{\"children\":\"Vulkan在32G专用显存下的速度实在是过于逆天，于是我重新跑了数次，结果均非常接近。后面我们还能拿到如此让人匪夷所思的成绩。\"}]\n3a:[\"$\",\"p\",\"p-9\",{\"children\":\"16K的上下文只能说勉强够用。既然还有这么多显存可用，不妨试试更多的长度上下文。根据LM Studio估计，不同长度上下文的显存使用估计值：\"}]\n3b:[\"$\",\"ul\",\"ul-1\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":[\"16K上下文：\",[\"$\",\"strong\",\"strong-0\",{\"children\":\"18.59G\"}]]}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":[\"64K上下文：\",[\"$\",\"strong\",\"strong-0\",{\"children\":\"19.57G\"}]]}],\"\\n\",[\"$\",\"li\",\"li-2\",{\"children\":[\"最大支持（198K）：\",[\"$\",\"strong\",\"strong-0\",{\"children\":\"22.3G\"}]]}],\"\\n\"]}]\n3c:[\"$\",\"p\",\"p-10\",{\"children\":[\"看起来MoE模型的一大好处就是可以把上下文拉大！于是我选择GLM 4.7 Flash最大支持的长上下文 198K下，虽然LM Studio的估计显存占用也仅有\",[\"$\",\"strong\",\"strong-0\",{\"children\":\"22.3G\"}],\"，但是512M专用显存的无法正常加载：\"]}]\n3d:[\"$\",\"p\",\"p-11\",{\"children\":\"$L6d\"}]\n3e:[\"$\",\"p\",\"p-12\",{\"children\":\"只有在32G下可以正常使用，在Vulkan下获得了**37.28 token/s（7857 token，首token 0.15s）**的成绩。\"}]\n3f:[\"$\",\"p\",\"p-13\",{\"children\":[\"同时我还测试了\",[\"$\",\"strong\",\"strong-0\",{\"children\":\"Q6_K\"}],\"的量化模型，在16K上下文、32G专用显存下：\"]}]\n40:[\"$\",\"ul\",\"ul-2\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"模型大小\"}],\"：24.61GB\"]}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"预计显存占用\"}],\"：25.12GB\"]}],\"\\n\",[\"$\",\"li\",\"li-2\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"推理性能\"}],\"：\\n\",[\"$\",\"ul\",\"ul-0\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":\"ROCm：13.79 token/s（6419 token，首token 0.33s）\"}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":[\"Vulkan：\",[\"$\",\"strong\",\"strong-0\",{\"children\":\"25.51\"}],\" token/s（5717 token，首token 0.20s）\"]}],\"\\n\"]}],\"\\n\"]}],\"\\n\"]}]\n41:[\"$\",\"p\",\"p-14\",{\"children\":\"再次看到了不知道该说是Vulkan逆天还是ROCm的成绩！ROCm作为AMD官方的方案，居然被Vulkan拉开了如此大的差距。\"}]\n42:[\"$\",\"p\",\"p-15\",{\"children\":\"在不开启思考的情况下，10 token/s的速度还是可以应付日常使用的。\"}]\n6e:T4df,M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1."])</script><script>self.__next_f.push([1,"986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z43:[\"$\",\"h2\",\"h2-1\",{\"id\":\"qwen3-vl-32b\",\"children\":[[\"$\",\"a\",\"qwen3-vl-32b\",{\"href\":\"#qwen3-vl-32b\",\"className\":\"mr-1\",\"children\":[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 512 512\",\"className\":\"inline-block opacity-20 hover:opacity-60\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"$6e\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":16,\"width\":16,\"xmlns\":\"http://www.w3.org/2000/svg\"}]}],\"Qwen3 VL 32B\"]}]\n44:[\"$\",\"p\",\"p-16\",{\"children\":\"稠密模型的情况就不一样了。这一部分我选择了Qwen 3 VL 32B来测试。\"}]\n45:[\"$\",\"p\",\"p-17\",{\"children\":\"这是个支持图像输入的模型，于是我去stackoverflow上截了如下这一张图，\"}]\n46:[\"$\",\"p\",\"p-18\",{\"children\":\"$L6f\"}]\n47:[\"$\",\"p\",\"p-19\",{\"children\":\"并给出prompt：\"}]\n48:[\"$\",\"blockquote\",\"blockquote-1\",{\"children\":[\"\\n\",[\"$\",\"p\",\"p-0\",{\"children\":\"使用html和css重现这个HTML页面\"}],\"\\n\"]}]\n49:[\"$\",\"p\",\"p-20\",{\"children\":\"以下为结果：\"}]\n4a:[\"$\",\"table\",\"table-2\",{\"children\":[[\"$\",\"thead\",\"thead-0\",{\"children\":[\"$\",\"tr\",\"tr-0\",{\"children\":[[\"$\",\"th\",\"th-0\",{\"children\":\"专用显存\"}],[\"$\",\"th\",\"th-1\",{\"children\":\"512M 16K\"}],[\"$\",\"th\",\"th-2\",{\"children\":\"512M 24K\"}],[\"$\",\"th\",\"th-3\",{\"children\":\"32G 16K\"}]]}]}],[\"$\",\"tbody\",\"tbody-0\",{\"children\":[[\"$\",\"tr\",\"tr-0\",{\"children\":[[\"$\",\"td\",\"td-0\",{\"children\":\"显存占用\"}],[\"$\",\"td\",\"td-1\",{\"children\":\"25.8G\"}],[\"$\",\"td\",\"td-2\",{\"children\":\"28.3G\"}],[\"$\",\"td\",\"td-3\",{\"children\":\"27.5G\"}]]}],[\"$\",\"tr\",\"tr-1\",{\"children\":[[\"$\",\"td\",\"td-0\",{\"children\":\"Vulkan速度、总数(token/s)\"}],[\"$\",\"td\",\"td-1\",{\"children\":\"3.74 (4059)\"}],[\"$\",\"td\",\"td-2\",{\"children\":\"3.51 (3676)\"}],[\"$\",\"td\",\"td-3\",{\"children\":\"9.41 (6801)\"}]]}],[\"$\",\"tr\",\"tr-2\",{\"children\":[[\"$\",\"td\",\"td-0\",{\"children\":\"Vulkan 首token (s)\"}],[\"$\",\"td\",\"td-1\",{\"children\":\"36.67\"}],[\"$\",\"td\",\"td-2\",{\"children\":\"39.29\"}],[\"$\",\"td\",\"td-3\",{\"children\":\"18.32\"}]]}],[\"$\",\"tr\",\"tr-3\",{\"children\":[[\"$\",\"td\",\"td-0\",{\"children\":\"ROCm速度、总数（token/s）\"}],[\"$\",\"td\",\"td-1\",{\"children\":\"4.15 (3723)\"}],[\"$\",\"td\",\"td-2\",{\"children\":\"3.10 (3713)\"}],[\"$\",\"td\",\"td-3\",{\"children\":\"9.42 (4198)\"}]]}],[\"$\",\"tr\",\"tr-4\",{\"children\":[[\"$\",\"td\",\"td-0\",{\"children\":\"ROCm 首token (s)\"}],[\"$\",\"td\",\"td-1\",{\"children\":\"24.59\"}],[\"$\",\"td\",\"td-2\",{\"children\":\"26.56\"}],[\"$\",\"td\",\"td-3\",{\"children\":\"9.46s\"}]]}]]}]]}]\n4b:[\"$\",\"p\",\"p-21\",{\"children\":\"可以看到，在24K上下文已经到32G显存的极限了（28G）。但不管有没有独立显存，这个推理速度用起来已经是比较难受的级别了。\"}]\n70:T4df,M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-"])</script><script>self.__next_f.push([1,"12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z4c:[\"$\",\"h1\",\"h1-4\",{\"id\":\"分配48g给显存\",\"children\":[[\"$\",\"a\",\"分配48g给显存\",{\"href\":\"#分配48g给显存\",\"className\":\"mr-1\",\"children\":[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 512 512\",\"className\":\"inline-block opacity-20 hover:opacity-60\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"$70\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":16,\"width\":16,\"xmlns\":\"http://www.w3.org/2000/svg\"}]}],\"分配48G给显存？\"]}]\n4d:[\"$\",\"p\",\"p-22\",{\"children\":\"395的另一个宣传点是可以将75%的内存划给显存，在64G的型号上，BIOS中最高可以将48G的内存划给显存。\"}]\n4e:[\"$\",\"p\",\"p-23\",{\"children\":\"听起来很美？48G显存甚至可以高量化跑32B模型了！\"}]\n4f:[\"$\",\"p\",\"p-24\",{\"children\":[\"Qwen 3 VL 32B的Q6_K量化模型大小为\",[\"$\",\"strong\",\"strong-0\",{\"children\":\"28.08G\"}],\"，在32G显存下可以加载，但是推理的时候因为显存不够了，速度比可以完全在显存中的Q4版本慢很多。经过测试，Q5_K_M是最大的32G显存可以充分的量化规格。\"]}]\n50:[\"$\",\"p\",\"p-25\",{\"children\":\"而这时候你想到，48G显存岂不是就可以接近这个问题了？\"}]\n51:[\"$\",\"p\",\"p-26\",{\"children\":[\"可是事实却是：\",[\"$\",\"strong\",\"strong-0\",{\"children\":\"16G的系统内存\"}],\"不仅使得正常的系统操作会开始缓慢甚至卡顿，甚至模型都无法正常加载！而我已经LM Studio中有三个选项和显存和内存全部调整为不给内存太多压力了：\"]}]\n52:[\"$\",\"ul\",\"ul-3\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":\"KV缓存卸载到GPU内存中：打开，显存够大！\"}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":\"保持模型在内存中：关闭\"}],\"\\n\",[\"$\",\"li\",\"li-2\",{\"children\":\"尝试mmap()：将磁盘上映射到内存中空间中，关闭\"}],\"\\n\"]}]\n53:[\"$\",\"p\",\"p-27\",{\"children\":\"$L71\"}]\n72:T4df,M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z54:[\"$\",\"h1\",\"h1-5\",{\"id\":\"内存可划分为显存--共享内存\",\"children\":[[\"$\",\"a\",\"内存可划分为显存--共享内存\",{\"href\":\"#内存可划分为显存--共享内存\",\"classN"])</script><script>self.__next_f.push([1,"ame\":\"mr-1\",\"children\":[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 512 512\",\"className\":\"inline-block opacity-20 hover:opacity-60\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"$72\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":16,\"width\":16,\"xmlns\":\"http://www.w3.org/2000/svg\"}]}],\"内存可划分为显存 != 共享内存\"]}]\n55:[\"$\",\"p\",\"p-28\",{\"children\":[\"395的主要的宣传口号，就是内存可以当作显存用。这话当然不假，BIOS里确实可以将内存划分给显存，但是，它和我们预期的\",[\"$\",\"strong\",\"strong-0\",{\"children\":\"共享内存\"}],\"完全是两码事：\"]}]\n56:[\"$\",\"ul\",\"ul-4\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":\"被划分给显存部分不可以再作为内存使用\"}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":\"每次切换显存需要重启，不可无缝切换\"}],\"\\n\"]}]\n57:[\"$\",\"p\",\"p-29\",{\"children\":[\"那，如果我们不划分显存，\",[\"$\",\"strong\",\"strong-0\",{\"children\":\"直接把内存当显存用呢\"}],\"？其实现在的推理框架都支持把内存当显存用，但是以下两个问题让用内存当显存的方案下的推理速度惨不忍睹：\"]}]\n58:[\"$\",\"ol\",\"ol-0\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":\"内存与显存的速度之间有巨大差距\"}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":\"内存中的数据仅能由CPU计算，而CPU在AI计算场景下速度非常缓慢，且CPU和显卡的计算数据需频繁相互拷贝\"}],\"\\n\"]}]\n59:[\"$\",\"p\",\"p-30\",{\"children\":\"理论上来说，395的内存和显存均为同一款芯片，问题1不存在，但实际上问题2的问题仍然无法避免：即使是在同一块芯片上，显存仍然不能直接用内存部分的部分，内存和显存之间拷贝仍然非常频繁。\"}]\n5a:[\"$\",\"p\",\"p-31\",{\"children\":\"以下为使用512M专用显存（上）和32G专用显存（下）使用Vulkan运行GLM 4.7 Flash Q4_K_M时的任务管理器的图片，可以看出，512M的专用显存下GPU利用率只有70%左右，而32G下可以到达90%以上。而右上角的Copy也可以看出512M专用显存下显存一直在进行复制的操作。\"}]\n5b:[\"$\",\"p\",\"p-32\",{\"children\":\"$L73\"}]\n5c:[\"$\",\"p\",\"p-33\",{\"children\":\"$L74\"}]\n5d:[\"$\",\"p\",\"p-34\",{\"children\":\"同一现象也出现在512M专用显存下运行Qwen 3 VL 32B Q4_K_M的情况，GPU利用率更是只有50%，而Copy图中也能一直看到复制的过程，而整个过程中CPU也在（艰难地）参与运算。而CPU参与计算在笔记本场景下有抢功耗的问题，更影响了GPU的性能发挥。\"}]\n5e:[\"$\",\"p\",\"p-35\",{\"children\":\"$L75\"}]\n5f:[\"$\",\"p\",\"p-36\",{\"children\":\"更进一步地，如果把上下文拉到24K，进一步加大显存的需求量，在512M专用显存下情况更加恶化了：GPU有接近一半的时间都闲着。要知道，这个时候显存需求甚至才26G！\"}]\n60:[\"$\",\"p\",\"p-37\",{\"children\":\"$L76\"}]\n77:T4df,M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13."])</script><script>self.__next_f.push([1,"906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z61:[\"$\",\"h1\",\"h1-6\",{\"id\":\"总结\",\"children\":[[\"$\",\"a\",\"总结\",{\"href\":\"#总结\",\"className\":\"mr-1\",\"children\":[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 512 512\",\"className\":\"inline-block opacity-20 hover:opacity-60\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"$77\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":16,\"width\":16,\"xmlns\":\"http://www.w3.org/2000/svg\"}]}],\"总结\"]}]\n62:[\"$\",\"p\",\"p-38\",{\"children\":[\"我用两个字总结395的优点：\",[\"$\",\"strong\",\"strong-0\",{\"children\":\"能用\"}]]}]\n63:[\"$\",\"ul\",\"ul-5\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":\"大显存确实可以跑一些正常显卡无法跑的模型，虽然慢，但是能跑比不能跑好！\"}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":\"成本相对较低（相比高端显卡）（也只是相对了）\"}],\"\\n\",[\"$\",\"li\",\"li-2\",{\"children\":\"4060移动端的绝对算力，不算高，但是愿意等等的话，它能跑的模型还是能给出结果的\"}],\"\\n\"]}]\n64:[\"$\",\"p\",\"p-39\",{\"children\":\"可是这台笔记本形态、64G的总内存的设备却有点尴尬：\"}]\n65:[\"$\",\"ul\",\"ul-6\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":\"为了兼顾日常使用，实际上最多只能32G给显存\"}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":\"80W的最高功耗，无法充分发挥CPU的性能\"}],\"\\n\",[\"$\",\"li\",\"li-2\",{\"children\":\"手动划分显存操作失去了灵活性\"}],\"\\n\"]}]\n66:[\"$\",\"p\",\"p-40\",{\"children\":\"所以395确实非常适合小主机场景：\"}]\n67:[\"$\",\"ul\",\"ul-7\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":\"这类主机在分配96G显存的情况下还有32G可以用于日常场景，比64G=48G+16G实用太多\"}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":\"这类主机的性能释放普遍超过100W，也有更完善的散热方案，可以更完美地发挥CPU和GPU的性能\"}],\"\\n\",[\"$\",\"li\",\"li-2\",{\"children\":[\"和395刚出来的时候AMD更羸弱的AI生态相比，至少现在主流的推理场景（LM Studio，Ollama、ComfyUI）都已经可以用了（至少我在搜索了包括AMD官网的无数地方后，终于还是找到了AMD官方支持的\",[\"$\",\"code\",\"code-0\",{\"children\":\"pytorch\"}],\"）\"]}],\"\\n\"]}]\n68:[\"$\",\"p\",\"p-41\",{\"children\":\"甚至小主机的价格也比笔记本形态的设备（64G 19999）便宜太多（128G普遍15000，希望还没开始涨）。在这个内存价格疯涨的年代，能以这个价格有一台可以跑大模型的机器已经很不容易了。\"}]\n69:[\"$\",\"div\",null,{\"className\":\"hidden lg:block lg:w-[25%]\",\"children\":[\"$\",\"$L78\",null,{\"toc\":[{\"depth\":1,\"value\":\"前言\",\"id\":\"前言\"},{\"depth\":1,\"value\":\"硬件配置回顾\",\"id\":\"硬件配置回顾\"},{\"depth\":1,\"value\":\"关键概念：可划分显存 vs 统一内存\",\"id\":\"关键概念可划分显存-vs-统一内存\"},{\"depth\":1,\"value\":\"AI推理测试数据\",\"id\":\"ai推理测试数据\",\"children\":[{\"depth\":2,\"value\":\"GLM 4.7 Flash\",\"id\":\"glm-47-flash\"},{\"depth\":2,\"value\":\"Qwen3 VL 32B\",\"id\":\"qwen3-vl-32b\"}]},{\"depth\":1,\"value\":\"分配48G给显存？\",\"id\":\"分配48g给显存\"},{\"depth\":1,\"value\":\"内存可划分为显存 != 共享内存\",\"id\":\"内存可划分为显存--共享内存\"},{\"depth\":1,\"value\":\"总结\",\"id\":\"总结\"}],\"hasSummary\":false}]}]\n"])</script><script>self.__next_f.push([1,"a:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"79:I[99195,[\"/_next/static/chunks/2caa33a942c5f527.js\",\"/_next/static/chunks/59983278a34fd25c.js\"],\"IconMark\"]\n8:null\nc:[[\"$\",\"title\",\"0\",{\"children\":\"可划分显存 != 统一内存：AI Max+ 395 64G AI推理性能 - ddadaal.me\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"ddadaal's personal website\"}],[\"$\",\"link\",\"2\",{\"rel\":\"manifest\",\"href\":\"/site.webmanifest\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"link\",\"3\",{\"rel\":\"icon\",\"href\":\"/favicon.ico?favicon.3d1adb1d.ico\",\"sizes\":\"48x48\",\"type\":\"image/x-icon\"}],[\"$\",\"link\",\"4\",{\"rel\":\"icon\",\"href\":\"/icon.svg?icon.443451fa.svg\",\"sizes\":\"any\",\"type\":\"image/svg+xml\"}],[\"$\",\"link\",\"5\",{\"rel\":\"apple-touch-icon\",\"href\":\"/apple-icon.png?apple-icon.01036b81.png\",\"sizes\":\"180x180\",\"type\":\"image/png\"}],[\"$\",\"$L79\",\"6\",{}]]\n"])</script><script>self.__next_f.push([1,"7a:I[72053,[\"/_next/static/chunks/8d29a04bcfe27c24.js\",\"/_next/static/chunks/3dff3d4c63cf346e.js\",\"/_next/static/chunks/b3af52d5d180873a.js\",\"/_next/static/chunks/86b442c1397f7351.js\",\"/_next/static/chunks/0a1497ca0a1721ad.js\",\"/_next/static/chunks/4ec1bf7a32b70f87.js\",\"/_next/static/chunks/276b22541034e0ea.js\"],\"ArticleImage\"]\n6d:[\"$\",\"$L7a\",\"img-0\",{\"src\":\"/articles/asset/contents/20260202-aimaxplus395-ai-inference/198K-glm4.7-vulkan-no-memory.png\",\"imageSize\":{\"height\":175,\"width\":454},\"imageProps\":{\"src\":\"./198K-glm4.7-vulkan-no-memory.png\",\"alt\":\"无法正常加载模型\"}}]\n71:[\"$\",\"$L7a\",\"img-0\",{\"src\":\"/articles/asset/contents/20260202-aimaxplus395-ai-inference/q6_16G-memory-not-loadable-vulkan.png\",\"imageSize\":{\"height\":821,\"width\":1046},\"imageProps\":{\"src\":\"./q6_16G-memory-not-loadable-vulkan.png\",\"alt\":\"Qwen 3 VL 32B的Q6_K模型无法加载\"}}]\n6f:[\"$\",\"$L7a\",\"img-0\",{\"src\":\"/articles/asset/contents/20260202-aimaxplus395-ai-inference/reproduce.png\",\"imageSize\":{\"height\":831,\"width\":1486},\"imageProps\":{\"src\":\"reproduce.png\",\"alt\":\"Stack Overflow截图\"}}]\n73:[\"$\",\"$L7a\",\"img-0\",{\"src\":\"/articles/asset/contents/20260202-aimaxplus395-ai-inference/glm4.7-no-dedicated-vulkan.png\",\"imageSize\":{\"height\":1553,\"width\":1844},\"imageProps\":{\"src\":\"./glm4.7-no-dedicated-vulkan.png\",\"alt\":\"512M显存跑GLM 4.7 Flash Q4 16K\"}}]\n74:[\"$\",\"$L7a\",\"img-0\",{\"src\":\"/articles/asset/contents/20260202-aimaxplus395-ai-inference/dedicated-memory-vulkan-glm4.7.png\",\"imageSize\":{\"height\":1470,\"width\":1866},\"imageProps\":{\"src\":\"./dedicated-memory-vulkan-glm4.7.png\",\"alt\":\"32G显存跑GLM 4.7 Flash Q4 16K\"}}]\n75:[\"$\",\"$L7a\",\"img-0\",{\"src\":\"/articles/asset/contents/20260202-aimaxplus395-ai-inference/qwen3-32b-q4-km-no-dedicated-memory.png\",\"imageSize\":{\"height\":735,\"width\":1127},\"imageProps\":{\"src\":\"./qwen3-32b-q4-km-no-dedicated-memory.png\",\"alt\":\"512M显存跑Qwen 3 32B Q4KM，16K\"}}]\n76:[\"$\",\"$L7a\",\"img-0\",{\"src\":\"/articles/asset/contents/20260202-aimaxplus395-ai-inference/24k-qwen3-32b-q4km-no-dedicated.png\",\"imageSize\":{\"height\":1072,\"width\":1661},\"imageProps\":{\"src\":\"./24k-qwen3-32b-q4km-no-dedicated.png\",\"alt\":\"512M显存跑Qwen 3 32B Q4KM，24K\"}}]\n"])</script></body></html>